{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study 2 Analysis\n",
    "Analyses for each research question in Study 2. These analyses are done with the newest setup of the project where the researchers annotate whether VLMs accurately identified the product in images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import statistics as s\n",
    "from scipy import stats\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality_metrics(df, reference_df=None, quality_columns=None):\n",
    "    \"\"\"\n",
    "    Calculate quality issue counts and optionally percentages compared to a reference dataset.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame containing the quality issues data\n",
    "        reference_df: Optional reference DataFrame to calculate percentages against\n",
    "        quality_columns: List of quality issue column names. If None, uses default columns\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with quality counts, and optionally percentages if reference_df is provided\n",
    "    \"\"\"\n",
    "    if quality_columns is None:\n",
    "        quality_columns = [\n",
    "            \"unrecognizable\",\n",
    "            \"blur\",\n",
    "            \"framing\",\n",
    "            \"obstruction\",\n",
    "            \"rotation\",\n",
    "            \"too dark\",\n",
    "            \"too bright\",\n",
    "            \"other\",\n",
    "        ]\n",
    "\n",
    "    # Calculate counts\n",
    "    quality_counts = pd.concat(\n",
    "        [df[col].value_counts() for col in quality_columns], axis=1\n",
    "    )\n",
    "    quality_counts.columns = quality_columns\n",
    "\n",
    "    # Replace NaN with 0 and convert to int\n",
    "    quality_counts = quality_counts.fillna(0).astype(int)\n",
    "\n",
    "    # sort index from 0 to 5\n",
    "    quality_counts = quality_counts.sort_index()\n",
    "\n",
    "    # Add total row\n",
    "    quality_counts.loc[\"total\"] = quality_counts.sum()\n",
    "\n",
    "    # Calculate percentages if reference DataFrame is provided\n",
    "    if reference_df is not None:\n",
    "        reference_counts = calculate_quality_metrics(\n",
    "            reference_df, quality_columns=quality_columns\n",
    "        )\n",
    "        quality_percentages = quality_counts.div(reference_counts, axis=0) * 100\n",
    "        return quality_percentages.round(2)\n",
    "\n",
    "    return quality_counts\n",
    "\n",
    "\n",
    "def combine_counts_and_percentages(counts_df, percentages_df=None):\n",
    "    \"\"\"\n",
    "    Combines counts and percentages into a single DataFrame with formatted strings.\n",
    "\n",
    "    Args:\n",
    "        counts_df: DataFrame containing the counts\n",
    "        percentages_df: Optional DataFrame containing percentages. If None, percentages\n",
    "                       will be calculated using the total row of counts_df\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with formatted strings combining counts and percentages\n",
    "    \"\"\"\n",
    "    # Calculate percentages if not provided\n",
    "    if percentages_df is None:\n",
    "        percentages_df = (counts_df.div(counts_df.loc[\"total\"], axis=1) * 100).round(2)\n",
    "\n",
    "    def format_count_and_percentage(count, percentage):\n",
    "        count_str = (\n",
    "            str(int(float(count))) if float(count).is_integer() else str(float(count))\n",
    "        )\n",
    "        return f\"{count_str} ({percentage:.2f}%)\"\n",
    "\n",
    "    # Create combined DataFrame\n",
    "    combined_stats = pd.DataFrame(\n",
    "        [\n",
    "            [\n",
    "                format_count_and_percentage(count, pct)\n",
    "                for count, pct in zip(row_counts, row_pcts)\n",
    "            ]\n",
    "            for row_counts, row_pcts in zip(counts_df.values, percentages_df.values)\n",
    "        ],\n",
    "        index=counts_df.index,\n",
    "        columns=counts_df.columns,\n",
    "    )\n",
    "\n",
    "    return combined_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = {\n",
    "    \"gpt-4o-2024-08-06\": \"gpt4o\",\n",
    "    \"Llama-3.2-11B-Vision-Instruct\": \"llama\",\n",
    "    \"Molmo-7B-O-0924\": \"molmo\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "We load 3 pieces of data:\n",
    "1. A `.json` file with all images that fit our study conditions, their model captions, and evaluation metrics.\n",
    "2. A `.csv` that has annotations from the research team noting what captions accurately identify products.\n",
    "3. A `.csv` with expert captions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) load images with model captions and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of evaluated captions: 5432\n",
      "{\n",
      "    \"image_id\": 1,\n",
      "    \"file_name\": \"VizWiz_train_00000001.jpg\",\n",
      "    \"vizwiz_url\": \"https://vizwiz.cs.colorado.edu/VizWiz_visualization_img/VizWiz_train_00000001.jpg\",\n",
      "    \"text_detected\": true,\n",
      "    \"unrecognizable\": 0,\n",
      "    \"framing\": 0,\n",
      "    \"blur\": 5,\n",
      "    \"obstruction\": 0,\n",
      "    \"rotation\": 0,\n",
      "    \"too dark\": 0,\n",
      "    \"too bright\": 0,\n",
      "    \"other\": 0,\n",
      "    \"no issue\": 0,\n",
      "    \"human_captions\": [\n",
      "        {\n",
      "            \"caption\": \"A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.\",\n",
      "            \"is_precanned\": false,\n",
      "            \"is_rejected\": false\n",
      "        },\n",
      "        {\n",
      "            \"caption\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\",\n",
      "            \"is_precanned\": false,\n",
      "            \"is_rejected\": false\n",
      "        },\n",
      "        {\n",
      "            \"caption\": \"A kitchen counter the various items on top including a can of Coca-Cola, metal containers, and a teapot.\",\n",
      "            \"is_precanned\": false,\n",
      "            \"is_rejected\": false\n",
      "        },\n",
      "        {\n",
      "            \"caption\": \"a black tin of Coca Cola placed on a black surface\",\n",
      "            \"is_precanned\": false,\n",
      "            \"is_rejected\": false\n",
      "        },\n",
      "        {\n",
      "            \"caption\": \"Black counter with canisters, kettle and can of soda.\",\n",
      "            \"is_precanned\": false,\n",
      "            \"is_rejected\": false\n",
      "        }\n",
      "    ],\n",
      "    \"model_captions\": [\n",
      "        {\n",
      "            \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "            \"caption\": \"A can of Coca-Cola Zero is on a kitchen countertop, next to a white mug and a black kettle. Three silver canisters are aligned against the wall, along with a visible electrical outlet above them.\"\n",
      "        },\n",
      "        {\n",
      "            \"model_name\": \"Llama-3.2-11B-Vision-Instruct\",\n",
      "            \"caption\": \"The image shows a black can with a yellow band and red writing, likely a beverage can, on a kitchen counter. The can has a white label with indistinct writing.\"\n",
      "        },\n",
      "        {\n",
      "            \"model_name\": \"Molmo-7B-O-0924\",\n",
      "            \"caption\": \"A black and yellow can of Coca-Cola is prominently displayed on a black countertop. The can features the Coca-Cola logo in red and white text.\"\n",
      "        }\n",
      "    ],\n",
      "    \"evaluation\": {\n",
      "        \"bleu-1\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"bleu\": 0.48717948717948717,\n",
      "                \"precisions\": [\n",
      "                    0.48717948717948717\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 3.5454545454545454,\n",
      "                \"translation_length\": 39,\n",
      "                \"reference_length\": 11\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"bleu\": 0.38235294117647056,\n",
      "                \"precisions\": [\n",
      "                    0.38235294117647056\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 3.090909090909091,\n",
      "                \"translation_length\": 34,\n",
      "                \"reference_length\": 11\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"bleu\": 0.48148148148148145,\n",
      "                \"precisions\": [\n",
      "                    0.48148148148148145\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 2.4545454545454546,\n",
      "                \"translation_length\": 27,\n",
      "                \"reference_length\": 11\n",
      "            }\n",
      "        },\n",
      "        \"bleu-2\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"bleu\": 0.29957234475763905,\n",
      "                \"precisions\": [\n",
      "                    0.48717948717948717,\n",
      "                    0.18421052631578946\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 3.5454545454545454,\n",
      "                \"translation_length\": 39,\n",
      "                \"reference_length\": 11\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"bleu\": 0.21528077260102307,\n",
      "                \"precisions\": [\n",
      "                    0.38235294117647056,\n",
      "                    0.12121212121212122\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 3.090909090909091,\n",
      "                \"translation_length\": 34,\n",
      "                \"reference_length\": 11\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"bleu\": 0.3042903097250923,\n",
      "                \"precisions\": [\n",
      "                    0.48148148148148145,\n",
      "                    0.19230769230769232\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 2.4545454545454546,\n",
      "                \"translation_length\": 27,\n",
      "                \"reference_length\": 11\n",
      "            }\n",
      "        },\n",
      "        \"bleu-3\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"bleu\": 0.16928191745772345,\n",
      "                \"precisions\": [\n",
      "                    0.48717948717948717,\n",
      "                    0.18421052631578946,\n",
      "                    0.05405405405405406\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 3.5454545454545454,\n",
      "                \"translation_length\": 39,\n",
      "                \"reference_length\": 11\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"bleu\": 0.0,\n",
      "                \"precisions\": [\n",
      "                    0.38235294117647056,\n",
      "                    0.12121212121212122,\n",
      "                    0.0\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 3.090909090909091,\n",
      "                \"translation_length\": 34,\n",
      "                \"reference_length\": 11\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"bleu\": 0.19493451588085775,\n",
      "                \"precisions\": [\n",
      "                    0.48148148148148145,\n",
      "                    0.19230769230769232,\n",
      "                    0.08\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 2.4545454545454546,\n",
      "                \"translation_length\": 27,\n",
      "                \"reference_length\": 11\n",
      "            }\n",
      "        },\n",
      "        \"bleu-4\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"bleu\": 0.0,\n",
      "                \"precisions\": [\n",
      "                    0.48717948717948717,\n",
      "                    0.18421052631578946,\n",
      "                    0.05405405405405406,\n",
      "                    0.0\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 3.5454545454545454,\n",
      "                \"translation_length\": 39,\n",
      "                \"reference_length\": 11\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"bleu\": 0.0,\n",
      "                \"precisions\": [\n",
      "                    0.38235294117647056,\n",
      "                    0.12121212121212122,\n",
      "                    0.0,\n",
      "                    0.0\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 3.090909090909091,\n",
      "                \"translation_length\": 34,\n",
      "                \"reference_length\": 11\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"bleu\": 0.0,\n",
      "                \"precisions\": [\n",
      "                    0.48148148148148145,\n",
      "                    0.19230769230769232,\n",
      "                    0.08,\n",
      "                    0.0\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 2.4545454545454546,\n",
      "                \"translation_length\": 27,\n",
      "                \"reference_length\": 11\n",
      "            }\n",
      "        },\n",
      "        \"meteor\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"meteor\": 0.42315262122025415\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"meteor\": 0.33087319382162433\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"meteor\": 0.503725299643667\n",
      "            }\n",
      "        },\n",
      "        \"rouge\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"rouge1\": 0.4000000000000001,\n",
      "                \"rouge2\": 0.23529411764705876,\n",
      "                \"rougeL\": 0.33962264150943394,\n",
      "                \"rougeLsum\": 0.33962264150943394\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"rouge1\": 0.3673469387755102,\n",
      "                \"rouge2\": 0.1276595744680851,\n",
      "                \"rougeL\": 0.2857142857142857,\n",
      "                \"rougeLsum\": 0.2857142857142857\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"rouge1\": 0.45454545454545453,\n",
      "                \"rouge2\": 0.2777777777777778,\n",
      "                \"rougeL\": 0.45454545454545453,\n",
      "                \"rougeLsum\": 0.45454545454545453\n",
      "            }\n",
      "        },\n",
      "        \"cider\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"score\": 0.0037823278003754957\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"score\": 0.033202632588137\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"score\": 0.0910111360233031\n",
      "            }\n",
      "        },\n",
      "        \"spice\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"All\": {\n",
      "                    \"pr\": 0.13636363636363635,\n",
      "                    \"re\": 0.07692307692307693,\n",
      "                    \"f\": 0.09836065573770493,\n",
      "                    \"fn\": 36.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 19.0,\n",
      "                    \"tp\": 3.0\n",
      "                },\n",
      "                \"Relation\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 13.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 5.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Cardinality\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 1.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Attribute\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 13.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 8.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Size\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Color\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 3.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 2.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Object\": {\n",
      "                    \"pr\": 0.3333333333333333,\n",
      "                    \"re\": 0.23076923076923078,\n",
      "                    \"f\": 0.27272727272727276,\n",
      "                    \"fn\": 10.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 6.0,\n",
      "                    \"tp\": 3.0\n",
      "                }\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"All\": {\n",
      "                    \"pr\": 0.2222222222222222,\n",
      "                    \"re\": 0.10256410256410256,\n",
      "                    \"f\": 0.14035087719298245,\n",
      "                    \"fn\": 35.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 14.0,\n",
      "                    \"tp\": 4.0\n",
      "                },\n",
      "                \"Relation\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 13.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 6.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Cardinality\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Attribute\": {\n",
      "                    \"pr\": 0.2,\n",
      "                    \"re\": 0.07692307692307693,\n",
      "                    \"f\": 0.1111111111111111,\n",
      "                    \"fn\": 12.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 4.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Size\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Color\": {\n",
      "                    \"pr\": 0.25,\n",
      "                    \"re\": 0.3333333333333333,\n",
      "                    \"f\": 0.28571428571428575,\n",
      "                    \"fn\": 2.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 3.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Object\": {\n",
      "                    \"pr\": 0.42857142857142855,\n",
      "                    \"re\": 0.23076923076923078,\n",
      "                    \"f\": 0.3,\n",
      "                    \"fn\": 10.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 4.0,\n",
      "                    \"tp\": 3.0\n",
      "                }\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"All\": {\n",
      "                    \"pr\": 0.14285714285714285,\n",
      "                    \"re\": 0.05128205128205128,\n",
      "                    \"f\": 0.07547169811320754,\n",
      "                    \"fn\": 37.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 12.0,\n",
      "                    \"tp\": 2.0\n",
      "                },\n",
      "                \"Relation\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 13.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 3.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Cardinality\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Attribute\": {\n",
      "                    \"pr\": 0.16666666666666666,\n",
      "                    \"re\": 0.07692307692307693,\n",
      "                    \"f\": 0.10526315789473684,\n",
      "                    \"fn\": 12.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 5.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Size\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Color\": {\n",
      "                    \"pr\": 0.2,\n",
      "                    \"re\": 0.3333333333333333,\n",
      "                    \"f\": 0.25,\n",
      "                    \"fn\": 2.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 4.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Object\": {\n",
      "                    \"pr\": 0.2,\n",
      "                    \"re\": 0.07692307692307693,\n",
      "                    \"f\": 0.1111111111111111,\n",
      "                    \"fn\": 12.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 4.0,\n",
      "                    \"tp\": 1.0\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"bertscore\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"precision\": 0.6953459978103638,\n",
      "                \"recall\": 0.800594687461853,\n",
      "                \"f1\": 0.7392169237136841,\n",
      "                \"best_ref_indices\": [\n",
      "                    1,\n",
      "                    4,\n",
      "                    1\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\",\n",
      "                    \"recall_reference\": \"Black counter with canisters, kettle and can of soda.\",\n",
      "                    \"f1_reference\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\"\n",
      "                }\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"precision\": 0.5674580931663513,\n",
      "                \"recall\": 0.6933881044387817,\n",
      "                \"f1\": 0.6142570972442627,\n",
      "                \"best_ref_indices\": [\n",
      "                    1,\n",
      "                    3,\n",
      "                    1\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\",\n",
      "                    \"recall_reference\": \"a black tin of Coca Cola placed on a black surface\",\n",
      "                    \"f1_reference\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\"\n",
      "                }\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"precision\": 0.680425226688385,\n",
      "                \"recall\": 0.796323299407959,\n",
      "                \"f1\": 0.7177727818489075,\n",
      "                \"best_ref_indices\": [\n",
      "                    1,\n",
      "                    3,\n",
      "                    3\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\",\n",
      "                    \"recall_reference\": \"a black tin of Coca Cola placed on a black surface\",\n",
      "                    \"f1_reference\": \"a black tin of Coca Cola placed on a black surface\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"clipscore\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"score\": 0.86474609375\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"score\": 0.75\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"score\": 0.7216796875\n",
      "            }\n",
      "        },\n",
      "        \"clipscore_ref\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"score\": 0.81640625\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"score\": 0.73828125\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"score\": 0.71142578125\n",
      "            }\n",
      "        },\n",
      "        \"cap_f1\": {\n",
      "            \"parsed_atomics\": [\n",
      "                \"There is a can of Coca Cola.\",\n",
      "                \"The can is on a counter.\",\n",
      "                \"There is a can on the counter.\",\n",
      "                \"The can is black.\",\n",
      "                \"The can is of Coca Cola Zero calorie soda.\",\n",
      "                \"The can is near the coffee maker.\",\n",
      "                \"There is a kitchen counter.\",\n",
      "                \"There are various items on the kitchen counter.\",\n",
      "                \"There is a can of Coca-Cola on the kitchen counter.\",\n",
      "                \"There are metal containers on the kitchen counter.\",\n",
      "                \"There is a teapot on the kitchen counter.\",\n",
      "                \"There is a tin.\",\n",
      "                \"The tin is black.\",\n",
      "                \"The tin is of Coca Cola.\",\n",
      "                \"The tin is placed on a surface.\",\n",
      "                \"The surface is black.\",\n",
      "                \"There is a black counter.\",\n",
      "                \"There are canisters on the counter.\",\n",
      "                \"There is a kettle on the counter.\",\n",
      "                \"There is a can of soda on the counter.\"\n",
      "            ],\n",
      "            \"T_atomics\": [\n",
      "                \"There is a can of Coca Cola.\",\n",
      "                \"The can is on a counter.\",\n",
      "                \"The can is black.\",\n",
      "                \"The can is of Coca Cola Zero calorie soda.\",\n",
      "                \"The can is near the coffee maker.\",\n",
      "                \"There is a kitchen counter.\",\n",
      "                \"There are various items on the kitchen counter.\",\n",
      "                \"There are metal containers on the kitchen counter.\",\n",
      "                \"There is a teapot on the kitchen counter.\",\n",
      "                \"There is a black counter.\",\n",
      "                \"There are canisters on the counter.\",\n",
      "                \"There is a kettle on the counter.\"\n",
      "            ],\n",
      "            \"g_atomics\": {\n",
      "                \"gpt-4o-2024-08-06\": [\n",
      "                    \"There is a can of Coca-Cola Zero.\",\n",
      "                    \"The can is on a kitchen countertop.\",\n",
      "                    \"There is a white mug next to the can.\",\n",
      "                    \"There is a black kettle next to the can.\",\n",
      "                    \"There are three silver canisters.\",\n",
      "                    \"The canisters are aligned against the wall.\",\n",
      "                    \"There is an electrical outlet above the canisters.\"\n",
      "                ],\n",
      "                \"Llama-3.2-11B-Vision-Instruct\": [\n",
      "                    \"There is a can.\",\n",
      "                    \"The can is black.\",\n",
      "                    \"The can has a yellow band.\",\n",
      "                    \"The can has red writing.\",\n",
      "                    \"The can is likely a beverage can.\",\n",
      "                    \"The can is on a kitchen counter.\",\n",
      "                    \"The can has a white label.\",\n",
      "                    \"The label has indistinct writing.\"\n",
      "                ],\n",
      "                \"Molmo-7B-O-0924\": [\n",
      "                    \"There is a can of Coca-Cola.\",\n",
      "                    \"The can is black and yellow.\",\n",
      "                    \"The can is on a black countertop.\",\n",
      "                    \"The can has the Coca-Cola logo.\",\n",
      "                    \"The logo is in red text.\",\n",
      "                    \"The logo is in white text.\"\n",
      "                ]\n",
      "            },\n",
      "            \"T_org\": [\n",
      "                \"A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.\",\n",
      "                \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\",\n",
      "                \"A kitchen counter the various items on top including a can of Coca-Cola, metal containers, and a teapot.\",\n",
      "                \"a black tin of Coca Cola placed on a black surface\",\n",
      "                \"Black counter with canisters, kettle and can of soda.\"\n",
      "            ],\n",
      "            \"metadata\": {\n",
      "                \"gpt-4o-2024-08-06\": {\n",
      "                    \"recall\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a can of Coca Cola.\",\n",
      "                            \"The can is on a counter.\",\n",
      "                            \"The can is of Coca Cola Zero calorie soda.\",\n",
      "                            \"There are various items on the kitchen counter.\",\n",
      "                            \"There are metal containers on the kitchen counter.\",\n",
      "                            \"There are canisters on the counter.\",\n",
      "                            \"There is a kettle on the counter.\"\n",
      "                        ],\n",
      "                        \"FNs\": [\n",
      "                            \"The can is black.\",\n",
      "                            \"The can is near the coffee maker.\",\n",
      "                            \"There is a kitchen counter.\",\n",
      "                            \"There is a teapot on the kitchen counter.\",\n",
      "                            \"There is a black counter.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a can of Coca Cola.\",\n",
      "                                \"g_atomic\": \"There is a can of Coca-Cola Zero.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The can is on a counter.\",\n",
      "                                \"g_atomic\": \"The can is on a kitchen countertop.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The can is of Coca Cola Zero calorie soda.\",\n",
      "                                \"g_atomic\": \"There is a can of Coca-Cola Zero.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"There are various items on the kitchen counter.\",\n",
      "                                \"g_atomic\": \"There is a white mug next to the can.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"There are metal containers on the kitchen counter.\",\n",
      "                                \"g_atomic\": \"There are three silver canisters.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"There are canisters on the counter.\",\n",
      "                                \"g_atomic\": \"There are three silver canisters.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a kettle on the counter.\",\n",
      "                                \"g_atomic\": \"There is a black kettle next to the can.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 7,\n",
      "                            \"FN\": 5\n",
      "                        }\n",
      "                    },\n",
      "                    \"precision\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a can of Coca-Cola Zero.\",\n",
      "                            \"The can is on a kitchen countertop.\"\n",
      "                        ],\n",
      "                        \"FPs\": [\n",
      "                            \"There is a white mug next to the can.\",\n",
      "                            \"There is a black kettle next to the can.\",\n",
      "                            \"There are three silver canisters.\",\n",
      "                            \"The canisters are aligned against the wall.\",\n",
      "                            \"There is an electrical outlet above the canisters.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"g_atomic\": \"There is a can of Coca-Cola Zero.\",\n",
      "                                \"T_org\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The can is on a kitchen countertop.\",\n",
      "                                \"T_org\": \"A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 2,\n",
      "                            \"FP\": 5\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                    \"recall\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a can of Coca Cola.\",\n",
      "                            \"The can is on a counter.\",\n",
      "                            \"The can is black.\",\n",
      "                            \"There is a kitchen counter.\"\n",
      "                        ],\n",
      "                        \"FNs\": [\n",
      "                            \"The can is of Coca Cola Zero calorie soda.\",\n",
      "                            \"The can is near the coffee maker.\",\n",
      "                            \"There are various items on the kitchen counter.\",\n",
      "                            \"There are metal containers on the kitchen counter.\",\n",
      "                            \"There is a teapot on the kitchen counter.\",\n",
      "                            \"There is a black counter.\",\n",
      "                            \"There are canisters on the counter.\",\n",
      "                            \"There is a kettle on the counter.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a can of Coca Cola.\",\n",
      "                                \"g_atomic\": \"The can is likely a beverage can.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The can is on a counter.\",\n",
      "                                \"g_atomic\": \"The can is on a kitchen counter.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The can is black.\",\n",
      "                                \"g_atomic\": \"The can is black.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a kitchen counter.\",\n",
      "                                \"g_atomic\": \"The can is on a kitchen counter.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 4,\n",
      "                            \"FN\": 8\n",
      "                        }\n",
      "                    },\n",
      "                    \"precision\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a can.\",\n",
      "                            \"The can is black.\",\n",
      "                            \"The can is likely a beverage can.\",\n",
      "                            \"The can is on a kitchen counter.\"\n",
      "                        ],\n",
      "                        \"FPs\": [\n",
      "                            \"The can has a yellow band.\",\n",
      "                            \"The can has red writing.\",\n",
      "                            \"The can has a white label.\",\n",
      "                            \"The label has indistinct writing.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"g_atomic\": \"There is a can.\",\n",
      "                                \"T_org\": \"A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The can is black.\",\n",
      "                                \"T_org\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The can is likely a beverage can.\",\n",
      "                                \"T_org\": \"A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The can is on a kitchen counter.\",\n",
      "                                \"T_org\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 4,\n",
      "                            \"FP\": 4\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"Molmo-7B-O-0924\": {\n",
      "                    \"recall\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a can of Coca Cola.\",\n",
      "                            \"The can is on a counter.\",\n",
      "                            \"The can is black.\",\n",
      "                            \"There is a black counter.\"\n",
      "                        ],\n",
      "                        \"FNs\": [\n",
      "                            \"The can is of Coca Cola Zero calorie soda.\",\n",
      "                            \"The can is near the coffee maker.\",\n",
      "                            \"There is a kitchen counter.\",\n",
      "                            \"There are various items on the kitchen counter.\",\n",
      "                            \"There are metal containers on the kitchen counter.\",\n",
      "                            \"There is a teapot on the kitchen counter.\",\n",
      "                            \"There are canisters on the counter.\",\n",
      "                            \"There is a kettle on the counter.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a can of Coca Cola.\",\n",
      "                                \"g_atomic\": \"There is a can of Coca-Cola.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The can is on a counter.\",\n",
      "                                \"g_atomic\": \"The can is on a black countertop.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The can is black.\",\n",
      "                                \"g_atomic\": \"The can is black and yellow.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a black counter.\",\n",
      "                                \"g_atomic\": \"The can is on a black countertop.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 4,\n",
      "                            \"FN\": 8\n",
      "                        }\n",
      "                    },\n",
      "                    \"precision\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a can of Coca-Cola.\",\n",
      "                            \"The can is on a black countertop.\",\n",
      "                            \"The can has the Coca-Cola logo.\"\n",
      "                        ],\n",
      "                        \"FPs\": [\n",
      "                            \"The can is black and yellow.\",\n",
      "                            \"The logo is in red text.\",\n",
      "                            \"The logo is in white text.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"g_atomic\": \"There is a can of Coca-Cola.\",\n",
      "                                \"T_org\": \"A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The can is on a black countertop.\",\n",
      "                                \"T_org\": \"a black tin of Coca Cola placed on a black surface\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The can has the Coca-Cola logo.\",\n",
      "                                \"T_org\": \"A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 3,\n",
      "                            \"FP\": 3\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            \"scores\": {\n",
      "                \"gpt-4o-2024-08-06\": {\n",
      "                    \"recall\": 0.5833333333333334,\n",
      "                    \"precision\": 0.2857142857142857,\n",
      "                    \"cap_f1\": 0.3835616438356164\n",
      "                },\n",
      "                \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                    \"recall\": 0.3333333333333333,\n",
      "                    \"precision\": 0.5,\n",
      "                    \"cap_f1\": 0.4\n",
      "                },\n",
      "                \"Molmo-7B-O-0924\": {\n",
      "                    \"recall\": 0.3333333333333333,\n",
      "                    \"precision\": 0.5,\n",
      "                    \"cap_f1\": 0.4\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"human_caption_similarity\": {\n",
      "        \"sentences\": [\n",
      "            \"A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.\",\n",
      "            \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\",\n",
      "            \"A kitchen counter the various items on top including a can of Coca-Cola, metal containers, and a teapot.\",\n",
      "            \"a black tin of Coca Cola placed on a black surface\",\n",
      "            \"Black counter with canisters, kettle and can of soda.\"\n",
      "        ],\n",
      "        \"similarities\": [\n",
      "            0.32641178369522095,\n",
      "            0.42414015531539917,\n",
      "            0.4487512707710266,\n",
      "            0.39667344093322754,\n",
      "            0.46702706813812256,\n",
      "            0.3708420991897583,\n",
      "            0.3800613284111023,\n",
      "            0.6190057992935181,\n",
      "            0.23785948753356934,\n",
      "            0.5282124280929565\n",
      "        ],\n",
      "        \"pairwise_distances\": [\n",
      "            [\n",
      "                0.0,\n",
      "                0.32641178369522095,\n",
      "                0.42414015531539917,\n",
      "                0.4487512707710266,\n",
      "                0.39667344093322754\n",
      "            ],\n",
      "            [\n",
      "                0.32641178369522095,\n",
      "                0.0,\n",
      "                0.46702706813812256,\n",
      "                0.3708420991897583,\n",
      "                0.3800613284111023\n",
      "            ],\n",
      "            [\n",
      "                0.42414015531539917,\n",
      "                0.46702706813812256,\n",
      "                0.0,\n",
      "                0.6190057992935181,\n",
      "                0.23785948753356934\n",
      "            ],\n",
      "            [\n",
      "                0.4487512707710266,\n",
      "                0.3708420991897583,\n",
      "                0.6190057992935181,\n",
      "                0.0,\n",
      "                0.5282124280929565\n",
      "            ],\n",
      "            [\n",
      "                0.39667344093322754,\n",
      "                0.3800613284111023,\n",
      "                0.23785948753356934,\n",
      "                0.5282124280929565,\n",
      "                0.0\n",
      "            ]\n",
      "        ],\n",
      "        \"min_similarity\": 0.23785948753356934,\n",
      "        \"max_similarity\": 0.6190057992935181,\n",
      "        \"mean_similarity\": 0.41989845037460327,\n",
      "        \"std_similarity\": 0.10042813420295715,\n",
      "        \"variance_similarity\": 0.010085809975862503\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "evaluated_captions_data = json.load(\n",
    "    open(\n",
    "        \"../../data/study-2-output/final-evaluated-captions/low-quality_evaluation_5432-images_2025-04-11_03-31_merged.json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Length of evaluated captions: {len(evaluated_captions_data)}\")\n",
    "print(json.dumps(evaluated_captions_data[0], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>too bright</th>\n",
       "      <th>other</th>\n",
       "      <th>no issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>VizWiz_train_00000001.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>VizWiz_train_00000008.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>VizWiz_train_00000011.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>VizWiz_train_00000020.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>VizWiz_train_00000026.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                  file_name                                         vizwiz_url  text_detected  unrecognizable  framing  blur  obstruction  rotation  too dark  too bright  other  no issue\n",
       "0         1  VizWiz_train_00000001.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0        0     5            0         0         0           0      0         0\n",
       "1         8  VizWiz_train_00000008.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0        4     0            0         0         0           0      0         1\n",
       "2        11  VizWiz_train_00000011.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0        2     2            4         1         1           1      0         0\n",
       "3        20  VizWiz_train_00000020.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0        4     0            1         0         0           0      0         0\n",
       "4        26  VizWiz_train_00000026.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0        0     4            0         0         0           0      0         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe with only the data we need for the regression\n",
    "target_keys = [\n",
    "    \"image_id\",\n",
    "    \"file_name\",\n",
    "    \"vizwiz_url\",\n",
    "    \"text_detected\",\n",
    "    \"unrecognizable\",\n",
    "    \"framing\",\n",
    "    \"blur\",\n",
    "    \"obstruction\",\n",
    "    \"rotation\",\n",
    "    \"too dark\",\n",
    "    \"too bright\",\n",
    "    \"other\",\n",
    "    \"no issue\",\n",
    "]\n",
    "evaluation_data_regression = [\n",
    "    {x: y for x, y in image.items() if x in target_keys}\n",
    "    for image in evaluated_captions_data\n",
    "]\n",
    "filtered_evaluation_data_df = pd.DataFrame.from_dict(evaluation_data_regression)\n",
    "filtered_evaluation_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) load annotations from research team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotated images: 1696\n",
      "Number of images that were verified: 1220\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>image_preview</th>\n",
       "      <th>human_captions</th>\n",
       "      <th>annotator</th>\n",
       "      <th>notes</th>\n",
       "      <th>unable_to_verify</th>\n",
       "      <th>double code notes</th>\n",
       "      <th>double verified</th>\n",
       "      <th>gpt4o_caption</th>\n",
       "      <th>gpt4o_code</th>\n",
       "      <th>llama_caption</th>\n",
       "      <th>llama_code</th>\n",
       "      <th>molmo_caption</th>\n",
       "      <th>molmo_code</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>too bright</th>\n",
       "      <th>other</th>\n",
       "      <th>curved label</th>\n",
       "      <th>text panel</th>\n",
       "      <th>expert_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9886</td>\n",
       "      <td>VizWiz_train_00009886.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A box of frozen food sits on a table top that ...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>trade joes paneer tikka masala</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A package of Trader Joe's Paneer Tikka Masala ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a frozen food package with a g...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a food package for a Tikka Mas...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12066</td>\n",
       "      <td>VizWiz_train_00012066.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A Kroger grocery store tag for a caramel iced ...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>kroger iced carmel cake</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A caramel iced cake with a label featuring the...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a white label with the blue an...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a plastic container of apple c...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1908</td>\n",
       "      <td>VizWiz_train_00001908.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A description on a box of herbal tea.\\nA print...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>caffeine free herb tea</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A label with the text \"A delicious CAFFEINE FR...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a white box with the words \"A ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a sideways view of a product l...</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15399</td>\n",
       "      <td>VizWiz_train_00015399.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A green and white box of Lean Pockets frozen r...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>lean pocket garlic chicken white pizza</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>Box of Lean Pockets with garlic chicken white ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a green and white box of Lean ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a box of Lean Pockets on a whi...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4380</td>\n",
       "      <td>VizWiz_train_00004380.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>garlic spinach hummus possibly in a green cont...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>garlic spinach hummus</td>\n",
       "      <td></td>\n",
       "      <td>garlic spinach hummus</td>\n",
       "      <td>x</td>\n",
       "      <td>A plastic container with a green lid, featurin...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a plastic container with a gre...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a plastic food container on a ...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                  file_name                                         vizwiz_url image_preview                                     human_captions   annotator                                   notes unable_to_verify      double code notes double verified                                      gpt4o_caption gpt4o_code                                      llama_caption llama_code                                      molmo_caption molmo_code  text_detected  unrecognizable  framing  blur  obstruction  rotation  too dark  too bright  other curved label text panel expert_caption\n",
       "0      9886  VizWiz_train_00009886.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A box of frozen food sits on a table top that ...  Anne Marie          trade joes paneer tikka masala                                                       x  A package of Trader Joe's Paneer Tikka Masala ...        yes  The image shows a frozen food package with a g...        yes  The image shows a food package for a Tikka Mas...         no           True               0        1     2            0         4         0           1      0                                       \n",
       "1     12066  VizWiz_train_00012066.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A Kroger grocery store tag for a caramel iced ...  Anne Marie                 kroger iced carmel cake                                                       x  A caramel iced cake with a label featuring the...        yes  The image shows a white label with the blue an...         no  The image shows a plastic container of apple c...         no           True               0        4     2            0         1         0           0      0                                       \n",
       "2      1908  VizWiz_train_00001908.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A description on a box of herbal tea.\\nA print...  Anne Marie                  caffeine free herb tea                                                       x  A label with the text \"A delicious CAFFEINE FR...        yes  The image shows a white box with the words \"A ...        yes  The image shows a sideways view of a product l...        yes           True               0        2     4            0         3         0           0      0                                       \n",
       "3     15399  VizWiz_train_00015399.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A green and white box of Lean Pockets frozen r...  Anne Marie  lean pocket garlic chicken white pizza                                                       x  Box of Lean Pockets with garlic chicken white ...        yes  The image shows a green and white box of Lean ...        yes  The image shows a box of Lean Pockets on a whi...         no           True               0        4     0            0         3         0           0      0                                       \n",
       "4      4380  VizWiz_train_00004380.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                garlic spinach hummus possibly in a green cont...  Anne Marie                   garlic spinach hummus                   garlic spinach hummus               x  A plastic container with a green lid, featurin...         no  The image shows a plastic container with a gre...         no  The image shows a plastic food container on a ...         no           True               0        5     0            0         3         0           0      0                                       "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_images_dtypes = {\n",
    "    \"image_id\": int,\n",
    "    \"file_name\": str,\n",
    "    \"vizwiz_url\": str,\n",
    "    \"image_preview\": str,\n",
    "    \"INCLUDE because product\": str,\n",
    "    \"EXCLUDE because not verifable\": str,\n",
    "    \"EXCLUDE because Book/DVD/CD/magazine?\": str,\n",
    "    \"text_detected\": bool,\n",
    "    \"unrecognizable\": int,\n",
    "    \"framing\": int,\n",
    "    \"blur\": int,\n",
    "    \"obstruction\": int,\n",
    "    \"rotation\": int,\n",
    "    \"too dark\": int,\n",
    "    \"too bright\": int,\n",
    "    \"other\": int,\n",
    "    \"no issue\": int,\n",
    "    \"human_caption_0\": str,\n",
    "    \"human_caption_1\": str,\n",
    "    \"human_caption_2\": str,\n",
    "    \"human_caption_3\": str,\n",
    "    \"human_caption_4\": str,\n",
    "    \"gpt-4o-2024-08-06_caption\": str,\n",
    "    \"Llama-3.2-11B-Vision-Instruct_caption\": str,\n",
    "    \"Molmo-7B-O-0924_caption\": str,\n",
    "    \"general_notes\": str,\n",
    "    \"gpt-4o-2024-08-06_notes\": str,\n",
    "    \"Llama-3.2-11B-Vision-Instruct_notes\": str,\n",
    "    \"Molmo-7B-O-0924_notes\": str,\n",
    "    \"image_preview\": str,\n",
    "    \"unable_to_verify\": str,\n",
    "    \"gpt4o_code\": str,\n",
    "    \"llama_code\": str,\n",
    "    \"molmo_code\": str,\n",
    "    \"notes\": str,\n",
    "    \"double code notes\": str,\n",
    "    \"double verified\": str,\n",
    "}\n",
    "\n",
    "annotations_df = pd.read_csv(\n",
    "    \"./annotated-data/final-annotated-images_1696-images_2025-04-14_03-41.csv\",\n",
    "    dtype=target_images_dtypes,\n",
    "    keep_default_na=False,\n",
    ")\n",
    "\n",
    "print(f\"Number of annotated images: {len(annotations_df)}\")\n",
    "print(\n",
    "    f\"Number of images that were verified: {len(annotations_df[annotations_df['unable_to_verify'] == ''])}\"\n",
    ")\n",
    "annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>blur</th>\n",
       "      <th>framing</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>too bright</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003 (82.21%)</td>\n",
       "      <td>346 (28.36%)</td>\n",
       "      <td>190 (15.57%)</td>\n",
       "      <td>1098 (90.00%)</td>\n",
       "      <td>620 (50.82%)</td>\n",
       "      <td>1051 (86.15%)</td>\n",
       "      <td>1034 (84.75%)</td>\n",
       "      <td>1162 (95.25%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217 (17.79%)</td>\n",
       "      <td>186 (15.25%)</td>\n",
       "      <td>150 (12.30%)</td>\n",
       "      <td>95 (7.79%)</td>\n",
       "      <td>124 (10.16%)</td>\n",
       "      <td>144 (11.80%)</td>\n",
       "      <td>142 (11.64%)</td>\n",
       "      <td>57 (4.67%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 (0.00%)</td>\n",
       "      <td>107 (8.77%)</td>\n",
       "      <td>142 (11.64%)</td>\n",
       "      <td>8 (0.66%)</td>\n",
       "      <td>93 (7.62%)</td>\n",
       "      <td>18 (1.48%)</td>\n",
       "      <td>27 (2.21%)</td>\n",
       "      <td>1 (0.08%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 (0.00%)</td>\n",
       "      <td>80 (6.56%)</td>\n",
       "      <td>144 (11.80%)</td>\n",
       "      <td>4 (0.33%)</td>\n",
       "      <td>82 (6.72%)</td>\n",
       "      <td>3 (0.25%)</td>\n",
       "      <td>9 (0.74%)</td>\n",
       "      <td>0 (0.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 (0.00%)</td>\n",
       "      <td>300 (24.59%)</td>\n",
       "      <td>416 (34.10%)</td>\n",
       "      <td>11 (0.90%)</td>\n",
       "      <td>237 (19.43%)</td>\n",
       "      <td>3 (0.25%)</td>\n",
       "      <td>5 (0.41%)</td>\n",
       "      <td>0 (0.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0 (0.00%)</td>\n",
       "      <td>201 (16.48%)</td>\n",
       "      <td>178 (14.59%)</td>\n",
       "      <td>4 (0.33%)</td>\n",
       "      <td>64 (5.25%)</td>\n",
       "      <td>1 (0.08%)</td>\n",
       "      <td>3 (0.25%)</td>\n",
       "      <td>0 (0.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       unrecognizable            blur         framing     obstruction        rotation        too dark      too bright           other\n",
       "0       1003 (82.21%)    346 (28.36%)    190 (15.57%)   1098 (90.00%)    620 (50.82%)   1051 (86.15%)   1034 (84.75%)   1162 (95.25%)\n",
       "1        217 (17.79%)    186 (15.25%)    150 (12.30%)      95 (7.79%)    124 (10.16%)    144 (11.80%)    142 (11.64%)      57 (4.67%)\n",
       "2           0 (0.00%)     107 (8.77%)    142 (11.64%)       8 (0.66%)      93 (7.62%)      18 (1.48%)      27 (2.21%)       1 (0.08%)\n",
       "3           0 (0.00%)      80 (6.56%)    144 (11.80%)       4 (0.33%)      82 (6.72%)       3 (0.25%)       9 (0.74%)       0 (0.00%)\n",
       "4           0 (0.00%)    300 (24.59%)    416 (34.10%)      11 (0.90%)    237 (19.43%)       3 (0.25%)       5 (0.41%)       0 (0.00%)\n",
       "5           0 (0.00%)    201 (16.48%)    178 (14.59%)       4 (0.33%)      64 (5.25%)       1 (0.08%)       3 (0.25%)       0 (0.00%)\n",
       "total  1220 (100.00%)  1220 (100.00%)  1220 (100.00%)  1220 (100.00%)  1220 (100.00%)  1220 (100.00%)  1220 (100.00%)  1220 (100.00%)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_counts_and_percentages(\n",
    "    calculate_quality_metrics(annotations_df[annotations_df[\"unable_to_verify\"] == \"\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing step for combining annotation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the expert caption data and combine with the above\n",
    "# curr_annotations_df = pd.read_csv(\n",
    "#     \"./intermediate-data/annotated-images_04-14-25-00:00.csv\",\n",
    "#     dtype=target_images_dtypes,\n",
    "#     keep_default_na=False,\n",
    "# )\n",
    "# expert_caption_annotated_df = pd.read_csv(\n",
    "#     \"./intermediate-data/expert-annotated-images_04-14-25-00:00.csv\",\n",
    "#     dtype=target_images_dtypes,\n",
    "#     keep_default_na=False,\n",
    "# )\n",
    "# print(f\"Length of curr annotations: {len(curr_annotations_df)}\")\n",
    "# print(f\"Length of expert annotations: {len(expert_caption_annotated_df)}\")\n",
    "\n",
    "# # merge expert_caption_annotated with filtered_evaluation_data_df\n",
    "# expert_caption_annotated_df = pd.merge(\n",
    "#     filtered_evaluation_data_df,\n",
    "#     expert_caption_annotated_df,\n",
    "#     on=[\"image_id\", \"file_name\", \"vizwiz_url\"],\n",
    "#     how=\"right\",\n",
    "# )\n",
    "\n",
    "# # concat to the annotation_df\n",
    "# columns_to_include = [\n",
    "#     \"image_id\",\n",
    "#     \"file_name\",\n",
    "#     \"vizwiz_url\",\n",
    "#     \"image_preview\",\n",
    "#     \"human_captions\",\n",
    "#     \"annotator\",\n",
    "#     \"notes\",\n",
    "#     \"unable_to_verify\",\n",
    "#     \"double code notes\",\n",
    "#     \"double verified\",\n",
    "#     \"gpt4o_caption\",\n",
    "#     \"gpt4o_code\",\n",
    "#     \"llama_caption\",\n",
    "#     \"llama_code\",\n",
    "#     \"molmo_caption\",\n",
    "#     \"molmo_code\",\n",
    "#     \"text_detected\",\n",
    "#     \"unrecognizable\",\n",
    "#     \"framing\",\n",
    "#     \"blur\",\n",
    "#     \"obstruction\",\n",
    "#     \"rotation\",\n",
    "#     \"too dark\",\n",
    "#     \"too bright\",\n",
    "#     \"other\",\n",
    "#     \"curved label\",\n",
    "#     \"text panel\",\n",
    "# ]\n",
    "\n",
    "# full_annotations_df = pd.concat(\n",
    "#     [\n",
    "#         curr_annotations_df[columns_to_include],\n",
    "#         expert_caption_annotated_df[columns_to_include + [\"expert_caption\"]],\n",
    "#     ]\n",
    "# )\n",
    "# full_annotations_df[\"expert_caption\"].fillna(\"\", inplace=True)\n",
    "\n",
    "# # save\n",
    "# full_annotations_df.to_csv(\n",
    "#     f\"./annotated-data/final-annotated-images_{len(full_annotations_df)}-images_{datetime.now().strftime('%Y-%m-%d_%H-%M')}.csv\",\n",
    "#     index=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) load expert captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"image_id\": 20,\n",
      "    \"file_name\": \"VizWiz_train_00000020.jpg\",\n",
      "    \"vizwiz_url\": \"https://vizwiz.cs.colorado.edu/VizWiz_visualization_img/VizWiz_train_00000020.jpg\",\n",
      "    \"text_detected\": true,\n",
      "    \"unrecognizable\": 0,\n",
      "    \"framing\": 4,\n",
      "    \"blur\": 0,\n",
      "    \"obstruction\": 1,\n",
      "    \"rotation\": 0,\n",
      "    \"too dark\": 0,\n",
      "    \"too bright\": 0,\n",
      "    \"other\": 0,\n",
      "    \"no issue\": 0,\n",
      "    \"expert_captioner\": \"sm\",\n",
      "    \"human_captions\": [\n",
      "        {\n",
      "            \"caption\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "            \"captioning_issue\": \"\"\n",
      "        }\n",
      "    ],\n",
      "    \"model_captions\": [\n",
      "        {\n",
      "            \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "            \"caption\": \"A PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" with a colorful cover featuring illustrations and the PlayStation logo. There is a black object partially visible on the right side of the image.\"\n",
      "        },\n",
      "        {\n",
      "            \"model_name\": \"Llama-3.2-11B-Vision-Instruct\",\n",
      "            \"caption\": \"The image shows a video game case with the title \\\"Grand Theft Auto: Vice City\\\" in white text, featuring a black background with a collage of colorful images. The PlayStation logo is visible in the top-left corner.\"\n",
      "        },\n",
      "        {\n",
      "            \"model_name\": \"Molmo-7B-O-0924\",\n",
      "            \"caption\": \"A PlayStation 2 game case for Grand Theft Auto: Vice City is visible. The case features the PlayStation logo, game title, and various images of vehicles and characters from the game.\"\n",
      "        }\n",
      "    ],\n",
      "    \"evaluation\": {\n",
      "        \"bleu-1\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"bleu\": 0.41445829855415267,\n",
      "                \"precisions\": [\n",
      "                    0.65\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.6376281516217733,\n",
      "                \"length_ratio\": 0.6896551724137931,\n",
      "                \"translation_length\": 40,\n",
      "                \"reference_length\": 58\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"bleu\": 0.442993377175337,\n",
      "                \"precisions\": [\n",
      "                    0.627906976744186\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.7055079710570181,\n",
      "                \"length_ratio\": 0.7413793103448276,\n",
      "                \"translation_length\": 43,\n",
      "                \"reference_length\": 58\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"bleu\": 0.34675533518825286,\n",
      "                \"precisions\": [\n",
      "                    0.6388888888888888\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.5427474811642219,\n",
      "                \"length_ratio\": 0.6206896551724138,\n",
      "                \"translation_length\": 36,\n",
      "                \"reference_length\": 58\n",
      "            }\n",
      "        },\n",
      "        \"bleu-2\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"bleu\": 0.29679975226370464,\n",
      "                \"precisions\": [\n",
      "                    0.65,\n",
      "                    0.3333333333333333\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.6376281516217733,\n",
      "                \"length_ratio\": 0.6896551724137931,\n",
      "                \"translation_length\": 40,\n",
      "                \"reference_length\": 58\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"bleu\": 0.2727877941702201,\n",
      "                \"precisions\": [\n",
      "                    0.627906976744186,\n",
      "                    0.23809523809523808\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.7055079710570181,\n",
      "                \"length_ratio\": 0.7413793103448276,\n",
      "                \"translation_length\": 43,\n",
      "                \"reference_length\": 58\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"bleu\": 0.2540195165192828,\n",
      "                \"precisions\": [\n",
      "                    0.6388888888888888,\n",
      "                    0.34285714285714286\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.5427474811642219,\n",
      "                \"length_ratio\": 0.6206896551724138,\n",
      "                \"translation_length\": 36,\n",
      "                \"reference_length\": 58\n",
      "            }\n",
      "        },\n",
      "        \"bleu-3\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"bleu\": 0.2533385107951265,\n",
      "                \"precisions\": [\n",
      "                    0.65,\n",
      "                    0.3333333333333333,\n",
      "                    0.2894736842105263\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.6376281516217733,\n",
      "                \"length_ratio\": 0.6896551724137931,\n",
      "                \"translation_length\": 40,\n",
      "                \"reference_length\": 58\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"bleu\": 0.19732088843451168,\n",
      "                \"precisions\": [\n",
      "                    0.627906976744186,\n",
      "                    0.23809523809523808,\n",
      "                    0.14634146341463414\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.7055079710570181,\n",
      "                \"length_ratio\": 0.7413793103448276,\n",
      "                \"translation_length\": 43,\n",
      "                \"reference_length\": 58\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"bleu\": 0.2019827832128965,\n",
      "                \"precisions\": [\n",
      "                    0.6388888888888888,\n",
      "                    0.34285714285714286,\n",
      "                    0.23529411764705882\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.5427474811642219,\n",
      "                \"length_ratio\": 0.6206896551724138,\n",
      "                \"translation_length\": 36,\n",
      "                \"reference_length\": 58\n",
      "            }\n",
      "        },\n",
      "        \"bleu-4\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"bleu\": 0.23007389758045407,\n",
      "                \"precisions\": [\n",
      "                    0.65,\n",
      "                    0.3333333333333333,\n",
      "                    0.2894736842105263,\n",
      "                    0.2702702702702703\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.6376281516217733,\n",
      "                \"length_ratio\": 0.6896551724137931,\n",
      "                \"translation_length\": 40,\n",
      "                \"reference_length\": 58\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"bleu\": 0.16133655569193084,\n",
      "                \"precisions\": [\n",
      "                    0.627906976744186,\n",
      "                    0.23809523809523808,\n",
      "                    0.14634146341463414,\n",
      "                    0.125\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.7055079710570181,\n",
      "                \"length_ratio\": 0.7413793103448276,\n",
      "                \"translation_length\": 43,\n",
      "                \"reference_length\": 58\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"bleu\": 0.16134266807145842,\n",
      "                \"precisions\": [\n",
      "                    0.6388888888888888,\n",
      "                    0.34285714285714286,\n",
      "                    0.23529411764705882,\n",
      "                    0.15151515151515152\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.5427474811642219,\n",
      "                \"length_ratio\": 0.6206896551724138,\n",
      "                \"translation_length\": 36,\n",
      "                \"reference_length\": 58\n",
      "            }\n",
      "        },\n",
      "        \"meteor\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"meteor\": 0.40694746353331535\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"meteor\": 0.3753837818313167\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"meteor\": 0.37003849727864063\n",
      "            }\n",
      "        },\n",
      "        \"rouge\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"rouge1\": 0.6024096385542168,\n",
      "                \"rouge2\": 0.271604938271605,\n",
      "                \"rougeL\": 0.43373493975903615,\n",
      "                \"rougeLsum\": 0.43373493975903615\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"rouge1\": 0.5116279069767442,\n",
      "                \"rouge2\": 0.14285714285714288,\n",
      "                \"rougeL\": 0.3488372093023256,\n",
      "                \"rougeLsum\": 0.3488372093023256\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"rouge1\": 0.5316455696202531,\n",
      "                \"rouge2\": 0.33766233766233766,\n",
      "                \"rougeL\": 0.4050632911392405,\n",
      "                \"rougeLsum\": 0.4050632911392405\n",
      "            }\n",
      "        },\n",
      "        \"cider\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"score\": 0.4791910811641647\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"score\": 0.520852253705722\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"score\": 0.10816904937230937\n",
      "            }\n",
      "        },\n",
      "        \"spice\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"All\": {\n",
      "                    \"pr\": 0.46153846153846156,\n",
      "                    \"re\": 0.4,\n",
      "                    \"f\": 0.42857142857142855,\n",
      "                    \"fn\": 18.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 14.0,\n",
      "                    \"tp\": 12.0\n",
      "                },\n",
      "                \"Relation\": {\n",
      "                    \"pr\": 0.16666666666666666,\n",
      "                    \"re\": 0.16666666666666666,\n",
      "                    \"f\": 0.16666666666666666,\n",
      "                    \"fn\": 5.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 5.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Cardinality\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Attribute\": {\n",
      "                    \"pr\": 0.5833333333333334,\n",
      "                    \"re\": 0.4666666666666667,\n",
      "                    \"f\": 0.5185185185185186,\n",
      "                    \"fn\": 8.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 5.0,\n",
      "                    \"tp\": 7.0\n",
      "                },\n",
      "                \"Size\": {\n",
      "                    \"pr\": 1.0,\n",
      "                    \"re\": 1.0,\n",
      "                    \"f\": 1.0,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Color\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 2.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 1.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Object\": {\n",
      "                    \"pr\": 0.5,\n",
      "                    \"re\": 0.4444444444444444,\n",
      "                    \"f\": 0.47058823529411764,\n",
      "                    \"fn\": 5.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 4.0,\n",
      "                    \"tp\": 4.0\n",
      "                }\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"All\": {\n",
      "                    \"pr\": 0.2962962962962963,\n",
      "                    \"re\": 0.26666666666666666,\n",
      "                    \"f\": 0.28070175438596495,\n",
      "                    \"fn\": 22.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 19.0,\n",
      "                    \"tp\": 8.0\n",
      "                },\n",
      "                \"Relation\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 6.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 6.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Cardinality\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Attribute\": {\n",
      "                    \"pr\": 0.38461538461538464,\n",
      "                    \"re\": 0.3333333333333333,\n",
      "                    \"f\": 0.3571428571428571,\n",
      "                    \"fn\": 10.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 8.0,\n",
      "                    \"tp\": 5.0\n",
      "                },\n",
      "                \"Size\": {\n",
      "                    \"pr\": 1.0,\n",
      "                    \"re\": 1.0,\n",
      "                    \"f\": 1.0,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Color\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 2.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 2.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Object\": {\n",
      "                    \"pr\": 0.375,\n",
      "                    \"re\": 0.3333333333333333,\n",
      "                    \"f\": 0.35294117647058826,\n",
      "                    \"fn\": 6.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 5.0,\n",
      "                    \"tp\": 3.0\n",
      "                }\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"All\": {\n",
      "                    \"pr\": 0.43478260869565216,\n",
      "                    \"re\": 0.3333333333333333,\n",
      "                    \"f\": 0.3773584905660377,\n",
      "                    \"fn\": 20.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 13.0,\n",
      "                    \"tp\": 10.0\n",
      "                },\n",
      "                \"Relation\": {\n",
      "                    \"pr\": 0.16666666666666666,\n",
      "                    \"re\": 0.16666666666666666,\n",
      "                    \"f\": 0.16666666666666666,\n",
      "                    \"fn\": 5.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 5.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Cardinality\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Attribute\": {\n",
      "                    \"pr\": 0.5454545454545454,\n",
      "                    \"re\": 0.4,\n",
      "                    \"f\": 0.4615384615384615,\n",
      "                    \"fn\": 9.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 5.0,\n",
      "                    \"tp\": 6.0\n",
      "                },\n",
      "                \"Size\": {\n",
      "                    \"pr\": 1.0,\n",
      "                    \"re\": 1.0,\n",
      "                    \"f\": 1.0,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Color\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 2.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Object\": {\n",
      "                    \"pr\": 0.5,\n",
      "                    \"re\": 0.3333333333333333,\n",
      "                    \"f\": 0.4,\n",
      "                    \"fn\": 6.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 3.0,\n",
      "                    \"tp\": 3.0\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"bertscore\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"precision\": 0.7909770011901855,\n",
      "                \"recall\": 0.7363928556442261,\n",
      "                \"f1\": 0.7627096176147461,\n",
      "                \"best_ref_indices\": [\n",
      "                    0,\n",
      "                    0,\n",
      "                    0\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"recall_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"f1_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\"\n",
      "                }\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"precision\": 0.7593357563018799,\n",
      "                \"recall\": 0.7069831490516663,\n",
      "                \"f1\": 0.7322248816490173,\n",
      "                \"best_ref_indices\": [\n",
      "                    0,\n",
      "                    0,\n",
      "                    0\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"recall_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"f1_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\"\n",
      "                }\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"precision\": 0.803114116191864,\n",
      "                \"recall\": 0.7201811671257019,\n",
      "                \"f1\": 0.759390115737915,\n",
      "                \"best_ref_indices\": [\n",
      "                    0,\n",
      "                    0,\n",
      "                    0\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"recall_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"f1_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"bertscore_idf\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"precision\": 0.8259095549583435,\n",
      "                \"recall\": 0.7173210382461548,\n",
      "                \"f1\": 0.7677949070930481,\n",
      "                \"best_ref_indices\": [\n",
      "                    0,\n",
      "                    0,\n",
      "                    0\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"recall_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"f1_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\"\n",
      "                }\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"precision\": 0.7543994784355164,\n",
      "                \"recall\": 0.682621419429779,\n",
      "                \"f1\": 0.7167177796363831,\n",
      "                \"best_ref_indices\": [\n",
      "                    0,\n",
      "                    0,\n",
      "                    0\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"recall_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"f1_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\"\n",
      "                }\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"precision\": 0.8208200931549072,\n",
      "                \"recall\": 0.7194167375564575,\n",
      "                \"f1\": 0.766780436038971,\n",
      "                \"best_ref_indices\": [\n",
      "                    0,\n",
      "                    0,\n",
      "                    0\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"recall_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"f1_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"clipscore\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"score\": 1.001953125\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"score\": 0.93505859375\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"score\": 0.97900390625\n",
      "            }\n",
      "        },\n",
      "        \"clipscore_ref\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"score\": 0.95458984375\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"score\": 0.89892578125\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"score\": 0.92138671875\n",
      "            }\n",
      "        },\n",
      "        \"cap_f1\": {\n",
      "            \"parsed_atomics\": [\n",
      "                \"There is a PlayStation 2 game case.\",\n",
      "                \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                \"The cover of the game case is colorful.\",\n",
      "                \"The cover includes characters.\",\n",
      "                \"The cover includes vehicles.\",\n",
      "                \"The cover includes a building.\",\n",
      "                \"There is a 'Rockstar Games' logo on the cover.\",\n",
      "                \"The 'Rockstar Games' logo is yellow.\",\n",
      "                \"The game case is partially off-frame.\",\n",
      "                \"The game case is on a white surface.\",\n",
      "                \"There is a cord nearby.\"\n",
      "            ],\n",
      "            \"T_atomics\": [\n",
      "                \"There is a PlayStation 2 game case.\",\n",
      "                \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                \"The cover of the game case is colorful.\",\n",
      "                \"The cover includes characters.\",\n",
      "                \"The cover includes vehicles.\",\n",
      "                \"The cover includes a building.\",\n",
      "                \"There is a 'Rockstar Games' logo on the cover.\",\n",
      "                \"The 'Rockstar Games' logo is yellow.\",\n",
      "                \"The game case is partially off-frame.\",\n",
      "                \"The game case is on a white surface.\",\n",
      "                \"There is a cord nearby.\"\n",
      "            ],\n",
      "            \"g_atomics\": {\n",
      "                \"gpt-4o-2024-08-06\": [\n",
      "                    \"There is a PlayStation 2 game case.\",\n",
      "                    \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                    \"The cover of the game case is colorful.\",\n",
      "                    \"The cover features illustrations.\",\n",
      "                    \"The PlayStation logo is on the cover.\",\n",
      "                    \"There is a black object in the image.\",\n",
      "                    \"The black object is partially visible.\",\n",
      "                    \"The black object is on the right side of the image.\"\n",
      "                ],\n",
      "                \"Llama-3.2-11B-Vision-Instruct\": [\n",
      "                    \"There is a video game case.\",\n",
      "                    \"The title on the case is 'Grand Theft Auto: Vice City'.\",\n",
      "                    \"The title is in white text.\",\n",
      "                    \"The background is black.\",\n",
      "                    \"There is a collage of colorful images on the case.\",\n",
      "                    \"The PlayStation logo is visible.\",\n",
      "                    \"The PlayStation logo is in the top-left corner.\"\n",
      "                ],\n",
      "                \"Molmo-7B-O-0924\": [\n",
      "                    \"There is a PlayStation 2 game case.\",\n",
      "                    \"The game case is for Grand Theft Auto: Vice City.\",\n",
      "                    \"The PlayStation logo is on the case.\",\n",
      "                    \"The game title is on the case.\",\n",
      "                    \"There are images of vehicles on the case.\",\n",
      "                    \"There are images of characters on the case.\"\n",
      "                ]\n",
      "            },\n",
      "            \"T_org\": [\n",
      "                \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\"\n",
      "            ],\n",
      "            \"metadata\": {\n",
      "                \"gpt-4o-2024-08-06\": {\n",
      "                    \"recall\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a PlayStation 2 game case.\",\n",
      "                            \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                            \"The cover of the game case is colorful.\"\n",
      "                        ],\n",
      "                        \"FNs\": [\n",
      "                            \"The cover includes characters.\",\n",
      "                            \"The cover includes vehicles.\",\n",
      "                            \"The cover includes a building.\",\n",
      "                            \"There is a 'Rockstar Games' logo on the cover.\",\n",
      "                            \"The 'Rockstar Games' logo is yellow.\",\n",
      "                            \"The game case is partially off-frame.\",\n",
      "                            \"The game case is on a white surface.\",\n",
      "                            \"There is a cord nearby.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a PlayStation 2 game case.\",\n",
      "                                \"g_atomic\": \"There is a PlayStation 2 game case.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                                \"g_atomic\": \"The game case is for 'Grand Theft Auto: Vice City'.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The cover of the game case is colorful.\",\n",
      "                                \"g_atomic\": \"The cover of the game case is colorful.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 3,\n",
      "                            \"FN\": 8\n",
      "                        }\n",
      "                    },\n",
      "                    \"precision\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a PlayStation 2 game case.\",\n",
      "                            \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                            \"The cover of the game case is colorful.\",\n",
      "                            \"The cover features illustrations.\"\n",
      "                        ],\n",
      "                        \"FPs\": [\n",
      "                            \"The PlayStation logo is on the cover.\",\n",
      "                            \"There is a black object in the image.\",\n",
      "                            \"The black object is partially visible.\",\n",
      "                            \"The black object is on the right side of the image.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"g_atomic\": \"There is a PlayStation 2 game case.\",\n",
      "                                \"T_org\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                                \"T_org\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The cover of the game case is colorful.\",\n",
      "                                \"T_org\": \"The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The cover features illustrations.\",\n",
      "                                \"T_org\": \"The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 4,\n",
      "                            \"FP\": 4\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                    \"recall\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a PlayStation 2 game case.\",\n",
      "                            \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                            \"The cover of the game case is colorful.\"\n",
      "                        ],\n",
      "                        \"FNs\": [\n",
      "                            \"The cover includes characters.\",\n",
      "                            \"The cover includes vehicles.\",\n",
      "                            \"The cover includes a building.\",\n",
      "                            \"There is a 'Rockstar Games' logo on the cover.\",\n",
      "                            \"The 'Rockstar Games' logo is yellow.\",\n",
      "                            \"The game case is partially off-frame.\",\n",
      "                            \"The game case is on a white surface.\",\n",
      "                            \"There is a cord nearby.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a PlayStation 2 game case.\",\n",
      "                                \"g_atomic\": \"There is a video game case.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                                \"g_atomic\": \"The title on the case is 'Grand Theft Auto: Vice City'.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The cover of the game case is colorful.\",\n",
      "                                \"g_atomic\": \"There is a collage of colorful images on the case.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 3,\n",
      "                            \"FN\": 8\n",
      "                        }\n",
      "                    },\n",
      "                    \"precision\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a video game case.\",\n",
      "                            \"The title on the case is 'Grand Theft Auto: Vice City'.\",\n",
      "                            \"There is a collage of colorful images on the case.\"\n",
      "                        ],\n",
      "                        \"FPs\": [\n",
      "                            \"The title is in white text.\",\n",
      "                            \"The background is black.\",\n",
      "                            \"The PlayStation logo is visible.\",\n",
      "                            \"The PlayStation logo is in the top-left corner.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"g_atomic\": \"There is a video game case.\",\n",
      "                                \"T_org\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The title on the case is 'Grand Theft Auto: Vice City'.\",\n",
      "                                \"T_org\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"There is a collage of colorful images on the case.\",\n",
      "                                \"T_org\": \"The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 3,\n",
      "                            \"FP\": 4\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"Molmo-7B-O-0924\": {\n",
      "                    \"recall\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a PlayStation 2 game case.\",\n",
      "                            \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                            \"The cover includes characters.\",\n",
      "                            \"The cover includes vehicles.\"\n",
      "                        ],\n",
      "                        \"FNs\": [\n",
      "                            \"The cover of the game case is colorful.\",\n",
      "                            \"The cover includes a building.\",\n",
      "                            \"There is a 'Rockstar Games' logo on the cover.\",\n",
      "                            \"The 'Rockstar Games' logo is yellow.\",\n",
      "                            \"The game case is partially off-frame.\",\n",
      "                            \"The game case is on a white surface.\",\n",
      "                            \"There is a cord nearby.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a PlayStation 2 game case.\",\n",
      "                                \"g_atomic\": \"There is a PlayStation 2 game case.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                                \"g_atomic\": \"The game case is for Grand Theft Auto: Vice City.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The cover includes characters.\",\n",
      "                                \"g_atomic\": \"There are images of characters on the case.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The cover includes vehicles.\",\n",
      "                                \"g_atomic\": \"There are images of vehicles on the case.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 4,\n",
      "                            \"FN\": 7\n",
      "                        }\n",
      "                    },\n",
      "                    \"precision\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a PlayStation 2 game case.\",\n",
      "                            \"The game case is for Grand Theft Auto: Vice City.\",\n",
      "                            \"There are images of vehicles on the case.\",\n",
      "                            \"There are images of characters on the case.\"\n",
      "                        ],\n",
      "                        \"FPs\": [\n",
      "                            \"The PlayStation logo is on the case.\",\n",
      "                            \"The game title is on the case.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"g_atomic\": \"There is a PlayStation 2 game case.\",\n",
      "                                \"T_org\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The game case is for Grand Theft Auto: Vice City.\",\n",
      "                                \"T_org\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"There are images of vehicles on the case.\",\n",
      "                                \"T_org\": \"The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"There are images of characters on the case.\",\n",
      "                                \"T_org\": \"The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 4,\n",
      "                            \"FP\": 2\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            \"scores\": {\n",
      "                \"gpt-4o-2024-08-06\": {\n",
      "                    \"recall\": 0.2727272727272727,\n",
      "                    \"precision\": 0.5,\n",
      "                    \"cap_f1\": 0.3529411764705882\n",
      "                },\n",
      "                \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                    \"recall\": 0.2727272727272727,\n",
      "                    \"precision\": 0.42857142857142855,\n",
      "                    \"cap_f1\": 0.33333333333333326\n",
      "                },\n",
      "                \"Molmo-7B-O-0924\": {\n",
      "                    \"recall\": 0.36363636363636365,\n",
      "                    \"precision\": 0.6666666666666666,\n",
      "                    \"cap_f1\": 0.4705882352941177\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"human_caption_similarity\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "expert_captioned_data = json.load(\n",
    "    open(\n",
    "        \"../../data/study-2-output/final-evaluated-captions/expert-captions_evaluation_600-images_2025-04-13_16-42.json\"\n",
    "    )\n",
    ")\n",
    "print(json.dumps(expert_captioned_data[0], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw expert captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: replace this with the dataset that has metrics run\n",
    "# expert_captioned_data = pd.read_csv(\n",
    "#     \"./labeled-data/Dataset for Shawn _ 04-06-25 - dataset formatted.csv\",\n",
    "#     dtype={\n",
    "#         \"File Name\": str,\n",
    "#         \"Image URL\": str,\n",
    "#         \"Image Preview\": str,\n",
    "#         \"Captioner Name\": str,\n",
    "#         \"Describe all parts of the image that may be important to a person who is blind.\": str,\n",
    "#         \"If you are unable to caption the image, describe the issue in this column.\": str,\n",
    "#     },\n",
    "#     keep_default_na=False,\n",
    "#     encoding=\"utf-8\",\n",
    "# )\n",
    "\n",
    "# # rename columns so they're easier to program with\n",
    "# expert_captioned_data.rename(\n",
    "#     columns={\n",
    "#         \"File Name\": \"file_name\",\n",
    "#         \"Image URL\": \"vizwiz_url\",\n",
    "#         \"Captioner Name\": \"expert_captioner\",\n",
    "#         \"Describe all parts of the image that may be important to a person who is blind.\": \"expert_caption\",\n",
    "#         \"If you are unable to caption the image, describe the issue in this column.\": \"captioning_issue\",\n",
    "#     },\n",
    "#     inplace=True,\n",
    "# )\n",
    "# expert_captioned_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 1: how accurately do VLMs identify products?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>Llama-3.2-11B-Vision-Instruct</th>\n",
       "      <th>Molmo-7B-O-0924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>811</td>\n",
       "      <td>568</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>379</td>\n",
       "      <td>644</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes++</th>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gpt-4o-2024-08-06  Llama-3.2-11B-Vision-Instruct  Molmo-7B-O-0924\n",
       "yes                  811                            568              449\n",
       "no                   379                            644              770\n",
       "yes++                 30                              8                1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get only the images that were verifable\n",
    "accuracy_counts_df = pd.concat(\n",
    "    [\n",
    "        annotations_df[annotations_df[\"unable_to_verify\"] == \"\"][\n",
    "            \"gpt4o_code\"\n",
    "        ].value_counts(),\n",
    "        annotations_df[annotations_df[\"unable_to_verify\"] == \"\"][\n",
    "            \"llama_code\"\n",
    "        ].value_counts(),\n",
    "        annotations_df[annotations_df[\"unable_to_verify\"] == \"\"][\n",
    "            \"molmo_code\"\n",
    "        ].value_counts(),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "accuracy_counts_df.columns = MODEL_NAMES.keys()\n",
    "display(accuracy_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>Llama-3.2-11B-Vision-Instruct</th>\n",
       "      <th>Molmo-7B-O-0924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>66.475410</td>\n",
       "      <td>46.557377</td>\n",
       "      <td>36.803279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>31.065574</td>\n",
       "      <td>52.786885</td>\n",
       "      <td>63.114754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes++</th>\n",
       "      <td>2.459016</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.081967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gpt-4o-2024-08-06  Llama-3.2-11B-Vision-Instruct  Molmo-7B-O-0924\n",
       "yes            66.475410                      46.557377        36.803279\n",
       "no             31.065574                      52.786885        63.114754\n",
       "yes++           2.459016                       0.655738         0.081967"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * accuracy_counts_df / 1220"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 2: how does image quality affect a VLM's ability to accurately identify products?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine annotation data with image quality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in regression df: 1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6w/gkg9vw3d29jglv9knrxxf3r40000gn/T/ipykernel_57449/449857616.py:38: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  regression_df.replace({\"yes\": 1, \"no\": 0}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>too bright</th>\n",
       "      <th>other</th>\n",
       "      <th>no issue</th>\n",
       "      <th>human_captions</th>\n",
       "      <th>gpt4o_caption</th>\n",
       "      <th>gpt4o_code</th>\n",
       "      <th>llama_caption</th>\n",
       "      <th>llama_code</th>\n",
       "      <th>molmo_caption</th>\n",
       "      <th>molmo_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9886</td>\n",
       "      <td>VizWiz_train_00009886.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A box of frozen food sits on a table top that ...</td>\n",
       "      <td>A package of Trader Joe's Paneer Tikka Masala ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a frozen food package with a g...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a food package for a Tikka Mas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12066</td>\n",
       "      <td>VizWiz_train_00012066.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A Kroger grocery store tag for a caramel iced ...</td>\n",
       "      <td>A caramel iced cake with a label featuring the...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a white label with the blue an...</td>\n",
       "      <td>0</td>\n",
       "      <td>The image shows a plastic container of apple c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1908</td>\n",
       "      <td>VizWiz_train_00001908.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A description on a box of herbal tea.\\nA print...</td>\n",
       "      <td>A label with the text \"A delicious CAFFEINE FR...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a white box with the words \"A ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a sideways view of a product l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15399</td>\n",
       "      <td>VizWiz_train_00015399.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A green and white box of Lean Pockets frozen r...</td>\n",
       "      <td>Box of Lean Pockets with garlic chicken white ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a green and white box of Lean ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a box of Lean Pockets on a whi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4380</td>\n",
       "      <td>VizWiz_train_00004380.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>garlic spinach hummus possibly in a green cont...</td>\n",
       "      <td>A plastic container with a green lid, featurin...</td>\n",
       "      <td>0</td>\n",
       "      <td>The image shows a plastic container with a gre...</td>\n",
       "      <td>0</td>\n",
       "      <td>The image shows a plastic food container on a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                  file_name                                         vizwiz_url  text_detected  unrecognizable  framing  blur  obstruction  rotation  too dark  too bright  other  no issue                                     human_captions                                      gpt4o_caption  gpt4o_code                                      llama_caption  llama_code                                      molmo_caption  molmo_code\n",
       "0      9886  VizWiz_train_00009886.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0        1     2            0         4         0           1      0         1  A box of frozen food sits on a table top that ...  A package of Trader Joe's Paneer Tikka Masala ...           1  The image shows a frozen food package with a g...           1  The image shows a food package for a Tikka Mas...           0\n",
       "1     12066  VizWiz_train_00012066.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0        4     2            0         1         0           0      0         0  A Kroger grocery store tag for a caramel iced ...  A caramel iced cake with a label featuring the...           1  The image shows a white label with the blue an...           0  The image shows a plastic container of apple c...           0\n",
       "2      1908  VizWiz_train_00001908.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0        2     4            0         3         0           0      0         0  A description on a box of herbal tea.\\nA print...  A label with the text \"A delicious CAFFEINE FR...           1  The image shows a white box with the words \"A ...           1  The image shows a sideways view of a product l...           1\n",
       "3     15399  VizWiz_train_00015399.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0        4     0            0         3         0           0      0         1  A green and white box of Lean Pockets frozen r...  Box of Lean Pockets with garlic chicken white ...           1  The image shows a green and white box of Lean ...           1  The image shows a box of Lean Pockets on a whi...           0\n",
       "4      4380  VizWiz_train_00004380.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0        5     0            0         3         0           0      0         0  garlic spinach hummus possibly in a green cont...  A plastic container with a green lid, featurin...           0  The image shows a plastic container with a gre...           0  The image shows a plastic food container on a ...           0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine with annotation data\n",
    "columns_to_include = [\n",
    "    \"image_id\",\n",
    "    \"file_name\",\n",
    "    \"vizwiz_url\",\n",
    "    \"human_captions\",\n",
    "    \"unable_to_verify\",\n",
    "    \"double code notes\",\n",
    "    \"double verified\",\n",
    "    \"gpt4o_caption\",\n",
    "    \"gpt4o_code\",\n",
    "    \"llama_caption\",\n",
    "    \"llama_code\",\n",
    "    \"molmo_caption\",\n",
    "    \"molmo_code\",\n",
    "]\n",
    "regression_df = pd.merge(\n",
    "    filtered_evaluation_data_df,\n",
    "    annotations_df[columns_to_include],\n",
    "    on=[\"image_id\", \"file_name\", \"vizwiz_url\"],\n",
    "    how=\"right\",\n",
    ")\n",
    "\n",
    "# make sure each model has a yes or no\n",
    "regression_df = regression_df[regression_df[\"unable_to_verify\"] == \"\"]\n",
    "regression_df = regression_df[\n",
    "    (regression_df[\"gpt4o_code\"] != \"unsure\") & (regression_df[\"gpt4o_code\"] != \"\")\n",
    "]\n",
    "regression_df = regression_df[\n",
    "    (regression_df[\"llama_code\"] != \"unsure\") & (regression_df[\"llama_code\"] != \"\")\n",
    "]\n",
    "regression_df = regression_df[\n",
    "    (regression_df[\"molmo_code\"] != \"unsure\") & (regression_df[\"molmo_code\"] != \"\")\n",
    "]\n",
    "\n",
    "# combine yes and yes++\n",
    "regression_df.replace({\"yes++\": \"yes\"}, inplace=True)\n",
    "regression_df.replace({\"yes\": 1, \"no\": 0}, inplace=True)\n",
    "regression_df[\"gpt4o_code\"] = pd.to_numeric(regression_df[\"gpt4o_code\"])\n",
    "regression_df[\"llama_code\"] = pd.to_numeric(regression_df[\"llama_code\"])\n",
    "regression_df[\"molmo_code\"] = pd.to_numeric(regression_df[\"molmo_code\"])\n",
    "\n",
    "# cleanup\n",
    "del regression_df[\"unable_to_verify\"]\n",
    "del regression_df[\"double code notes\"]\n",
    "del regression_df[\"double verified\"]\n",
    "\n",
    "print(f\"Number of images in regression df: {len(regression_df)}\")\n",
    "regression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save regression df\n",
    "os.makedirs(\n",
    "    \"./intermediate-data\",\n",
    "    exist_ok=True,\n",
    ")\n",
    "regression_df.to_csv(\n",
    "    f\"./intermediate-data/regression-continuious-df_{len(regression_df)}-images.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bins for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_quality_columns = [\n",
    "    \"unrecognizable\",\n",
    "    \"framing\",\n",
    "    \"blur\",\n",
    "    \"obstruction\",\n",
    "    \"rotation\",\n",
    "    \"too dark\",\n",
    "    \"too bright\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>too bright</th>\n",
       "      <th>other</th>\n",
       "      <th>no issue</th>\n",
       "      <th>human_captions</th>\n",
       "      <th>gpt4o_caption</th>\n",
       "      <th>gpt4o_code</th>\n",
       "      <th>llama_caption</th>\n",
       "      <th>llama_code</th>\n",
       "      <th>molmo_caption</th>\n",
       "      <th>molmo_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9886</td>\n",
       "      <td>VizWiz_train_00009886.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A box of frozen food sits on a table top that ...</td>\n",
       "      <td>A package of Trader Joe's Paneer Tikka Masala ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a frozen food package with a g...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a food package for a Tikka Mas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12066</td>\n",
       "      <td>VizWiz_train_00012066.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A Kroger grocery store tag for a caramel iced ...</td>\n",
       "      <td>A caramel iced cake with a label featuring the...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a white label with the blue an...</td>\n",
       "      <td>0</td>\n",
       "      <td>The image shows a plastic container of apple c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1908</td>\n",
       "      <td>VizWiz_train_00001908.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A description on a box of herbal tea.\\nA print...</td>\n",
       "      <td>A label with the text \"A delicious CAFFEINE FR...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a white box with the words \"A ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a sideways view of a product l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15399</td>\n",
       "      <td>VizWiz_train_00015399.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A green and white box of Lean Pockets frozen r...</td>\n",
       "      <td>Box of Lean Pockets with garlic chicken white ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a green and white box of Lean ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a box of Lean Pockets on a whi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4380</td>\n",
       "      <td>VizWiz_train_00004380.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>garlic spinach hummus possibly in a green cont...</td>\n",
       "      <td>A plastic container with a green lid, featurin...</td>\n",
       "      <td>0</td>\n",
       "      <td>The image shows a plastic container with a gre...</td>\n",
       "      <td>0</td>\n",
       "      <td>The image shows a plastic food container on a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                  file_name                                         vizwiz_url  text_detected unrecognizable        framing           blur obstruction       rotation  too dark too bright  other  no issue                                     human_captions                                      gpt4o_caption  gpt4o_code                                      llama_caption  llama_code                                      molmo_caption  molmo_code\n",
       "0      9886  VizWiz_train_00009886.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True       no issue       no issue  issue present    no issue  issue present  no issue   no issue      0         1  A box of frozen food sits on a table top that ...  A package of Trader Joe's Paneer Tikka Masala ...           1  The image shows a frozen food package with a g...           1  The image shows a food package for a Tikka Mas...           0\n",
       "1     12066  VizWiz_train_00012066.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True       no issue  issue present  issue present    no issue       no issue  no issue   no issue      0         0  A Kroger grocery store tag for a caramel iced ...  A caramel iced cake with a label featuring the...           1  The image shows a white label with the blue an...           0  The image shows a plastic container of apple c...           0\n",
       "2      1908  VizWiz_train_00001908.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True       no issue  issue present  issue present    no issue  issue present  no issue   no issue      0         0  A description on a box of herbal tea.\\nA print...  A label with the text \"A delicious CAFFEINE FR...           1  The image shows a white box with the words \"A ...           1  The image shows a sideways view of a product l...           1\n",
       "3     15399  VizWiz_train_00015399.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True       no issue  issue present       no issue    no issue  issue present  no issue   no issue      0         1  A green and white box of Lean Pockets frozen r...  Box of Lean Pockets with garlic chicken white ...           1  The image shows a green and white box of Lean ...           1  The image shows a box of Lean Pockets on a whi...           0\n",
       "4      4380  VizWiz_train_00004380.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True       no issue  issue present       no issue    no issue  issue present  no issue   no issue      0         0  garlic spinach hummus possibly in a green cont...  A plastic container with a green lid, featurin...           0  The image shows a plastic container with a gre...           0  The image shows a plastic food container on a ...           0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bin image quality issues into 2 bins\n",
    "regression_two_bins_df = regression_df.copy()\n",
    "for iq in image_quality_columns:\n",
    "    regression_two_bins_df[iq] = regression_two_bins_df[iq].astype(str)\n",
    "    regression_two_bins_df[iq] = regression_two_bins_df[iq].map(\n",
    "        {\n",
    "            \"0\": \"no issue\",\n",
    "            \"1\": \"no issue\",\n",
    "            \"2\": \"issue present\",\n",
    "            \"3\": \"issue present\",\n",
    "            \"4\": \"issue present\",\n",
    "            \"5\": \"issue present\",\n",
    "        }\n",
    "    )\n",
    "display(regression_two_bins_df.head())\n",
    "regression_two_bins_df.to_csv(\n",
    "    f\"./intermediate-data/regression-two-bins-df_{len(regression_two_bins_df)}-images.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>too bright</th>\n",
       "      <th>other</th>\n",
       "      <th>no issue</th>\n",
       "      <th>human_captions</th>\n",
       "      <th>gpt4o_caption</th>\n",
       "      <th>gpt4o_code</th>\n",
       "      <th>llama_caption</th>\n",
       "      <th>llama_code</th>\n",
       "      <th>molmo_caption</th>\n",
       "      <th>molmo_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9886</td>\n",
       "      <td>VizWiz_train_00009886.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>.medium</td>\n",
       "      <td>.low</td>\n",
       "      <td>.high</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A box of frozen food sits on a table top that ...</td>\n",
       "      <td>A package of Trader Joe's Paneer Tikka Masala ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a frozen food package with a g...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a food package for a Tikka Mas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12066</td>\n",
       "      <td>VizWiz_train_00012066.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>.low</td>\n",
       "      <td>.high</td>\n",
       "      <td>.medium</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A Kroger grocery store tag for a caramel iced ...</td>\n",
       "      <td>A caramel iced cake with a label featuring the...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a white label with the blue an...</td>\n",
       "      <td>0</td>\n",
       "      <td>The image shows a plastic container of apple c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1908</td>\n",
       "      <td>VizWiz_train_00001908.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>.low</td>\n",
       "      <td>.medium</td>\n",
       "      <td>.high</td>\n",
       "      <td>.low</td>\n",
       "      <td>.medium</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A description on a box of herbal tea.\\nA print...</td>\n",
       "      <td>A label with the text \"A delicious CAFFEINE FR...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a white box with the words \"A ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a sideways view of a product l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15399</td>\n",
       "      <td>VizWiz_train_00015399.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>.low</td>\n",
       "      <td>.high</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>.medium</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A green and white box of Lean Pockets frozen r...</td>\n",
       "      <td>Box of Lean Pockets with garlic chicken white ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a green and white box of Lean ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a box of Lean Pockets on a whi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4380</td>\n",
       "      <td>VizWiz_train_00004380.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>.low</td>\n",
       "      <td>.high</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>.medium</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>garlic spinach hummus possibly in a green cont...</td>\n",
       "      <td>A plastic container with a green lid, featurin...</td>\n",
       "      <td>0</td>\n",
       "      <td>The image shows a plastic container with a gre...</td>\n",
       "      <td>0</td>\n",
       "      <td>The image shows a plastic food container on a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                  file_name                                         vizwiz_url  text_detected unrecognizable  framing     blur obstruction rotation too dark too bright  other  no issue                                     human_captions                                      gpt4o_caption  gpt4o_code                                      llama_caption  llama_code                                      molmo_caption  molmo_code\n",
       "0      9886  VizWiz_train_00009886.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True           .low     .low  .medium        .low    .high     .low       .low      0         1  A box of frozen food sits on a table top that ...  A package of Trader Joe's Paneer Tikka Masala ...           1  The image shows a frozen food package with a g...           1  The image shows a food package for a Tikka Mas...           0\n",
       "1     12066  VizWiz_train_00012066.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True           .low    .high  .medium        .low     .low     .low       .low      0         0  A Kroger grocery store tag for a caramel iced ...  A caramel iced cake with a label featuring the...           1  The image shows a white label with the blue an...           0  The image shows a plastic container of apple c...           0\n",
       "2      1908  VizWiz_train_00001908.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True           .low  .medium    .high        .low  .medium     .low       .low      0         0  A description on a box of herbal tea.\\nA print...  A label with the text \"A delicious CAFFEINE FR...           1  The image shows a white box with the words \"A ...           1  The image shows a sideways view of a product l...           1\n",
       "3     15399  VizWiz_train_00015399.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True           .low    .high     .low        .low  .medium     .low       .low      0         1  A green and white box of Lean Pockets frozen r...  Box of Lean Pockets with garlic chicken white ...           1  The image shows a green and white box of Lean ...           1  The image shows a box of Lean Pockets on a whi...           0\n",
       "4      4380  VizWiz_train_00004380.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True           .low    .high     .low        .low  .medium     .low       .low      0         0  garlic spinach hummus possibly in a green cont...  A plastic container with a green lid, featurin...           0  The image shows a plastic container with a gre...           0  The image shows a plastic food container on a ...           0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bin image quality issues into 2 bins\n",
    "regression_three_bins_df = regression_df.copy()\n",
    "for iq in image_quality_columns:\n",
    "    regression_three_bins_df[iq] = regression_three_bins_df[iq].astype(str)\n",
    "    regression_three_bins_df[iq] = regression_three_bins_df[iq].map(\n",
    "        {\n",
    "            \"0\": \".low\",\n",
    "            \"1\": \".low\",\n",
    "            \"2\": \".medium\",\n",
    "            \"3\": \".medium\",\n",
    "            \"4\": \".high\",\n",
    "            \"5\": \".high\",\n",
    "        }\n",
    "    )\n",
    "display(regression_three_bins_df.head())\n",
    "regression_three_bins_df.to_csv(\n",
    "    f\"./intermediate-data/regression-three-bins-df_{len(regression_three_bins_df)}-images.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create contingency tables for each image quality issue pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>blur</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>framing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.20</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.82</td>\n",
       "      <td>5.49</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.64</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.57</td>\n",
       "      <td>4.92</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.39</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4.75</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.21</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5.25</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.02</td>\n",
       "      <td>7.79</td>\n",
       "      <td>4.18</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.87</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.90</td>\n",
       "      <td>3.28</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "blur         0     1     2     3     4     5\n",
       "framing                                     \n",
       "0         3.20  1.23  0.98  0.82  5.49  3.85\n",
       "1         1.64  1.07  0.98  0.57  4.92  3.11\n",
       "2         1.39  1.15  0.57  0.41  4.75  3.36\n",
       "3         2.21  0.74  0.66  0.25  5.25  2.70\n",
       "4        14.02  7.79  4.18  2.79  2.87  2.46\n",
       "5         5.90  3.28  1.39  1.72  1.31  0.98"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\"\n",
    ")\n",
    "pd.crosstab(\n",
    "    regression_df[\"framing\"],\n",
    "    regression_df[\"blur\"],\n",
    "    normalize=True,\n",
    ").round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>obstruction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>framing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.75</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.23</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.33</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.16</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.49</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.03</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "obstruction      0     1     2     3     4     5\n",
       "framing                                         \n",
       "0            14.75  0.41  0.08  0.00  0.25  0.08\n",
       "1            11.23  0.66  0.00  0.00  0.25  0.16\n",
       "2            10.33  0.90  0.08  0.08  0.16  0.08\n",
       "3            10.16  1.39  0.00  0.00  0.25  0.00\n",
       "4            30.49  3.28  0.25  0.08  0.00  0.00\n",
       "5            13.03  1.15  0.25  0.16  0.00  0.00"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\"\n",
    ")\n",
    "pd.crosstab(\n",
    "    regression_df[\"framing\"],\n",
    "    regression_df[\"obstruction\"],\n",
    "    normalize=True,\n",
    ").round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rotation</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>framing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.89</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4.92</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.49</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.43</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.33</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.92</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.69</td>\n",
       "      <td>2.87</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.77</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rotation      0     1     2     3     4     5\n",
       "framing                                      \n",
       "0          6.89  1.15  0.82  0.41  4.92  1.39\n",
       "1          5.49  1.39  0.66  0.57  3.61  0.57\n",
       "2          4.43  1.56  0.82  0.57  3.28  0.98\n",
       "3          5.33  0.66  0.41  1.23  3.44  0.74\n",
       "4         19.92  3.77  3.69  2.87  2.62  1.23\n",
       "5          8.77  1.64  1.23  1.07  1.56  0.33"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\"\n",
    ")\n",
    "pd.crosstab(\n",
    "    regression_df[\"framing\"],\n",
    "    regression_df[\"rotation\"],\n",
    "    normalize=True,\n",
    ").round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>obstruction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blur</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.56</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.87</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.70</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.82</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.13</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.92</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "obstruction      0     1     2     3     4     5\n",
       "blur                                            \n",
       "0            26.56  1.31  0.08  0.08  0.25  0.08\n",
       "1            12.87  1.80  0.25  0.08  0.16  0.08\n",
       "2             7.70  0.82  0.08  0.00  0.08  0.08\n",
       "3             5.82  0.25  0.16  0.08  0.25  0.00\n",
       "4            22.13  2.21  0.08  0.00  0.16  0.00\n",
       "5            14.92  1.39  0.00  0.08  0.00  0.08"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\"\n",
    ")\n",
    "pd.crosstab(\n",
    "    regression_df[\"blur\"],\n",
    "    regression_df[\"obstruction\"],\n",
    "    normalize=True,\n",
    ").round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rotation</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blur</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.13</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.39</td>\n",
       "      <td>7.62</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.46</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.23</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.61</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.11</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.98</td>\n",
       "      <td>3.36</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.52</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rotation      0     1     2     3     4     5\n",
       "blur                                         \n",
       "0         12.13  2.13  2.38  1.39  7.62  2.70\n",
       "1          7.46  1.07  0.66  1.23  4.26  0.57\n",
       "2          3.61  0.66  0.57  0.25  2.95  0.74\n",
       "3          3.11  0.49  0.49  0.25  1.72  0.49\n",
       "4         15.98  3.36  1.64  1.72  1.23  0.66\n",
       "5          8.52  2.46  1.89  1.89  1.64  0.08"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\"\n",
    ")\n",
    "pd.crosstab(\n",
    "    regression_df[\"blur\"],\n",
    "    regression_df[\"rotation\"],\n",
    "    normalize=True,\n",
    ").round(4) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 3: expert captions and sensitivity of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_metrics(dataset, metric):\n",
    "    \"\"\"\n",
    "    Computes average precision, recall, and f1 for BERTScore for each model.\n",
    "    \"\"\"\n",
    "    total_scores = {}\n",
    "    for image in dataset:\n",
    "        if metric == \"bertscore\":\n",
    "            curr_evaluation = image[\"evaluation\"][metric]\n",
    "            f1_name = \"f1\"\n",
    "        elif metric == \"cap_f1\":\n",
    "            curr_evaluation = image[\"evaluation\"][metric][\"scores\"]\n",
    "            f1_name = \"cap_f1\"\n",
    "\n",
    "        for model_name, scores in curr_evaluation.items():\n",
    "            if model_name in total_scores:\n",
    "                total_scores[model_name] = {\n",
    "                    \"total_count\": total_scores[model_name][\"total_count\"] + 1,\n",
    "                    \"total_precision\": total_scores[model_name][\"total_precision\"]\n",
    "                    + scores[\"precision\"],\n",
    "                    \"total_recall\": total_scores[model_name][\"total_recall\"]\n",
    "                    + scores[\"recall\"],\n",
    "                    \"total_f1\": total_scores[model_name][\"total_f1\"] + scores[f1_name],\n",
    "                }\n",
    "            else:\n",
    "                total_scores[model_name] = {\n",
    "                    \"total_count\": 1,\n",
    "                    \"total_precision\": scores[\"precision\"],\n",
    "                    \"total_recall\": scores[\"recall\"],\n",
    "                    \"total_f1\": scores[f1_name],\n",
    "                }\n",
    "\n",
    "    # compute averages and f1\n",
    "    output = {}\n",
    "    for model_name, values in total_scores.items():\n",
    "        output[model_name] = {\n",
    "            \"avg_precision\": values[\"total_precision\"] / float(values[\"total_count\"]),\n",
    "            \"avg_recall\": values[\"total_recall\"] / float(values[\"total_count\"]),\n",
    "            \"avg_f1\": values[\"total_f1\"] / float(values[\"total_count\"]),\n",
    "        }\n",
    "        output[model_name][\"f1\"] = s.harmonic_mean(\n",
    "            [output[model_name][\"avg_precision\"], output[model_name][\"avg_recall\"]]\n",
    "        )\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can only merge Series or DataFrame objects, a <class 'list'> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# create an expert file to evaluate\u001b[39;00m\n\u001b[32m     23\u001b[39m expert_data_to_eval_df = pd.DataFrame.from_dict(evaluation_data_expert)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m expert_data_to_eval_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexpert_data_to_eval_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexpert_captioned_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvizwiz_url\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mright\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m expert_data_to_eval_df[\u001b[33m\"\u001b[39m\u001b[33mImage Preview\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     31\u001b[39m expert_data_to_eval_df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/local-blurred-captioning-exploration-4LZKhcfn/lib/python3.11/site-packages/pandas/core/reshape/merge.py:153\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mleft : DataFrame or named Series\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents=\u001b[32m0\u001b[39m)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmerge\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m     validate: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    151\u001b[39m ) -> DataFrame:\n\u001b[32m    152\u001b[39m     left_df = _validate_operand(left)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     right_df = \u001b[43m_validate_operand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m how == \u001b[33m\"\u001b[39m\u001b[33mcross\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[32m    156\u001b[39m             left_df,\n\u001b[32m    157\u001b[39m             right_df,\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/local-blurred-captioning-exploration-4LZKhcfn/lib/python3.11/site-packages/pandas/core/reshape/merge.py:2692\u001b[39m, in \u001b[36m_validate_operand\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m   2690\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.to_frame()\n\u001b[32m   2691\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2692\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   2693\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCan only merge Series or DataFrame objects, a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m was passed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2694\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: Can only merge Series or DataFrame objects, a <class 'list'> was passed"
     ]
    }
   ],
   "source": [
    "# get only the data we need for the expert file\n",
    "target_keys = [\n",
    "    \"image_id\",\n",
    "    \"file_name\",\n",
    "    \"vizwiz_url\",\n",
    "    \"text_detected\",\n",
    "    \"unrecognizable\",\n",
    "    \"framing\",\n",
    "    \"blur\",\n",
    "    \"obstruction\",\n",
    "    \"rotation\",\n",
    "    \"too dark\",\n",
    "    \"too bright\",\n",
    "    \"other\",\n",
    "    \"no issue\",\n",
    "]\n",
    "evaluation_data_expert = [\n",
    "    {x: y for x, y in image.items() if x in target_keys}\n",
    "    for image in evaluated_captions_data\n",
    "]\n",
    "\n",
    "# create an expert file to evaluate\n",
    "expert_data_to_eval_df = pd.DataFrame.from_dict(evaluation_data_expert)\n",
    "expert_data_to_eval_df = pd.merge(\n",
    "    expert_data_to_eval_df,\n",
    "    expert_captioned_data,\n",
    "    on=[\"file_name\", \"vizwiz_url\"],\n",
    "    how=\"right\",\n",
    ")\n",
    "del expert_data_to_eval_df[\"Image Preview\"]\n",
    "expert_data_to_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'expert_caption'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(expert_data_to_eval_dict):\n\u001b[32m     18\u001b[39m     matching_image = find_matching_image(image[\u001b[33m\"\u001b[39m\u001b[33mimage_id\u001b[39m\u001b[33m\"\u001b[39m], evaluated_captions_data)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     expert_caption = \u001b[43mimage\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexpert_caption\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     20\u001b[39m     captioning_challenge = image[\u001b[33m\"\u001b[39m\u001b[33mcaptioning_issue\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     21\u001b[39m     model_captions = matching_image[\u001b[33m\"\u001b[39m\u001b[33mmodel_captions\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mKeyError\u001b[39m: 'expert_caption'"
     ]
    }
   ],
   "source": [
    "# convert to a dict\n",
    "expert_data_to_eval_dict = expert_data_to_eval_df.to_dict(orient=\"records\")\n",
    "\n",
    "# sort dict by image_id\n",
    "expert_data_to_eval_dict = sorted(expert_data_to_eval_dict, key=lambda x: x[\"image_id\"])\n",
    "evaluated_captions_data = sorted(evaluated_captions_data, key=lambda x: x[\"image_id\"])\n",
    "\n",
    "\n",
    "def find_matching_image(image_id, data):\n",
    "    for image in data:\n",
    "        if image[\"image_id\"] == image_id:\n",
    "            return image\n",
    "    return None\n",
    "\n",
    "\n",
    "# add extra columns to the dict\n",
    "for index, image in enumerate(expert_data_to_eval_dict):\n",
    "    matching_image = find_matching_image(image[\"image_id\"], evaluated_captions_data)\n",
    "    expert_caption = image[\"expert_caption\"]\n",
    "    captioning_challenge = image[\"captioning_issue\"]\n",
    "    model_captions = matching_image[\"model_captions\"]\n",
    "\n",
    "    image[\"human_captions\"] = [\n",
    "        {\n",
    "            \"caption\": expert_caption.strip(),\n",
    "            \"captioning_issue\": captioning_challenge,\n",
    "        }\n",
    "    ]\n",
    "    image[\"model_captions\"] = model_captions\n",
    "    del image[\"expert_caption\"]\n",
    "    del image[\"captioning_issue\"]\n",
    "\n",
    "# save the dict\n",
    "with open(\n",
    "    f\"./intermediate-data/expert_data_{len(expert_data_to_eval_dict)}-images_{datetime.now().strftime('%Y-%m-%d_%H-%M')}.json\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    json.dump(expert_data_to_eval_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at subgroups for expert captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>image_preview</th>\n",
       "      <th>human_captions</th>\n",
       "      <th>annotator</th>\n",
       "      <th>notes</th>\n",
       "      <th>unable_to_verify</th>\n",
       "      <th>double code notes</th>\n",
       "      <th>double verified</th>\n",
       "      <th>gpt4o_caption</th>\n",
       "      <th>gpt4o_code</th>\n",
       "      <th>llama_caption</th>\n",
       "      <th>llama_code</th>\n",
       "      <th>molmo_caption</th>\n",
       "      <th>molmo_code</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>too bright</th>\n",
       "      <th>other</th>\n",
       "      <th>curved label</th>\n",
       "      <th>text panel</th>\n",
       "      <th>expert_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12066</td>\n",
       "      <td>VizWiz_train_00012066.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A Kroger grocery store tag for a caramel iced ...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>kroger iced carmel cake</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A caramel iced cake with a label featuring the...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a white label with the blue an...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a plastic container of apple c...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12884</td>\n",
       "      <td>VizWiz_train_00012884.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>The backside of a green plastic bottle with wo...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>nourishing shampoo</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>Green tube labeled \"Nourishing Shampoo\" with i...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a green tube with white text, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a green tube lying on its side...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8670</td>\n",
       "      <td>VizWiz_train_00008670.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A package of Kellogg's brand granola cereal wi...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>kellogg's low fat granola with raisens</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A box of Kelloggs Low Fat Granola with Raisin...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a box of Kellogg's Low Fat Gra...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a box of Kellogg's low-fat gra...</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13799</td>\n",
       "      <td>VizWiz_train_00013799.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A package for Macaroni and cheese on a kitchen...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>macaroni and cheese</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A food package with a label that includes part...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image appears to be a close-up of a person...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a box of Lipton iced tea. The ...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16729</td>\n",
       "      <td>VizWiz_train_00016729.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>the back of a Unilever brand product listing i...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>(Unilever) vasaline lotion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A bottle with a barcode and text showing ingre...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a white plastic bottle with a ...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a bottle of Vaseline lotion be...</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id                  file_name                                         vizwiz_url image_preview                                     human_captions   annotator                                   notes unable_to_verify double code notes double verified                                      gpt4o_caption gpt4o_code                                      llama_caption llama_code                                      molmo_caption molmo_code  text_detected  unrecognizable  framing  blur  obstruction  rotation  too dark  too bright  other curved label text panel expert_caption\n",
       "1      12066  VizWiz_train_00012066.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A Kroger grocery store tag for a caramel iced ...  Anne Marie                 kroger iced carmel cake                                                  x  A caramel iced cake with a label featuring the...        yes  The image shows a white label with the blue an...         no  The image shows a plastic container of apple c...         no           True               0        4     2            0         1         0           0      0                                       \n",
       "6      12884  VizWiz_train_00012884.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                The backside of a green plastic bottle with wo...  Anne Marie                      nourishing shampoo                                                  x  Green tube labeled \"Nourishing Shampoo\" with i...        yes  The image shows a green tube with white text, ...        yes  The image shows a green tube lying on its side...         no           True               0        1     0            0         4         0           0      0            x                          \n",
       "9       8670  VizWiz_train_00008670.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A package of Kellogg's brand granola cereal wi...  Anne Marie  kellogg's low fat granola with raisens                                                  x  A box of Kelloggs Low Fat Granola with Raisin...        yes  The image shows a box of Kellogg's Low Fat Gra...        yes  The image shows a box of Kellogg's low-fat gra...        yes           True               0        0     5            0         0         0           0      0                                       \n",
       "13     13799  VizWiz_train_00013799.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A package for Macaroni and cheese on a kitchen...  Anne Marie                     macaroni and cheese                                                  x  A food package with a label that includes part...         no  The image appears to be a close-up of a person...         no  The image shows a box of Lipton iced tea. The ...         no           True               0        4     5            1         1         0           1      0                                       \n",
       "17     16729  VizWiz_train_00016729.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                the back of a Unilever brand product listing i...  Anne Marie              (Unilever) vasaline lotion                                                  x  A bottle with a barcode and text showing ingre...         no  The image shows a white plastic bottle with a ...         no  The image shows a bottle of Vaseline lotion be...        yes           True               0        4     0            0         0         0           0      0                       x               "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_image_set = {x[\"image_id\"] for x in expert_captioned_data}\n",
    "expert_annotations_df = annotations_df[\n",
    "    (annotations_df[\"image_id\"].isin(expert_image_set))\n",
    "    & (annotations_df[\"unable_to_verify\"] == \"\")\n",
    "]\n",
    "print(len(expert_annotations_df))\n",
    "expert_annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Performance for bertscore ---\n",
      "gpt4o -- correct count = 185; incorrect count = 83\n",
      "[13799, 16729, 6341, 1646, 763, 5711, 4629, 5368, 14683, 15302, 18234, 20318, 13687, 11856, 2030, 2002, 15338, 1471, 16393, 16060, 944, 1950, 10733, 7498, 19322, 23160, 10504, 19212, 11989, 12265, 7632, 5209, 18833, 981, 7902, 6048, 12113, 20178, 6719, 8055, 5656, 14146, 16379, 3462, 21997, 10689, 13355, 15949, 9159, 13702, 2390, 14578, 11510, 9584, 18225, 4356, 20540, 143, 4474, 7866, 16052, 19303, 14975, 16007, 9718, 13286, 16479, 15240, 17913, 2015, 9831, 2294, 860, 10709, 21209, 3380, 3552, 3737, 6693, 3493, 2235, 17557, 5029]\n",
      "Performance Correct -- Avg Precision: 0.7629, Avg Recall: 0.6906\n",
      "Performance incorrect -- Avg Precision: 0.7449, Avg Recall: 0.6653\n",
      "\n",
      "llama -- correct count = 117; incorrect count = 151\n",
      "[12066, 13799, 16729, 6341, 1646, 763, 5711, 4629, 22396, 5368, 14683, 14321, 15302, 18234, 20318, 14833, 13687, 11856, 2030, 4191, 327, 5824, 7367, 15338, 1471, 1386, 16393, 15008, 9431, 16830, 16060, 944, 16570, 1404, 7185, 1950, 13189, 661, 17565, 3598, 17994, 19585, 20014, 11256, 10733, 21099, 10251, 15289, 8072, 5347, 1573, 7498, 10504, 19212, 3535, 18203, 4928, 7605, 13729, 10973, 12265, 10130, 7632, 5209, 18833, 981, 14116, 7902, 637, 16411, 2597, 16469, 12113, 2968, 14416, 20178, 6719, 20018, 9682, 14577, 8055, 5656, 9070, 14146, 16379, 20892, 17455, 10633, 3462, 21997, 10689, 13355, 1353, 15949, 9159, 11625, 11675, 13702, 2390, 20056, 14578, 14044, 11510, 9584, 18225, 4356, 20540, 6810, 143, 18152, 4474, 8760, 7473, 7866, 19486, 7285, 16052, 13070, 19303, 14975, 16007, 9718, 13286, 16479, 17585, 15240, 2015, 9831, 19761, 2294, 5941, 860, 21209, 13437, 2970, 189, 16316, 2948, 22131, 3380, 10309, 3552, 3737, 6693, 3493, 12650, 259, 2235, 422, 5029, 9975]\n",
      "Performance Correct -- Avg Precision: 0.6996, Avg Recall: 0.6588\n",
      "Performance incorrect -- Avg Precision: 0.6893, Avg Recall: 0.6522\n",
      "\n",
      "molmo -- correct count = 96; incorrect count = 172\n",
      "[12066, 12884, 13799, 6341, 1646, 763, 5711, 4629, 22396, 5368, 22462, 14683, 14321, 15302, 18234, 20318, 14833, 10570, 13687, 2030, 4191, 327, 5824, 7367, 15338, 5918, 7908, 1471, 903, 19515, 6910, 16393, 15008, 9431, 16830, 16060, 944, 13665, 16570, 1404, 1950, 5659, 11878, 13189, 661, 136, 17565, 19585, 2259, 11256, 7880, 14584, 13641, 15492, 21099, 8578, 10251, 15289, 8072, 5347, 1573, 16613, 7498, 23160, 10504, 19212, 3535, 17422, 18203, 4928, 11989, 7605, 14803, 13729, 10973, 14074, 7632, 5209, 981, 14116, 8263, 7902, 8078, 16411, 2597, 8833, 16469, 12113, 8836, 9046, 14416, 19604, 20178, 6719, 20018, 9682, 2350, 14577, 8055, 5656, 9070, 16379, 18471, 5781, 3462, 21997, 10689, 10336, 13355, 1353, 589, 7634, 4790, 9159, 11675, 13702, 2390, 20056, 6272, 14578, 2774, 14044, 11510, 9584, 4356, 20540, 143, 18152, 9299, 4474, 7473, 7866, 19486, 7285, 16052, 13070, 20818, 19303, 14975, 2004, 9718, 16479, 17585, 15240, 2015, 9831, 19761, 2294, 860, 10709, 21209, 13437, 2970, 189, 16316, 2948, 17782, 3324, 3380, 10309, 3552, 3737, 6693, 13313, 12827, 3493, 7032, 12650, 259, 422, 5029, 14006]\n",
      "Performance Correct -- Avg Precision: 0.7486, Avg Recall: 0.6707\n",
      "Performance incorrect -- Avg Precision: 0.7197, Avg Recall: 0.6403\n",
      "\n",
      "--- Performance for cap_f1 ---\n",
      "gpt4o -- correct count = 185; incorrect count = 83\n",
      "[13799, 16729, 6341, 1646, 763, 5711, 4629, 5368, 14683, 15302, 18234, 20318, 13687, 11856, 2030, 2002, 15338, 1471, 16393, 16060, 944, 1950, 10733, 7498, 19322, 23160, 10504, 19212, 11989, 12265, 7632, 5209, 18833, 981, 7902, 6048, 12113, 20178, 6719, 8055, 5656, 14146, 16379, 3462, 21997, 10689, 13355, 15949, 9159, 13702, 2390, 14578, 11510, 9584, 18225, 4356, 20540, 143, 4474, 7866, 16052, 19303, 14975, 16007, 9718, 13286, 16479, 15240, 17913, 2015, 9831, 2294, 860, 10709, 21209, 3380, 3552, 3737, 6693, 3493, 2235, 17557, 5029]\n",
      "Performance Correct -- Avg Precision: 0.7001, Avg Recall: 0.4607\n",
      "Performance incorrect -- Avg Precision: 0.7014, Avg Recall: 0.4455\n",
      "\n",
      "llama -- correct count = 117; incorrect count = 151\n",
      "[12066, 13799, 16729, 6341, 1646, 763, 5711, 4629, 22396, 5368, 14683, 14321, 15302, 18234, 20318, 14833, 13687, 11856, 2030, 4191, 327, 5824, 7367, 15338, 1471, 1386, 16393, 15008, 9431, 16830, 16060, 944, 16570, 1404, 7185, 1950, 13189, 661, 17565, 3598, 17994, 19585, 20014, 11256, 10733, 21099, 10251, 15289, 8072, 5347, 1573, 7498, 10504, 19212, 3535, 18203, 4928, 7605, 13729, 10973, 12265, 10130, 7632, 5209, 18833, 981, 14116, 7902, 637, 16411, 2597, 16469, 12113, 2968, 14416, 20178, 6719, 20018, 9682, 14577, 8055, 5656, 9070, 14146, 16379, 20892, 17455, 10633, 3462, 21997, 10689, 13355, 1353, 15949, 9159, 11625, 11675, 13702, 2390, 20056, 14578, 14044, 11510, 9584, 18225, 4356, 20540, 6810, 143, 18152, 4474, 8760, 7473, 7866, 19486, 7285, 16052, 13070, 19303, 14975, 16007, 9718, 13286, 16479, 17585, 15240, 2015, 9831, 19761, 2294, 5941, 860, 21209, 13437, 2970, 189, 16316, 2948, 22131, 3380, 10309, 3552, 3737, 6693, 3493, 12650, 259, 2235, 422, 5029, 9975]\n",
      "Performance Correct -- Avg Precision: 0.5080, Avg Recall: 0.3719\n",
      "Performance incorrect -- Avg Precision: 0.4579, Avg Recall: 0.3299\n",
      "\n",
      "molmo -- correct count = 96; incorrect count = 172\n",
      "[12066, 12884, 13799, 6341, 1646, 763, 5711, 4629, 22396, 5368, 22462, 14683, 14321, 15302, 18234, 20318, 14833, 10570, 13687, 2030, 4191, 327, 5824, 7367, 15338, 5918, 7908, 1471, 903, 19515, 6910, 16393, 15008, 9431, 16830, 16060, 944, 13665, 16570, 1404, 1950, 5659, 11878, 13189, 661, 136, 17565, 19585, 2259, 11256, 7880, 14584, 13641, 15492, 21099, 8578, 10251, 15289, 8072, 5347, 1573, 16613, 7498, 23160, 10504, 19212, 3535, 17422, 18203, 4928, 11989, 7605, 14803, 13729, 10973, 14074, 7632, 5209, 981, 14116, 8263, 7902, 8078, 16411, 2597, 8833, 16469, 12113, 8836, 9046, 14416, 19604, 20178, 6719, 20018, 9682, 2350, 14577, 8055, 5656, 9070, 16379, 18471, 5781, 3462, 21997, 10689, 10336, 13355, 1353, 589, 7634, 4790, 9159, 11675, 13702, 2390, 20056, 6272, 14578, 2774, 14044, 11510, 9584, 4356, 20540, 143, 18152, 9299, 4474, 7473, 7866, 19486, 7285, 16052, 13070, 20818, 19303, 14975, 2004, 9718, 16479, 17585, 15240, 2015, 9831, 19761, 2294, 860, 10709, 21209, 13437, 2970, 189, 16316, 2948, 17782, 3324, 3380, 10309, 3552, 3737, 6693, 13313, 12827, 3493, 7032, 12650, 259, 422, 5029, 14006]\n",
      "Performance Correct -- Avg Precision: 0.5888, Avg Recall: 0.3622\n",
      "Performance incorrect -- Avg Precision: 0.4672, Avg Recall: 0.2610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# expert annotations\n",
    "for metric in [\"bertscore\", \"cap_f1\"]:\n",
    "    print(f\"--- Performance for {metric} ---\")\n",
    "    for model, model_short_name in MODEL_NAMES.items():\n",
    "        correct_predictions = expert_annotations_df[\n",
    "            expert_annotations_df[f\"{model_short_name}_code\"] != \"no\"\n",
    "        ]\n",
    "        ids_for_correct = list(correct_predictions[\"image_id\"])\n",
    "\n",
    "        incorrect_predictions = expert_annotations_df[\n",
    "            expert_annotations_df[f\"{model_short_name}_code\"] == \"no\"\n",
    "        ]\n",
    "        ids_for_incorrect = list(incorrect_predictions[\"image_id\"])\n",
    "        print(\n",
    "            f\"{model_short_name} -- correct count = {len(ids_for_correct)}; incorrect count = {len(ids_for_incorrect)}\"\n",
    "        )\n",
    "        print(ids_for_incorrect)\n",
    "\n",
    "        # filter expert captioned data\n",
    "        filted_expert_data_correct = [\n",
    "            x for x in expert_captioned_data if x[\"image_id\"] in ids_for_correct\n",
    "        ]\n",
    "        filted_expert_data_incorrect = [\n",
    "            x for x in expert_captioned_data if x[\"image_id\"] in ids_for_incorrect\n",
    "        ]\n",
    "\n",
    "        # print metrics\n",
    "        performance_correct = compute_average_metrics(\n",
    "            filted_expert_data_correct, metric\n",
    "        )[model]\n",
    "        performance_incorrect = compute_average_metrics(\n",
    "            filted_expert_data_incorrect, metric\n",
    "        )[model]\n",
    "\n",
    "        # print\n",
    "        print(\n",
    "            f\"Performance Correct -- Avg Precision: {performance_correct['avg_precision']:.4f}, Avg Recall: {performance_correct['avg_recall']:.4f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Performance incorrect -- Avg Precision: {performance_incorrect['avg_precision']:.4f}, Avg Recall: {performance_incorrect['avg_recall']:.4f}\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>image_preview</th>\n",
       "      <th>human_captions</th>\n",
       "      <th>annotator</th>\n",
       "      <th>notes</th>\n",
       "      <th>unable_to_verify</th>\n",
       "      <th>double code notes</th>\n",
       "      <th>double verified</th>\n",
       "      <th>gpt4o_caption</th>\n",
       "      <th>gpt4o_code</th>\n",
       "      <th>llama_caption</th>\n",
       "      <th>llama_code</th>\n",
       "      <th>molmo_caption</th>\n",
       "      <th>molmo_code</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>too bright</th>\n",
       "      <th>other</th>\n",
       "      <th>curved label</th>\n",
       "      <th>text panel</th>\n",
       "      <th>expert_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12066</td>\n",
       "      <td>VizWiz_train_00012066.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A Kroger grocery store tag for a caramel iced ...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>kroger iced carmel cake</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A caramel iced cake with a label featuring the...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a white label with the blue an...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a plastic container of apple c...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12884</td>\n",
       "      <td>VizWiz_train_00012884.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>The backside of a green plastic bottle with wo...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>nourishing shampoo</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>Green tube labeled \"Nourishing Shampoo\" with i...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a green tube with white text, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a green tube lying on its side...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8670</td>\n",
       "      <td>VizWiz_train_00008670.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A package of Kellogg's brand granola cereal wi...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>kellogg's low fat granola with raisens</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A box of Kelloggs Low Fat Granola with Raisin...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a box of Kellogg's Low Fat Gra...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a box of Kellogg's low-fat gra...</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13799</td>\n",
       "      <td>VizWiz_train_00013799.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A package for Macaroni and cheese on a kitchen...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>macaroni and cheese</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A food package with a label that includes part...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image appears to be a close-up of a person...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a box of Lipton iced tea. The ...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16729</td>\n",
       "      <td>VizWiz_train_00016729.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>the back of a Unilever brand product listing i...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>(Unilever) vasaline lotion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A bottle with a barcode and text showing ingre...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a white plastic bottle with a ...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a bottle of Vaseline lotion be...</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id                  file_name                                         vizwiz_url image_preview                                     human_captions   annotator                                   notes unable_to_verify double code notes double verified                                      gpt4o_caption gpt4o_code                                      llama_caption llama_code                                      molmo_caption molmo_code  text_detected  unrecognizable  framing  blur  obstruction  rotation  too dark  too bright  other curved label text panel expert_caption\n",
       "1      12066  VizWiz_train_00012066.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A Kroger grocery store tag for a caramel iced ...  Anne Marie                 kroger iced carmel cake                                                  x  A caramel iced cake with a label featuring the...        yes  The image shows a white label with the blue an...         no  The image shows a plastic container of apple c...         no           True               0        4     2            0         1         0           0      0                                       \n",
       "6      12884  VizWiz_train_00012884.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                The backside of a green plastic bottle with wo...  Anne Marie                      nourishing shampoo                                                  x  Green tube labeled \"Nourishing Shampoo\" with i...        yes  The image shows a green tube with white text, ...        yes  The image shows a green tube lying on its side...         no           True               0        1     0            0         4         0           0      0            x                          \n",
       "9       8670  VizWiz_train_00008670.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A package of Kellogg's brand granola cereal wi...  Anne Marie  kellogg's low fat granola with raisens                                                  x  A box of Kelloggs Low Fat Granola with Raisin...        yes  The image shows a box of Kellogg's Low Fat Gra...        yes  The image shows a box of Kellogg's low-fat gra...        yes           True               0        0     5            0         0         0           0      0                                       \n",
       "13     13799  VizWiz_train_00013799.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A package for Macaroni and cheese on a kitchen...  Anne Marie                     macaroni and cheese                                                  x  A food package with a label that includes part...         no  The image appears to be a close-up of a person...         no  The image shows a box of Lipton iced tea. The ...         no           True               0        4     5            1         1         0           1      0                                       \n",
       "17     16729  VizWiz_train_00016729.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                the back of a Unilever brand product listing i...  Anne Marie              (Unilever) vasaline lotion                                                  x  A bottle with a barcode and text showing ingre...         no  The image shows a white plastic bottle with a ...         no  The image shows a bottle of Vaseline lotion be...        yes           True               0        4     0            0         0         0           0      0                       x               "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on the same dataset, look at crowdworker annotations\n",
    "crowdworker_annotations_df = annotations_df[\n",
    "    (annotations_df[\"image_id\"].isin(expert_image_set))\n",
    "    & (annotations_df[\"unable_to_verify\"] == \"\")\n",
    "]\n",
    "print(len(crowdworker_annotations_df))\n",
    "crowdworker_annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Performance for bertscore ---\n",
      "gpt4o -- correct count = 185 (69%); incorrect count = 83 (31%)\n",
      "Performance Correct -- Avg Precision: 0.6398, Avg Recall: 0.7958\n",
      "Performance incorrect -- Avg Precision: 0.6377, Avg Recall: 0.7692\n",
      "\n",
      "llama -- correct count = 117 (44%); incorrect count = 151 (56%)\n",
      "Performance Correct -- Avg Precision: 0.5921, Avg Recall: 0.7603\n",
      "Performance incorrect -- Avg Precision: 0.5946, Avg Recall: 0.7402\n",
      "\n",
      "molmo -- correct count = 96 (36%); incorrect count = 172 (64%)\n",
      "Performance Correct -- Avg Precision: 0.6638, Avg Recall: 0.8006\n",
      "Performance incorrect -- Avg Precision: 0.6448, Avg Recall: 0.7676\n",
      "\n",
      "--- Performance for cap_f1 ---\n",
      "gpt4o -- correct count = 185 (69%); incorrect count = 83 (31%)\n",
      "Performance Correct -- Avg Precision: 0.5186, Avg Recall: 0.4206\n",
      "Performance incorrect -- Avg Precision: 0.5018, Avg Recall: 0.3407\n",
      "\n",
      "llama -- correct count = 117 (44%); incorrect count = 151 (56%)\n",
      "Performance Correct -- Avg Precision: 0.4062, Avg Recall: 0.4000\n",
      "Performance incorrect -- Avg Precision: 0.3571, Avg Recall: 0.2903\n",
      "\n",
      "molmo -- correct count = 96 (36%); incorrect count = 172 (64%)\n",
      "Performance Correct -- Avg Precision: 0.5134, Avg Recall: 0.4085\n",
      "Performance incorrect -- Avg Precision: 0.4203, Avg Recall: 0.2765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for metric in [\"bertscore\", \"cap_f1\"]:\n",
    "    print(f\"--- Performance for {metric} ---\")\n",
    "    for model, model_short_name in MODEL_NAMES.items():\n",
    "        correct_predictions = crowdworker_annotations_df[\n",
    "            crowdworker_annotations_df[f\"{model_short_name}_code\"] != \"no\"\n",
    "        ]\n",
    "        ids_for_correct = list(correct_predictions[\"image_id\"])\n",
    "\n",
    "        incorrect_predictions = crowdworker_annotations_df[\n",
    "            crowdworker_annotations_df[f\"{model_short_name}_code\"] == \"no\"\n",
    "        ]\n",
    "        ids_for_incorrect = list(incorrect_predictions[\"image_id\"])\n",
    "        print(\n",
    "            f\"{model_short_name} -- correct count = {len(ids_for_correct)} ({100 * len(ids_for_correct) / len(crowdworker_annotations_df):.0f}%); incorrect count = {len(ids_for_incorrect)} ({100 * len(ids_for_incorrect) / len(crowdworker_annotations_df):.0f}%)\"\n",
    "        )\n",
    "        # print(ids_for_incorrect)\n",
    "\n",
    "        # filter crowdworker captioned data\n",
    "        filted_crowdworker_data_correct = [\n",
    "            x for x in evaluated_captions_data if x[\"image_id\"] in ids_for_correct\n",
    "        ]\n",
    "        filted_crowdworker_data_incorrect = [\n",
    "            x for x in evaluated_captions_data if x[\"image_id\"] in ids_for_incorrect\n",
    "        ]\n",
    "\n",
    "        # print metrics\n",
    "        performance_correct = compute_average_metrics(\n",
    "            filted_crowdworker_data_correct, metric\n",
    "        )[model]\n",
    "        performance_incorrect = compute_average_metrics(\n",
    "            filted_crowdworker_data_incorrect, metric\n",
    "        )[model]\n",
    "\n",
    "        # print\n",
    "        print(\n",
    "            f\"Performance Correct -- Avg Precision: {performance_correct['avg_precision']:.4f}, Avg Recall: {performance_correct['avg_recall']:.4f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Performance incorrect -- Avg Precision: {performance_incorrect['avg_precision']:.4f}, Avg Recall: {performance_incorrect['avg_recall']:.4f}\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-08-06': 'gpt4o',\n",
       " 'Llama-3.2-11B-Vision-Instruct': 'llama',\n",
       " 'Molmo-7B-O-0924': 'molmo'}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=5432, minmax=(np.float64(0.3801501393318176), np.float64(0.90423983335495)), mean=np.float64(0.6410437088092139), variance=np.float64(0.00351636410091269), skewness=np.float64(0.13506593282533155), kurtosis=np.float64(0.38863508604686503))\n",
      "DescribeResult(nobs=5432, minmax=(np.float64(0.5880314707756042), np.float64(0.9440022110939026)), mean=np.float64(0.7789125641443065), variance=np.float64(0.002378888823964874), skewness=np.float64(-0.10485067445019737), kurtosis=np.float64(-0.09655775360738117))\n",
      "\n",
      "DescribeResult(nobs=5432, minmax=(np.float64(0.18891480565071106), np.float64(0.8394327163696289)), mean=np.float64(0.6055959118296981), variance=np.float64(0.0028518755754962633), skewness=np.float64(-0.05755974845593788), kurtosis=np.float64(0.9191530939957211))\n",
      "DescribeResult(nobs=5432, minmax=(np.float64(0.5791395902633667), np.float64(0.8977669477462769)), mean=np.float64(0.7485131648244318), variance=np.float64(0.002095130992444404), skewness=np.float64(-0.004731030420948404), kurtosis=np.float64(-0.03372707051547463))\n",
      "\n",
      "DescribeResult(nobs=5432, minmax=(np.float64(0.45671236515045166), np.float64(0.8330786824226379)), mean=np.float64(0.6515604777149143), variance=np.float64(0.002435263382471827), skewness=np.float64(-0.025090048556009187), kurtosis=np.float64(0.2756568894027298))\n",
      "DescribeResult(nobs=5432, minmax=(np.float64(0.5999084711074829), np.float64(0.9167557954788208)), mean=np.float64(0.7760883432666227), variance=np.float64(0.0021158568795428896), skewness=np.float64(-0.13117391244654), kurtosis=np.float64(-0.13425293690367512))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in MODEL_NAMES.keys():\n",
    "    bert_precisions = [\n",
    "        x[\"evaluation\"][\"bertscore\"][model][\"precision\"]\n",
    "        for x in evaluated_captions_data\n",
    "    ]\n",
    "    bert_recalls = [\n",
    "        x[\"evaluation\"][\"bertscore\"][model][\"recall\"] for x in evaluated_captions_data\n",
    "    ]\n",
    "    print(stats.describe(bert_precisions))\n",
    "    print(stats.describe(bert_recalls))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_NAMES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[43mMODEL_NAMES\u001b[49m.keys():\n\u001b[32m      2\u001b[39m     cap_f1_precisions = [\n\u001b[32m      3\u001b[39m         x[\u001b[33m\"\u001b[39m\u001b[33mevaluation\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcap_f1\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mscores\u001b[39m\u001b[33m\"\u001b[39m][model][\u001b[33m\"\u001b[39m\u001b[33mprecision\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      4\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m evaluated_captions_data\n\u001b[32m      5\u001b[39m     ]\n\u001b[32m      6\u001b[39m     cap_f1_recalls = [\n\u001b[32m      7\u001b[39m         x[\u001b[33m\"\u001b[39m\u001b[33mevaluation\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcap_f1\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mscores\u001b[39m\u001b[33m\"\u001b[39m][model][\u001b[33m\"\u001b[39m\u001b[33mrecall\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      8\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m evaluated_captions_data\n\u001b[32m      9\u001b[39m     ]\n",
      "\u001b[31mNameError\u001b[39m: name 'MODEL_NAMES' is not defined"
     ]
    }
   ],
   "source": [
    "for model in MODEL_NAMES.keys():\n",
    "    cap_f1_precisions = [\n",
    "        x[\"evaluation\"][\"cap_f1\"][\"scores\"][model][\"precision\"]\n",
    "        for x in evaluated_captions_data\n",
    "    ]\n",
    "    cap_f1_recalls = [\n",
    "        x[\"evaluation\"][\"cap_f1\"][\"scores\"][model][\"recall\"]\n",
    "        for x in evaluated_captions_data\n",
    "    ]\n",
    "    print(stats.describe(cap_f1_precisions))\n",
    "    print(stats.describe(cap_f1_recalls))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-blurred-captioning-exploration-4LZKhcfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
