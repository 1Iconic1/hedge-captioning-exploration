{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study 2 Analysis\n",
    "Analyses for each research question in Study 2. These analyses are done with the newest setup of the project where the researchers annotate whether VLMs accurately identified the product in images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import statistics as s\n",
    "from scipy import stats\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality_metrics(df, reference_df=None, quality_columns=None):\n",
    "    \"\"\"\n",
    "    Calculate quality issue counts and optionally percentages compared to a reference dataset.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame containing the quality issues data\n",
    "        reference_df: Optional reference DataFrame to calculate percentages against\n",
    "        quality_columns: List of quality issue column names. If None, uses default columns\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with quality counts, and optionally percentages if reference_df is provided\n",
    "    \"\"\"\n",
    "    if quality_columns is None:\n",
    "        quality_columns = [\n",
    "            \"unrecognizable\",\n",
    "            \"blur\",\n",
    "            \"framing\",\n",
    "            \"obstruction\",\n",
    "            \"rotation\",\n",
    "            \"too dark\",\n",
    "            \"too bright\",\n",
    "            \"other\",\n",
    "        ]\n",
    "\n",
    "    # Calculate counts\n",
    "    quality_counts = pd.concat(\n",
    "        [df[col].value_counts() for col in quality_columns], axis=1\n",
    "    )\n",
    "    quality_counts.columns = quality_columns\n",
    "\n",
    "    # Replace NaN with 0 and convert to int\n",
    "    quality_counts = quality_counts.fillna(0).astype(int)\n",
    "\n",
    "    # sort index from 0 to 5\n",
    "    quality_counts = quality_counts.sort_index()\n",
    "\n",
    "    # Add total row\n",
    "    quality_counts.loc[\"total\"] = quality_counts.sum()\n",
    "\n",
    "    # Calculate percentages if reference DataFrame is provided\n",
    "    if reference_df is not None:\n",
    "        reference_counts = calculate_quality_metrics(\n",
    "            reference_df, quality_columns=quality_columns\n",
    "        )\n",
    "        quality_percentages = quality_counts.div(reference_counts, axis=0) * 100\n",
    "        return quality_percentages.round(2)\n",
    "\n",
    "    return quality_counts\n",
    "\n",
    "\n",
    "def combine_counts_and_percentages(counts_df, percentages_df=None):\n",
    "    \"\"\"\n",
    "    Combines counts and percentages into a single DataFrame with formatted strings.\n",
    "\n",
    "    Args:\n",
    "        counts_df: DataFrame containing the counts\n",
    "        percentages_df: Optional DataFrame containing percentages. If None, percentages\n",
    "                       will be calculated using the total row of counts_df\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with formatted strings combining counts and percentages\n",
    "    \"\"\"\n",
    "    # Calculate percentages if not provided\n",
    "    if percentages_df is None:\n",
    "        percentages_df = (counts_df.div(counts_df.loc[\"total\"], axis=1) * 100).round(2)\n",
    "\n",
    "    def format_count_and_percentage(count, percentage):\n",
    "        count_str = (\n",
    "            str(int(float(count))) if float(count).is_integer() else str(float(count))\n",
    "        )\n",
    "        return f\"{count_str} ({percentage:.2f}%)\"\n",
    "\n",
    "    # Create combined DataFrame\n",
    "    combined_stats = pd.DataFrame(\n",
    "        [\n",
    "            [\n",
    "                format_count_and_percentage(count, pct)\n",
    "                for count, pct in zip(row_counts, row_pcts)\n",
    "            ]\n",
    "            for row_counts, row_pcts in zip(counts_df.values, percentages_df.values)\n",
    "        ],\n",
    "        index=counts_df.index,\n",
    "        columns=counts_df.columns,\n",
    "    )\n",
    "\n",
    "    return combined_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = {\n",
    "    \"gpt-4o-2024-08-06\": \"gpt4o\",\n",
    "    \"Llama-3.2-11B-Vision-Instruct\": \"llama\",\n",
    "    \"Molmo-7B-O-0924\": \"molmo\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "We load 3 pieces of data:\n",
    "1. A `.json` file with all images that fit our study conditions, their model captions, and evaluation metrics.\n",
    "2. A `.csv` that has annotations from the research team noting what captions accurately identify products.\n",
    "3. A `.csv` with expert captions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) load images with model captions and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of evaluated captions: 5432\n",
      "{\n",
      "    \"image_id\": 1,\n",
      "    \"file_name\": \"VizWiz_train_00000001.jpg\",\n",
      "    \"vizwiz_url\": \"https://vizwiz.cs.colorado.edu/VizWiz_visualization_img/VizWiz_train_00000001.jpg\",\n",
      "    \"text_detected\": true,\n",
      "    \"unrecognizable\": 0,\n",
      "    \"framing\": 0,\n",
      "    \"blur\": 5,\n",
      "    \"obstruction\": 0,\n",
      "    \"rotation\": 0,\n",
      "    \"too dark\": 0,\n",
      "    \"too bright\": 0,\n",
      "    \"other\": 0,\n",
      "    \"no issue\": 0,\n",
      "    \"human_captions\": [\n",
      "        {\n",
      "            \"caption\": \"A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.\",\n",
      "            \"is_precanned\": false,\n",
      "            \"is_rejected\": false\n",
      "        },\n",
      "        {\n",
      "            \"caption\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\",\n",
      "            \"is_precanned\": false,\n",
      "            \"is_rejected\": false\n",
      "        },\n",
      "        {\n",
      "            \"caption\": \"A kitchen counter the various items on top including a can of Coca-Cola, metal containers, and a teapot.\",\n",
      "            \"is_precanned\": false,\n",
      "            \"is_rejected\": false\n",
      "        },\n",
      "        {\n",
      "            \"caption\": \"a black tin of Coca Cola placed on a black surface\",\n",
      "            \"is_precanned\": false,\n",
      "            \"is_rejected\": false\n",
      "        },\n",
      "        {\n",
      "            \"caption\": \"Black counter with canisters, kettle and can of soda.\",\n",
      "            \"is_precanned\": false,\n",
      "            \"is_rejected\": false\n",
      "        }\n",
      "    ],\n",
      "    \"model_captions\": [\n",
      "        {\n",
      "            \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "            \"caption\": \"A can of Coca-Cola Zero is on a kitchen countertop, next to a white mug and a black kettle. Three silver canisters are aligned against the wall, along with a visible electrical outlet above them.\"\n",
      "        },\n",
      "        {\n",
      "            \"model_name\": \"Llama-3.2-11B-Vision-Instruct\",\n",
      "            \"caption\": \"The image shows a black can with a yellow band and red writing, likely a beverage can, on a kitchen counter. The can has a white label with indistinct writing.\"\n",
      "        },\n",
      "        {\n",
      "            \"model_name\": \"Molmo-7B-O-0924\",\n",
      "            \"caption\": \"A black and yellow can of Coca-Cola is prominently displayed on a black countertop. The can features the Coca-Cola logo in red and white text.\"\n",
      "        }\n",
      "    ],\n",
      "    \"evaluation\": {\n",
      "        \"bleu-1\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"bleu\": 0.48717948717948717,\n",
      "                \"precisions\": [\n",
      "                    0.48717948717948717\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 3.5454545454545454,\n",
      "                \"translation_length\": 39,\n",
      "                \"reference_length\": 11\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"bleu\": 0.38235294117647056,\n",
      "                \"precisions\": [\n",
      "                    0.38235294117647056\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 3.090909090909091,\n",
      "                \"translation_length\": 34,\n",
      "                \"reference_length\": 11\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"bleu\": 0.48148148148148145,\n",
      "                \"precisions\": [\n",
      "                    0.48148148148148145\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 2.4545454545454546,\n",
      "                \"translation_length\": 27,\n",
      "                \"reference_length\": 11\n",
      "            }\n",
      "        },\n",
      "        \"bleu-2\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"bleu\": 0.29957234475763905,\n",
      "                \"precisions\": [\n",
      "                    0.48717948717948717,\n",
      "                    0.18421052631578946\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 3.5454545454545454,\n",
      "                \"translation_length\": 39,\n",
      "                \"reference_length\": 11\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"bleu\": 0.21528077260102307,\n",
      "                \"precisions\": [\n",
      "                    0.38235294117647056,\n",
      "                    0.12121212121212122\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 3.090909090909091,\n",
      "                \"translation_length\": 34,\n",
      "                \"reference_length\": 11\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"bleu\": 0.3042903097250923,\n",
      "                \"precisions\": [\n",
      "                    0.48148148148148145,\n",
      "                    0.19230769230769232\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 2.4545454545454546,\n",
      "                \"translation_length\": 27,\n",
      "                \"reference_length\": 11\n",
      "            }\n",
      "        },\n",
      "        \"bleu-3\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"bleu\": 0.16928191745772345,\n",
      "                \"precisions\": [\n",
      "                    0.48717948717948717,\n",
      "                    0.18421052631578946,\n",
      "                    0.05405405405405406\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 3.5454545454545454,\n",
      "                \"translation_length\": 39,\n",
      "                \"reference_length\": 11\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"bleu\": 0.0,\n",
      "                \"precisions\": [\n",
      "                    0.38235294117647056,\n",
      "                    0.12121212121212122,\n",
      "                    0.0\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 3.090909090909091,\n",
      "                \"translation_length\": 34,\n",
      "                \"reference_length\": 11\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"bleu\": 0.19493451588085775,\n",
      "                \"precisions\": [\n",
      "                    0.48148148148148145,\n",
      "                    0.19230769230769232,\n",
      "                    0.08\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 2.4545454545454546,\n",
      "                \"translation_length\": 27,\n",
      "                \"reference_length\": 11\n",
      "            }\n",
      "        },\n",
      "        \"bleu-4\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"bleu\": 0.0,\n",
      "                \"precisions\": [\n",
      "                    0.48717948717948717,\n",
      "                    0.18421052631578946,\n",
      "                    0.05405405405405406,\n",
      "                    0.0\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 3.5454545454545454,\n",
      "                \"translation_length\": 39,\n",
      "                \"reference_length\": 11\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"bleu\": 0.0,\n",
      "                \"precisions\": [\n",
      "                    0.38235294117647056,\n",
      "                    0.12121212121212122,\n",
      "                    0.0,\n",
      "                    0.0\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 3.090909090909091,\n",
      "                \"translation_length\": 34,\n",
      "                \"reference_length\": 11\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"bleu\": 0.0,\n",
      "                \"precisions\": [\n",
      "                    0.48148148148148145,\n",
      "                    0.19230769230769232,\n",
      "                    0.08,\n",
      "                    0.0\n",
      "                ],\n",
      "                \"brevity_penalty\": 1.0,\n",
      "                \"length_ratio\": 2.4545454545454546,\n",
      "                \"translation_length\": 27,\n",
      "                \"reference_length\": 11\n",
      "            }\n",
      "        },\n",
      "        \"meteor\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"meteor\": 0.42315262122025415\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"meteor\": 0.33087319382162433\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"meteor\": 0.503725299643667\n",
      "            }\n",
      "        },\n",
      "        \"rouge\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"rouge1\": 0.4000000000000001,\n",
      "                \"rouge2\": 0.23529411764705876,\n",
      "                \"rougeL\": 0.33962264150943394,\n",
      "                \"rougeLsum\": 0.33962264150943394\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"rouge1\": 0.3673469387755102,\n",
      "                \"rouge2\": 0.1276595744680851,\n",
      "                \"rougeL\": 0.2857142857142857,\n",
      "                \"rougeLsum\": 0.2857142857142857\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"rouge1\": 0.45454545454545453,\n",
      "                \"rouge2\": 0.2777777777777778,\n",
      "                \"rougeL\": 0.45454545454545453,\n",
      "                \"rougeLsum\": 0.45454545454545453\n",
      "            }\n",
      "        },\n",
      "        \"cider\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"score\": 0.0037823278003754957\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"score\": 0.033202632588137\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"score\": 0.0910111360233031\n",
      "            }\n",
      "        },\n",
      "        \"spice\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"All\": {\n",
      "                    \"pr\": 0.13636363636363635,\n",
      "                    \"re\": 0.07692307692307693,\n",
      "                    \"f\": 0.09836065573770493,\n",
      "                    \"fn\": 36.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 19.0,\n",
      "                    \"tp\": 3.0\n",
      "                },\n",
      "                \"Relation\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 13.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 5.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Cardinality\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 1.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Attribute\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 13.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 8.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Size\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Color\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 3.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 2.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Object\": {\n",
      "                    \"pr\": 0.3333333333333333,\n",
      "                    \"re\": 0.23076923076923078,\n",
      "                    \"f\": 0.27272727272727276,\n",
      "                    \"fn\": 10.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 6.0,\n",
      "                    \"tp\": 3.0\n",
      "                }\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"All\": {\n",
      "                    \"pr\": 0.2222222222222222,\n",
      "                    \"re\": 0.10256410256410256,\n",
      "                    \"f\": 0.14035087719298245,\n",
      "                    \"fn\": 35.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 14.0,\n",
      "                    \"tp\": 4.0\n",
      "                },\n",
      "                \"Relation\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 13.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 6.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Cardinality\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Attribute\": {\n",
      "                    \"pr\": 0.2,\n",
      "                    \"re\": 0.07692307692307693,\n",
      "                    \"f\": 0.1111111111111111,\n",
      "                    \"fn\": 12.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 4.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Size\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Color\": {\n",
      "                    \"pr\": 0.25,\n",
      "                    \"re\": 0.3333333333333333,\n",
      "                    \"f\": 0.28571428571428575,\n",
      "                    \"fn\": 2.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 3.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Object\": {\n",
      "                    \"pr\": 0.42857142857142855,\n",
      "                    \"re\": 0.23076923076923078,\n",
      "                    \"f\": 0.3,\n",
      "                    \"fn\": 10.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 4.0,\n",
      "                    \"tp\": 3.0\n",
      "                }\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"All\": {\n",
      "                    \"pr\": 0.14285714285714285,\n",
      "                    \"re\": 0.05128205128205128,\n",
      "                    \"f\": 0.07547169811320754,\n",
      "                    \"fn\": 37.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 12.0,\n",
      "                    \"tp\": 2.0\n",
      "                },\n",
      "                \"Relation\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 13.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 3.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Cardinality\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Attribute\": {\n",
      "                    \"pr\": 0.16666666666666666,\n",
      "                    \"re\": 0.07692307692307693,\n",
      "                    \"f\": 0.10526315789473684,\n",
      "                    \"fn\": 12.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 5.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Size\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Color\": {\n",
      "                    \"pr\": 0.2,\n",
      "                    \"re\": 0.3333333333333333,\n",
      "                    \"f\": 0.25,\n",
      "                    \"fn\": 2.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 4.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Object\": {\n",
      "                    \"pr\": 0.2,\n",
      "                    \"re\": 0.07692307692307693,\n",
      "                    \"f\": 0.1111111111111111,\n",
      "                    \"fn\": 12.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 4.0,\n",
      "                    \"tp\": 1.0\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"bertscore\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"precision\": 0.6953459978103638,\n",
      "                \"recall\": 0.800594687461853,\n",
      "                \"f1\": 0.7392169237136841,\n",
      "                \"best_ref_indices\": [\n",
      "                    1,\n",
      "                    4,\n",
      "                    1\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\",\n",
      "                    \"recall_reference\": \"Black counter with canisters, kettle and can of soda.\",\n",
      "                    \"f1_reference\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\"\n",
      "                }\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"precision\": 0.5674580931663513,\n",
      "                \"recall\": 0.6933881044387817,\n",
      "                \"f1\": 0.6142570972442627,\n",
      "                \"best_ref_indices\": [\n",
      "                    1,\n",
      "                    3,\n",
      "                    1\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\",\n",
      "                    \"recall_reference\": \"a black tin of Coca Cola placed on a black surface\",\n",
      "                    \"f1_reference\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\"\n",
      "                }\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"precision\": 0.680425226688385,\n",
      "                \"recall\": 0.796323299407959,\n",
      "                \"f1\": 0.7177727818489075,\n",
      "                \"best_ref_indices\": [\n",
      "                    1,\n",
      "                    3,\n",
      "                    3\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\",\n",
      "                    \"recall_reference\": \"a black tin of Coca Cola placed on a black surface\",\n",
      "                    \"f1_reference\": \"a black tin of Coca Cola placed on a black surface\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"clipscore\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"score\": 0.86474609375\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"score\": 0.75\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"score\": 0.7216796875\n",
      "            }\n",
      "        },\n",
      "        \"clipscore_ref\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"score\": 0.81640625\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"score\": 0.73828125\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"score\": 0.71142578125\n",
      "            }\n",
      "        },\n",
      "        \"cap_f1\": {\n",
      "            \"parsed_atomics\": [\n",
      "                \"There is a can of Coca Cola.\",\n",
      "                \"The can is on a counter.\",\n",
      "                \"There is a can on the counter.\",\n",
      "                \"The can is black.\",\n",
      "                \"The can is of Coca Cola Zero calorie soda.\",\n",
      "                \"The can is near the coffee maker.\",\n",
      "                \"There is a kitchen counter.\",\n",
      "                \"There are various items on the kitchen counter.\",\n",
      "                \"There is a can of Coca-Cola on the kitchen counter.\",\n",
      "                \"There are metal containers on the kitchen counter.\",\n",
      "                \"There is a teapot on the kitchen counter.\",\n",
      "                \"There is a tin.\",\n",
      "                \"The tin is black.\",\n",
      "                \"The tin is of Coca Cola.\",\n",
      "                \"The tin is placed on a surface.\",\n",
      "                \"The surface is black.\",\n",
      "                \"There is a black counter.\",\n",
      "                \"There are canisters on the counter.\",\n",
      "                \"There is a kettle on the counter.\",\n",
      "                \"There is a can of soda on the counter.\"\n",
      "            ],\n",
      "            \"T_atomics\": [\n",
      "                \"There is a can of Coca Cola.\",\n",
      "                \"The can is on a counter.\",\n",
      "                \"The can is black.\",\n",
      "                \"The can is of Coca Cola Zero calorie soda.\",\n",
      "                \"The can is near the coffee maker.\",\n",
      "                \"There is a kitchen counter.\",\n",
      "                \"There are various items on the kitchen counter.\",\n",
      "                \"There are metal containers on the kitchen counter.\",\n",
      "                \"There is a teapot on the kitchen counter.\",\n",
      "                \"There is a black counter.\",\n",
      "                \"There are canisters on the counter.\",\n",
      "                \"There is a kettle on the counter.\"\n",
      "            ],\n",
      "            \"g_atomics\": {\n",
      "                \"gpt-4o-2024-08-06\": [\n",
      "                    \"There is a can of Coca-Cola Zero.\",\n",
      "                    \"The can is on a kitchen countertop.\",\n",
      "                    \"There is a white mug next to the can.\",\n",
      "                    \"There is a black kettle next to the can.\",\n",
      "                    \"There are three silver canisters.\",\n",
      "                    \"The canisters are aligned against the wall.\",\n",
      "                    \"There is an electrical outlet above the canisters.\"\n",
      "                ],\n",
      "                \"Llama-3.2-11B-Vision-Instruct\": [\n",
      "                    \"There is a can.\",\n",
      "                    \"The can is black.\",\n",
      "                    \"The can has a yellow band.\",\n",
      "                    \"The can has red writing.\",\n",
      "                    \"The can is likely a beverage can.\",\n",
      "                    \"The can is on a kitchen counter.\",\n",
      "                    \"The can has a white label.\",\n",
      "                    \"The label has indistinct writing.\"\n",
      "                ],\n",
      "                \"Molmo-7B-O-0924\": [\n",
      "                    \"There is a can of Coca-Cola.\",\n",
      "                    \"The can is black and yellow.\",\n",
      "                    \"The can is on a black countertop.\",\n",
      "                    \"The can has the Coca-Cola logo.\",\n",
      "                    \"The logo is in red text.\",\n",
      "                    \"The logo is in white text.\"\n",
      "                ]\n",
      "            },\n",
      "            \"T_org\": [\n",
      "                \"A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.\",\n",
      "                \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\",\n",
      "                \"A kitchen counter the various items on top including a can of Coca-Cola, metal containers, and a teapot.\",\n",
      "                \"a black tin of Coca Cola placed on a black surface\",\n",
      "                \"Black counter with canisters, kettle and can of soda.\"\n",
      "            ],\n",
      "            \"metadata\": {\n",
      "                \"gpt-4o-2024-08-06\": {\n",
      "                    \"recall\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a can of Coca Cola.\",\n",
      "                            \"The can is on a counter.\",\n",
      "                            \"The can is of Coca Cola Zero calorie soda.\",\n",
      "                            \"There are various items on the kitchen counter.\",\n",
      "                            \"There are metal containers on the kitchen counter.\",\n",
      "                            \"There are canisters on the counter.\",\n",
      "                            \"There is a kettle on the counter.\"\n",
      "                        ],\n",
      "                        \"FNs\": [\n",
      "                            \"The can is black.\",\n",
      "                            \"The can is near the coffee maker.\",\n",
      "                            \"There is a kitchen counter.\",\n",
      "                            \"There is a teapot on the kitchen counter.\",\n",
      "                            \"There is a black counter.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a can of Coca Cola.\",\n",
      "                                \"g_atomic\": \"There is a can of Coca-Cola Zero.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The can is on a counter.\",\n",
      "                                \"g_atomic\": \"The can is on a kitchen countertop.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The can is of Coca Cola Zero calorie soda.\",\n",
      "                                \"g_atomic\": \"There is a can of Coca-Cola Zero.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"There are various items on the kitchen counter.\",\n",
      "                                \"g_atomic\": \"There is a white mug next to the can.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"There are metal containers on the kitchen counter.\",\n",
      "                                \"g_atomic\": \"There are three silver canisters.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"There are canisters on the counter.\",\n",
      "                                \"g_atomic\": \"There are three silver canisters.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a kettle on the counter.\",\n",
      "                                \"g_atomic\": \"There is a black kettle next to the can.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 7,\n",
      "                            \"FN\": 5\n",
      "                        }\n",
      "                    },\n",
      "                    \"precision\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a can of Coca-Cola Zero.\",\n",
      "                            \"The can is on a kitchen countertop.\"\n",
      "                        ],\n",
      "                        \"FPs\": [\n",
      "                            \"There is a white mug next to the can.\",\n",
      "                            \"There is a black kettle next to the can.\",\n",
      "                            \"There are three silver canisters.\",\n",
      "                            \"The canisters are aligned against the wall.\",\n",
      "                            \"There is an electrical outlet above the canisters.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"g_atomic\": \"There is a can of Coca-Cola Zero.\",\n",
      "                                \"T_org\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The can is on a kitchen countertop.\",\n",
      "                                \"T_org\": \"A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 2,\n",
      "                            \"FP\": 5\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                    \"recall\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a can of Coca Cola.\",\n",
      "                            \"The can is on a counter.\",\n",
      "                            \"The can is black.\",\n",
      "                            \"There is a kitchen counter.\"\n",
      "                        ],\n",
      "                        \"FNs\": [\n",
      "                            \"The can is of Coca Cola Zero calorie soda.\",\n",
      "                            \"The can is near the coffee maker.\",\n",
      "                            \"There are various items on the kitchen counter.\",\n",
      "                            \"There are metal containers on the kitchen counter.\",\n",
      "                            \"There is a teapot on the kitchen counter.\",\n",
      "                            \"There is a black counter.\",\n",
      "                            \"There are canisters on the counter.\",\n",
      "                            \"There is a kettle on the counter.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a can of Coca Cola.\",\n",
      "                                \"g_atomic\": \"The can is likely a beverage can.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The can is on a counter.\",\n",
      "                                \"g_atomic\": \"The can is on a kitchen counter.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The can is black.\",\n",
      "                                \"g_atomic\": \"The can is black.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a kitchen counter.\",\n",
      "                                \"g_atomic\": \"The can is on a kitchen counter.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 4,\n",
      "                            \"FN\": 8\n",
      "                        }\n",
      "                    },\n",
      "                    \"precision\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a can.\",\n",
      "                            \"The can is black.\",\n",
      "                            \"The can is likely a beverage can.\",\n",
      "                            \"The can is on a kitchen counter.\"\n",
      "                        ],\n",
      "                        \"FPs\": [\n",
      "                            \"The can has a yellow band.\",\n",
      "                            \"The can has red writing.\",\n",
      "                            \"The can has a white label.\",\n",
      "                            \"The label has indistinct writing.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"g_atomic\": \"There is a can.\",\n",
      "                                \"T_org\": \"A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The can is black.\",\n",
      "                                \"T_org\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The can is likely a beverage can.\",\n",
      "                                \"T_org\": \"A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The can is on a kitchen counter.\",\n",
      "                                \"T_org\": \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 4,\n",
      "                            \"FP\": 4\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"Molmo-7B-O-0924\": {\n",
      "                    \"recall\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a can of Coca Cola.\",\n",
      "                            \"The can is on a counter.\",\n",
      "                            \"The can is black.\",\n",
      "                            \"There is a black counter.\"\n",
      "                        ],\n",
      "                        \"FNs\": [\n",
      "                            \"The can is of Coca Cola Zero calorie soda.\",\n",
      "                            \"The can is near the coffee maker.\",\n",
      "                            \"There is a kitchen counter.\",\n",
      "                            \"There are various items on the kitchen counter.\",\n",
      "                            \"There are metal containers on the kitchen counter.\",\n",
      "                            \"There is a teapot on the kitchen counter.\",\n",
      "                            \"There are canisters on the counter.\",\n",
      "                            \"There is a kettle on the counter.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a can of Coca Cola.\",\n",
      "                                \"g_atomic\": \"There is a can of Coca-Cola.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The can is on a counter.\",\n",
      "                                \"g_atomic\": \"The can is on a black countertop.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The can is black.\",\n",
      "                                \"g_atomic\": \"The can is black and yellow.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a black counter.\",\n",
      "                                \"g_atomic\": \"The can is on a black countertop.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 4,\n",
      "                            \"FN\": 8\n",
      "                        }\n",
      "                    },\n",
      "                    \"precision\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a can of Coca-Cola.\",\n",
      "                            \"The can is on a black countertop.\",\n",
      "                            \"The can has the Coca-Cola logo.\"\n",
      "                        ],\n",
      "                        \"FPs\": [\n",
      "                            \"The can is black and yellow.\",\n",
      "                            \"The logo is in red text.\",\n",
      "                            \"The logo is in white text.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"g_atomic\": \"There is a can of Coca-Cola.\",\n",
      "                                \"T_org\": \"A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The can is on a black countertop.\",\n",
      "                                \"T_org\": \"a black tin of Coca Cola placed on a black surface\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The can has the Coca-Cola logo.\",\n",
      "                                \"T_org\": \"A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 3,\n",
      "                            \"FP\": 3\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            \"scores\": {\n",
      "                \"gpt-4o-2024-08-06\": {\n",
      "                    \"recall\": 0.5833333333333334,\n",
      "                    \"precision\": 0.2857142857142857,\n",
      "                    \"cap_f1\": 0.3835616438356164\n",
      "                },\n",
      "                \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                    \"recall\": 0.3333333333333333,\n",
      "                    \"precision\": 0.5,\n",
      "                    \"cap_f1\": 0.4\n",
      "                },\n",
      "                \"Molmo-7B-O-0924\": {\n",
      "                    \"recall\": 0.3333333333333333,\n",
      "                    \"precision\": 0.5,\n",
      "                    \"cap_f1\": 0.4\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"human_caption_similarity\": {\n",
      "        \"sentences\": [\n",
      "            \"A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.\",\n",
      "            \"A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.\",\n",
      "            \"A kitchen counter the various items on top including a can of Coca-Cola, metal containers, and a teapot.\",\n",
      "            \"a black tin of Coca Cola placed on a black surface\",\n",
      "            \"Black counter with canisters, kettle and can of soda.\"\n",
      "        ],\n",
      "        \"similarities\": [\n",
      "            0.32641178369522095,\n",
      "            0.42414015531539917,\n",
      "            0.4487512707710266,\n",
      "            0.39667344093322754,\n",
      "            0.46702706813812256,\n",
      "            0.3708420991897583,\n",
      "            0.3800613284111023,\n",
      "            0.6190057992935181,\n",
      "            0.23785948753356934,\n",
      "            0.5282124280929565\n",
      "        ],\n",
      "        \"pairwise_distances\": [\n",
      "            [\n",
      "                0.0,\n",
      "                0.32641178369522095,\n",
      "                0.42414015531539917,\n",
      "                0.4487512707710266,\n",
      "                0.39667344093322754\n",
      "            ],\n",
      "            [\n",
      "                0.32641178369522095,\n",
      "                0.0,\n",
      "                0.46702706813812256,\n",
      "                0.3708420991897583,\n",
      "                0.3800613284111023\n",
      "            ],\n",
      "            [\n",
      "                0.42414015531539917,\n",
      "                0.46702706813812256,\n",
      "                0.0,\n",
      "                0.6190057992935181,\n",
      "                0.23785948753356934\n",
      "            ],\n",
      "            [\n",
      "                0.4487512707710266,\n",
      "                0.3708420991897583,\n",
      "                0.6190057992935181,\n",
      "                0.0,\n",
      "                0.5282124280929565\n",
      "            ],\n",
      "            [\n",
      "                0.39667344093322754,\n",
      "                0.3800613284111023,\n",
      "                0.23785948753356934,\n",
      "                0.5282124280929565,\n",
      "                0.0\n",
      "            ]\n",
      "        ],\n",
      "        \"min_similarity\": 0.23785948753356934,\n",
      "        \"max_similarity\": 0.6190057992935181,\n",
      "        \"mean_similarity\": 0.41989845037460327,\n",
      "        \"std_similarity\": 0.10042813420295715,\n",
      "        \"variance_similarity\": 0.010085809975862503\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "evaluated_captions_data = json.load(\n",
    "    open(\n",
    "        \"../../data/study-2-output/final-evaluated-captions/low-quality_evaluation_5432-images_2025-04-11_03-31_merged.json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Length of evaluated captions: {len(evaluated_captions_data)}\")\n",
    "print(json.dumps(evaluated_captions_data[0], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>too bright</th>\n",
       "      <th>other</th>\n",
       "      <th>no issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>VizWiz_train_00000001.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>VizWiz_train_00000008.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>VizWiz_train_00000011.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>VizWiz_train_00000020.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>VizWiz_train_00000026.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                  file_name                                         vizwiz_url  text_detected  unrecognizable  framing  blur  obstruction  rotation  too dark  too bright  other  no issue\n",
       "0         1  VizWiz_train_00000001.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0        0     5            0         0         0           0      0         0\n",
       "1         8  VizWiz_train_00000008.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0        4     0            0         0         0           0      0         1\n",
       "2        11  VizWiz_train_00000011.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0        2     2            4         1         1           1      0         0\n",
       "3        20  VizWiz_train_00000020.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0        4     0            1         0         0           0      0         0\n",
       "4        26  VizWiz_train_00000026.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0        0     4            0         0         0           0      0         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe with only the data we need for the regression\n",
    "target_keys = [\n",
    "    \"image_id\",\n",
    "    \"file_name\",\n",
    "    \"vizwiz_url\",\n",
    "    \"text_detected\",\n",
    "    \"unrecognizable\",\n",
    "    \"framing\",\n",
    "    \"blur\",\n",
    "    \"obstruction\",\n",
    "    \"rotation\",\n",
    "    \"too dark\",\n",
    "    \"too bright\",\n",
    "    \"other\",\n",
    "    \"no issue\",\n",
    "]\n",
    "evaluation_data_regression = [\n",
    "    {x: y for x, y in image.items() if x in target_keys}\n",
    "    for image in evaluated_captions_data\n",
    "]\n",
    "filtered_evaluation_data_df = pd.DataFrame.from_dict(evaluation_data_regression)\n",
    "filtered_evaluation_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) load annotations from research team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotated images: 1696\n",
      "Number of images that were verified: 1220\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>image_preview</th>\n",
       "      <th>human_captions</th>\n",
       "      <th>annotator</th>\n",
       "      <th>notes</th>\n",
       "      <th>unable_to_verify</th>\n",
       "      <th>double code notes</th>\n",
       "      <th>double verified</th>\n",
       "      <th>gpt4o_caption</th>\n",
       "      <th>gpt4o_code</th>\n",
       "      <th>llama_caption</th>\n",
       "      <th>llama_code</th>\n",
       "      <th>molmo_caption</th>\n",
       "      <th>molmo_code</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable_orig</th>\n",
       "      <th>framing_orig</th>\n",
       "      <th>blur_orig</th>\n",
       "      <th>obstruction_orig</th>\n",
       "      <th>rotation_orig</th>\n",
       "      <th>too_dark_orig</th>\n",
       "      <th>too_bright_orig</th>\n",
       "      <th>other_orig</th>\n",
       "      <th>curved label</th>\n",
       "      <th>text panel</th>\n",
       "      <th>AMP_rotation</th>\n",
       "      <th>XT_rotation</th>\n",
       "      <th>expert_caption</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>too bright</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16253</td>\n",
       "      <td>VizWiz_train_00016253.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A cup of hot chocolate with cookies next to it...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A white mug filled with a frothy drink topped ...</td>\n",
       "      <td></td>\n",
       "      <td>The image shows a white mug with a handle on t...</td>\n",
       "      <td></td>\n",
       "      <td>The image shows a white mug containing a light...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1210</td>\n",
       "      <td>VizWiz_train_00001210.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>The cooking instructions on a package of a foo...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A printed instruction sheet with text and illu...</td>\n",
       "      <td></td>\n",
       "      <td>The image shows a white and green plastic cont...</td>\n",
       "      <td></td>\n",
       "      <td>The image shows a green plastic food storage c...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8939</td>\n",
       "      <td>VizWiz_train_00008939.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A can of something with a lime green and dark ...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A green can with a black lid and design elemen...</td>\n",
       "      <td></td>\n",
       "      <td>The image shows a cylindrical can with a green...</td>\n",
       "      <td></td>\n",
       "      <td>A green cylindrical can with a black lid, like...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8607</td>\n",
       "      <td>VizWiz_train_00008607.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>Quality issues are too severe to recognize vis...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A can with a partially visible label featuring...</td>\n",
       "      <td></td>\n",
       "      <td>The object is a silver can with a red label fe...</td>\n",
       "      <td></td>\n",
       "      <td>A can of diced tomatoes is visible on a granit...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16752</td>\n",
       "      <td>VizWiz_train_00016752.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A white bag of instant flour mix for preparing...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>Nutrition facts and ingredient list from a foo...</td>\n",
       "      <td></td>\n",
       "      <td>The image shows a nutrition label on a food pr...</td>\n",
       "      <td></td>\n",
       "      <td>The image shows a nutrition label on a food pa...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                  file_name                                         vizwiz_url image_preview                                     human_captions   annotator notes unable_to_verify double code notes double verified                                      gpt4o_caption gpt4o_code                                      llama_caption llama_code                                      molmo_caption molmo_code text_detected  unrecognizable_orig  framing_orig  blur_orig  obstruction_orig  rotation_orig  too_dark_orig  too_bright_orig  other_orig curved label text panel AMP_rotation XT_rotation expert_caption  unrecognizable  framing   blur  obstruction  rotation  too dark  too bright  other\n",
       "0     16253  VizWiz_train_00016253.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A cup of hot chocolate with cookies next to it...  Anne Marie                    yes                                 x  A white mug filled with a frothy drink topped ...             The image shows a white mug with a handle on t...             The image shows a white mug containing a light...                     True                    0             4          0                 2              0              2                1           0                                                                           False     True  False         True     False      True       False      0\n",
       "1      1210  VizWiz_train_00001210.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                The cooking instructions on a package of a foo...  Anne Marie                    yes                                 x  A printed instruction sheet with text and illu...             The image shows a white and green plastic cont...             The image shows a green plastic food storage c...                     True                    0             4          0                 0              0              0                0           0                       x                                                   False     True  False        False     False     False       False      0\n",
       "2      8939  VizWiz_train_00008939.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A can of something with a lime green and dark ...  Anne Marie                    yes                                 x  A green can with a black lid and design elemen...             The image shows a cylindrical can with a green...             A green cylindrical can with a black lid, like...                     True                    1             4          0                 0              0              0                0           0            x          x                                                   False     True  False        False     False     False       False      0\n",
       "3      8607  VizWiz_train_00008607.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                Quality issues are too severe to recognize vis...  Anne Marie                    yes                                 x  A can with a partially visible label featuring...             The object is a silver can with a red label fe...             A can of diced tomatoes is visible on a granit...                     True                    1             4          0                 0              0              0                0           0            x                                                              False     True  False        False     False     False       False      0\n",
       "4     16752  VizWiz_train_00016752.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A white bag of instant flour mix for preparing...  Anne Marie                    yes                                 x  Nutrition facts and ingredient list from a foo...             The image shows a nutrition label on a food pr...             The image shows a nutrition label on a food pa...                     True                    0             4          0                 0              0              0                0           0                       x                                                   False     True  False        False     False     False       False      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_images_dtypes = {\n",
    "    \"image_id\": int,\n",
    "    \"file_name\": str,\n",
    "    \"vizwiz_url\": str,\n",
    "    \"image_preview\": str,\n",
    "    \"INCLUDE because product\": str,\n",
    "    \"EXCLUDE because not verifable\": str,\n",
    "    \"EXCLUDE because Book/DVD/CD/magazine?\": str,\n",
    "    \"text_detected\": str,\n",
    "    \"IQ quality check\": str,\n",
    "    \"unrecognizable\": bool,\n",
    "    \"framing\": bool,\n",
    "    \"blur\": bool,\n",
    "    \"obstruction\": bool,\n",
    "    \"rotation\": bool,\n",
    "    \"too dark\": bool,\n",
    "    \"too bright\": bool,\n",
    "    \"other\": bool,\n",
    "    \"no issue\": bool,\n",
    "    \"unrecognizable_orig\": int,\n",
    "    \"framing_orig\": int,\n",
    "    \"blur_orig\": int,\n",
    "    \"obstruction_orig\": int,\n",
    "    \"rotation_orig\": int,\n",
    "    \"too dark_orig\": int,\n",
    "    \"too bright_orig\": int,\n",
    "    \"other\": int,\n",
    "    \"no issue\": int,\n",
    "    \"human_caption_0\": str,\n",
    "    \"human_caption_1\": str,\n",
    "    \"human_caption_2\": str,\n",
    "    \"human_caption_3\": str,\n",
    "    \"human_caption_4\": str,\n",
    "    \"gpt-4o-2024-08-06_caption\": str,\n",
    "    \"Llama-3.2-11B-Vision-Instruct_caption\": str,\n",
    "    \"Molmo-7B-O-0924_caption\": str,\n",
    "    \"general_notes\": str,\n",
    "    \"gpt-4o-2024-08-06_notes\": str,\n",
    "    \"Llama-3.2-11B-Vision-Instruct_notes\": str,\n",
    "    \"Molmo-7B-O-0924_notes\": str,\n",
    "    \"image_preview\": str,\n",
    "    \"unable_to_verify\": str,\n",
    "    \"gpt4o_code\": str,\n",
    "    \"llama_code\": str,\n",
    "    \"molmo_code\": str,\n",
    "    \"notes\": str,\n",
    "    \"double code notes\": str,\n",
    "    \"double verified\": str,\n",
    "    \"curved label\": str,\n",
    "    \"text panel\": str,\n",
    "    \"AMP_rotation\": str,\n",
    "    \"XT_rotation\": str,\n",
    "}\n",
    "\n",
    "annotations_df = pd.read_csv(\n",
    "    \"./annotated-data/final-annotated-images_1696-images_2025-04-15_15-00.csv\",\n",
    "    dtype=target_images_dtypes,\n",
    "    keep_default_na=False,\n",
    ")\n",
    "\n",
    "print(f\"Number of annotated images: {len(annotations_df)}\")\n",
    "print(\n",
    "    f\"Number of images that were verified: {len(annotations_df[annotations_df['unable_to_verify'] == ''])}\"\n",
    ")\n",
    "annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blur_only</th>\n",
       "      <th>framing_only</th>\n",
       "      <th>rotation_only</th>\n",
       "      <th>obstruction_only</th>\n",
       "      <th>too_dark_only</th>\n",
       "      <th>too_bright_only</th>\n",
       "      <th>other_only</th>\n",
       "      <th>no_issues</th>\n",
       "      <th>other_single_issues</th>\n",
       "      <th>blur_framing</th>\n",
       "      <th>blur_rotation</th>\n",
       "      <th>framing_rotation</th>\n",
       "      <th>blur_framing_rotation</th>\n",
       "      <th>other_cooccurring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>1069 (87.62%)</td>\n",
       "      <td>957 (78.44%)</td>\n",
       "      <td>1163 (95.33%)</td>\n",
       "      <td>1214 (99.51%)</td>\n",
       "      <td>1217 (99.75%)</td>\n",
       "      <td>1217 (99.75%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1203 (98.61%)</td>\n",
       "      <td>1191 (97.62%)</td>\n",
       "      <td>961 (78.77%)</td>\n",
       "      <td>1140 (93.44%)</td>\n",
       "      <td>1064 (87.21%)</td>\n",
       "      <td>1079 (88.44%)</td>\n",
       "      <td>1136 (93.11%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>151 (12.38%)</td>\n",
       "      <td>263 (21.56%)</td>\n",
       "      <td>57 (4.67%)</td>\n",
       "      <td>6 (0.49%)</td>\n",
       "      <td>3 (0.25%)</td>\n",
       "      <td>3 (0.25%)</td>\n",
       "      <td>0 (0.00%)</td>\n",
       "      <td>17 (1.39%)</td>\n",
       "      <td>29 (2.38%)</td>\n",
       "      <td>259 (21.23%)</td>\n",
       "      <td>80 (6.56%)</td>\n",
       "      <td>156 (12.79%)</td>\n",
       "      <td>141 (11.56%)</td>\n",
       "      <td>84 (6.89%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "      <td>1220 (100.00%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            blur_only    framing_only   rotation_only obstruction_only   too_dark_only too_bright_only      other_only       no_issues other_single_issues    blur_framing   blur_rotation framing_rotation blur_framing_rotation other_cooccurring\n",
       "False   1069 (87.62%)    957 (78.44%)   1163 (95.33%)    1214 (99.51%)   1217 (99.75%)   1217 (99.75%)  1220 (100.00%)   1203 (98.61%)       1191 (97.62%)    961 (78.77%)   1140 (93.44%)    1064 (87.21%)         1079 (88.44%)     1136 (93.11%)\n",
       "True     151 (12.38%)    263 (21.56%)      57 (4.67%)        6 (0.49%)       3 (0.25%)       3 (0.25%)       0 (0.00%)      17 (1.39%)          29 (2.38%)    259 (21.23%)      80 (6.56%)     156 (12.79%)          141 (11.56%)        84 (6.89%)\n",
       "total  1220 (100.00%)  1220 (100.00%)  1220 (100.00%)   1220 (100.00%)  1220 (100.00%)  1220 (100.00%)  1220 (100.00%)  1220 (100.00%)      1220 (100.00%)  1220 (100.00%)  1220 (100.00%)   1220 (100.00%)        1220 (100.00%)    1220 (100.00%)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single issues\n",
    "annotations_df[\"blur_only\"] = (\n",
    "    (annotations_df[\"blur\"] == True)\n",
    "    & (annotations_df[\"framing\"] == False)\n",
    "    & (annotations_df[\"rotation\"] == False)\n",
    "    & (annotations_df[\"obstruction\"] == False)\n",
    "    & (annotations_df[\"too dark\"] == False)\n",
    "    & (annotations_df[\"too bright\"] == False)\n",
    "    & (annotations_df[\"other\"] == False)\n",
    ")\n",
    "annotations_df[\"framing_only\"] = (\n",
    "    (annotations_df[\"framing\"] == True)\n",
    "    & (annotations_df[\"blur\"] == False)\n",
    "    & (annotations_df[\"rotation\"] == False)\n",
    "    & (annotations_df[\"obstruction\"] == False)\n",
    "    & (annotations_df[\"too dark\"] == False)\n",
    "    & (annotations_df[\"too bright\"] == False)\n",
    "    & (annotations_df[\"other\"] == False)\n",
    ")\n",
    "annotations_df[\"rotation_only\"] = (\n",
    "    (annotations_df[\"rotation\"] == True)\n",
    "    & (annotations_df[\"blur\"] == False)\n",
    "    & (annotations_df[\"framing\"] == False)\n",
    "    & (annotations_df[\"obstruction\"] == False)\n",
    "    & (annotations_df[\"too dark\"] == False)\n",
    "    & (annotations_df[\"too bright\"] == False)\n",
    "    & (annotations_df[\"other\"] == False)\n",
    ")\n",
    "annotations_df[\"obstruction_only\"] = (\n",
    "    (annotations_df[\"obstruction\"] == True)\n",
    "    & (annotations_df[\"blur\"] == False)\n",
    "    & (annotations_df[\"framing\"] == False)\n",
    "    & (annotations_df[\"rotation\"] == False)\n",
    "    & (annotations_df[\"too dark\"] == False)\n",
    "    & (annotations_df[\"too bright\"] == False)\n",
    "    & (annotations_df[\"other\"] == False)\n",
    ")\n",
    "annotations_df[\"too_dark_only\"] = (\n",
    "    (annotations_df[\"too dark\"] == True)\n",
    "    & (annotations_df[\"blur\"] == False)\n",
    "    & (annotations_df[\"framing\"] == False)\n",
    "    & (annotations_df[\"rotation\"] == False)\n",
    "    & (annotations_df[\"obstruction\"] == False)\n",
    "    & (annotations_df[\"too bright\"] == False)\n",
    "    & (annotations_df[\"other\"] == False)\n",
    ")\n",
    "annotations_df[\"too_bright_only\"] = (\n",
    "    (annotations_df[\"too bright\"] == True)\n",
    "    & (annotations_df[\"blur\"] == False)\n",
    "    & (annotations_df[\"framing\"] == False)\n",
    "    & (annotations_df[\"rotation\"] == False)\n",
    "    & (annotations_df[\"obstruction\"] == False)\n",
    "    & (annotations_df[\"too dark\"] == False)\n",
    "    & (annotations_df[\"other\"] == False)\n",
    ")\n",
    "annotations_df[\"other_only\"] = (\n",
    "    (annotations_df[\"other\"] == True)\n",
    "    & (annotations_df[\"blur\"] == False)\n",
    "    & (annotations_df[\"framing\"] == False)\n",
    "    & (annotations_df[\"rotation\"] == False)\n",
    "    & (annotations_df[\"obstruction\"] == False)\n",
    "    & (annotations_df[\"too dark\"] == False)\n",
    "    & (annotations_df[\"too bright\"] == False)\n",
    ")\n",
    "annotations_df[\"no_issues\"] = (\n",
    "    (annotations_df[\"blur\"] == False)\n",
    "    & (annotations_df[\"framing\"] == False)\n",
    "    & (annotations_df[\"rotation\"] == False)\n",
    "    & (annotations_df[\"obstruction\"] == False)\n",
    "    & (annotations_df[\"too dark\"] == False)\n",
    "    & (annotations_df[\"too bright\"] == False)\n",
    "    & (annotations_df[\"other\"] == False)\n",
    ")\n",
    "annotations_df[\"other_single_issues\"] = (\n",
    "    (annotations_df[\"blur\"] == False)\n",
    "    & (annotations_df[\"framing\"] == False)\n",
    "    & (annotations_df[\"rotation\"] == False)\n",
    ")\n",
    "\n",
    "# cooccurring issues\n",
    "annotations_df[\"blur_framing\"] = (\n",
    "    (annotations_df[\"blur\"] == True)\n",
    "    & (annotations_df[\"framing\"] == True)\n",
    "    & (annotations_df[\"rotation\"] == False)\n",
    "    & (annotations_df[\"obstruction\"] == False)\n",
    "    & (annotations_df[\"too dark\"] == False)\n",
    "    & (annotations_df[\"too bright\"] == False)\n",
    "    & (annotations_df[\"other\"] == False)\n",
    ")\n",
    "annotations_df[\"blur_rotation\"] = (\n",
    "    (annotations_df[\"blur\"] == True)\n",
    "    & (annotations_df[\"rotation\"] == True)\n",
    "    & (annotations_df[\"framing\"] == False)\n",
    "    & (annotations_df[\"obstruction\"] == False)\n",
    "    & (annotations_df[\"too dark\"] == False)\n",
    "    & (annotations_df[\"too bright\"] == False)\n",
    "    & (annotations_df[\"other\"] == False)\n",
    ")\n",
    "annotations_df[\"framing_rotation\"] = (\n",
    "    (annotations_df[\"framing\"] == True)\n",
    "    & (annotations_df[\"rotation\"] == True)\n",
    "    & (annotations_df[\"blur\"] == False)\n",
    "    & (annotations_df[\"obstruction\"] == False)\n",
    "    & (annotations_df[\"too dark\"] == False)\n",
    "    & (annotations_df[\"too bright\"] == False)\n",
    "    & (annotations_df[\"other\"] == False)\n",
    ")\n",
    "annotations_df[\"blur_framing_rotation\"] = (\n",
    "    (annotations_df[\"blur\"] == True)\n",
    "    & (annotations_df[\"framing\"] == True)\n",
    "    & (annotations_df[\"rotation\"] == True)\n",
    "    & (annotations_df[\"obstruction\"] == False)\n",
    "    & (annotations_df[\"too dark\"] == False)\n",
    "    & (annotations_df[\"too bright\"] == False)\n",
    "    & (annotations_df[\"other\"] == False)\n",
    ")\n",
    "\n",
    "# other co-occurring issues are cases where there are multiple issues but not the co-occurring issues above\n",
    "annotations_df[\"multiple_issues\"] = (\n",
    "    annotations_df[\n",
    "        [\n",
    "            \"blur\",\n",
    "            \"framing\",\n",
    "            \"rotation\",\n",
    "            \"obstruction\",\n",
    "            \"too dark\",\n",
    "            \"too bright\",\n",
    "            \"other\",\n",
    "        ]\n",
    "    ].sum(axis=1)\n",
    "    >= 2\n",
    ")\n",
    "\n",
    "annotations_df[\"not_interesting_cooccurring\"] = ~(\n",
    "    (annotations_df[\"blur_framing\"])\n",
    "    | (annotations_df[\"blur_rotation\"])\n",
    "    | (annotations_df[\"framing_rotation\"])\n",
    "    | (annotations_df[\"blur_framing_rotation\"])\n",
    ")\n",
    "\n",
    "annotations_df[\"other_cooccurring\"] = (\n",
    "    annotations_df[\"multiple_issues\"] & annotations_df[\"not_interesting_cooccurring\"]\n",
    ")\n",
    "\n",
    "annotations_df[\n",
    "    [\"blur\", \"framing\", \"rotation\", \"obstruction\", \"too dark\", \"too bright\", \"other\"]\n",
    "].sum(axis=1)\n",
    "combine_counts_and_percentages(\n",
    "    calculate_quality_metrics(\n",
    "        annotations_df[annotations_df[\"unable_to_verify\"] == \"\"],\n",
    "        quality_columns=[\n",
    "            # \"blur\",\n",
    "            # \"framing\",\n",
    "            # \"rotation\",\n",
    "            # individual issues\n",
    "            \"blur_only\",\n",
    "            \"framing_only\",\n",
    "            \"rotation_only\",\n",
    "            \"obstruction_only\",\n",
    "            \"too_dark_only\",\n",
    "            \"too_bright_only\",\n",
    "            \"other_only\",\n",
    "            \"no_issues\",\n",
    "            \"other_single_issues\",\n",
    "            # cooccurring issues\n",
    "            \"blur_framing\",\n",
    "            \"blur_rotation\",\n",
    "            \"framing_rotation\",\n",
    "            \"blur_framing_rotation\",\n",
    "            \"other_cooccurring\",\n",
    "        ],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing step for combining annotation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot safely convert passed user dtype of bool for int64 dtyped data in column 19",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:1161\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._convert_tokens\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: Cannot cast array data from dtype('int64') to dtype('bool') according to the rule 'safe'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# TODO: this fails since it's not meant to be run again after creating the merged expert file. the dtype for unrecognizable (and other IQ issues needs to be an int here)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# get the expert caption data and combine with the above\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m curr_annotations_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./intermediate-data/annotated-images_04-15-25-14-00.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_images_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m expert_caption_annotated_df = pd.read_csv(\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m./intermediate-data/expert-annotated-images_04-15-25-14-00.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     dtype=target_images_dtypes,\n\u001b[32m     11\u001b[39m     keep_default_na=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     12\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLength of curr annotations: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(curr_annotations_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/local-blurred-captioning-exploration-4LZKhcfn/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/local-blurred-captioning-exploration-4LZKhcfn/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/local-blurred-captioning-exploration-4LZKhcfn/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/local-blurred-captioning-exploration-4LZKhcfn/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:921\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:1066\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._convert_column_data\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:1169\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._convert_tokens\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: cannot safely convert passed user dtype of bool for int64 dtyped data in column 19"
     ]
    }
   ],
   "source": [
    "# TODO: this fails since it's not meant to be run again after creating the merged expert file. the dtype for unrecognizable (and other IQ issues needs to be an int here)\n",
    "# get the expert caption data and combine with the above\n",
    "curr_annotations_df = pd.read_csv(\n",
    "    \"./intermediate-data/annotated-images_04-15-25-14-00.csv\",\n",
    "    dtype=target_images_dtypes,\n",
    "    keep_default_na=False,\n",
    ")\n",
    "expert_caption_annotated_df = pd.read_csv(\n",
    "    \"./intermediate-data/expert-annotated-images_04-15-25-14-00.csv\",\n",
    "    dtype=target_images_dtypes,\n",
    "    keep_default_na=False,\n",
    ")\n",
    "print(f\"Length of curr annotations: {len(curr_annotations_df)}\")\n",
    "print(f\"Length of expert annotations: {len(expert_caption_annotated_df)}\")\n",
    "\n",
    "# merge expert_caption_annotated with filtered_evaluation_data_df\n",
    "expert_caption_annotated_df = pd.merge(\n",
    "    filtered_evaluation_data_df,\n",
    "    expert_caption_annotated_df,\n",
    "    on=[\"image_id\", \"file_name\", \"vizwiz_url\"],\n",
    "    how=\"right\",\n",
    ")\n",
    "\n",
    "# concat to the annotation_df\n",
    "columns_to_include = [\n",
    "    \"image_id\",\n",
    "    \"file_name\",\n",
    "    \"vizwiz_url\",\n",
    "    \"image_preview\",\n",
    "    \"human_captions\",\n",
    "    \"annotator\",\n",
    "    \"notes\",\n",
    "    \"unable_to_verify\",\n",
    "    \"double code notes\",\n",
    "    \"double verified\",\n",
    "    \"gpt4o_caption\",\n",
    "    \"gpt4o_code\",\n",
    "    \"llama_caption\",\n",
    "    \"llama_code\",\n",
    "    \"molmo_caption\",\n",
    "    \"molmo_code\",\n",
    "    \"text_detected\",\n",
    "    \"unrecognizable\",\n",
    "    \"framing\",\n",
    "    \"blur\",\n",
    "    \"obstruction\",\n",
    "    \"rotation\",\n",
    "    \"too dark\",\n",
    "    \"too bright\",\n",
    "    \"other\",\n",
    "    \"curved label\",\n",
    "    \"text panel\",\n",
    "    \"AMP_rotation\",\n",
    "    \"XT_rotation\",\n",
    "]\n",
    "\n",
    "full_annotations_df = pd.concat(\n",
    "    [\n",
    "        curr_annotations_df[columns_to_include],\n",
    "        expert_caption_annotated_df[columns_to_include + [\"expert_caption\"]],\n",
    "    ]\n",
    ")\n",
    "full_annotations_df[\"expert_caption\"].fillna(\"\", inplace=True)\n",
    "\n",
    "# clean up columns\n",
    "full_annotations_df[\"AMP_rotation\"] = full_annotations_df[\"AMP_rotation\"].str.strip()\n",
    "full_annotations_df[\"XT_rotation\"] = full_annotations_df[\"XT_rotation\"].str.strip()\n",
    "full_annotations_df[\"AMP_rotation\"] = full_annotations_df[\"AMP_rotation\"].str.lower()\n",
    "full_annotations_df[\"XT_rotation\"] = full_annotations_df[\"XT_rotation\"].str.lower()\n",
    "\n",
    "# convert image quality issues to string\n",
    "full_annotations_df[\"unrecognizable\"] = full_annotations_df[\"unrecognizable\"].astype(\n",
    "    str\n",
    ")\n",
    "full_annotations_df[\"framing\"] = full_annotations_df[\"framing\"].astype(str)\n",
    "full_annotations_df[\"blur\"] = full_annotations_df[\"blur\"].astype(str)\n",
    "full_annotations_df[\"obstruction\"] = full_annotations_df[\"obstruction\"].astype(str)\n",
    "full_annotations_df[\"rotation\"] = full_annotations_df[\"rotation\"].astype(str)\n",
    "full_annotations_df[\"too dark\"] = full_annotations_df[\"too dark\"].astype(str)\n",
    "full_annotations_df[\"too bright\"] = full_annotations_df[\"too bright\"].astype(str)\n",
    "full_annotations_df[\"other\"] = full_annotations_df[\"other\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_annotations_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[298]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# convert to dict to add expert captions\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m full_annotations_dict = \u001b[43mfull_annotations_df\u001b[49m.to_dict(orient=\u001b[33m\"\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m full_annotations_dict:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m image[\u001b[33m\"\u001b[39m\u001b[33mimage_id\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m expert_image_set:\n",
      "\u001b[31mNameError\u001b[39m: name 'full_annotations_df' is not defined"
     ]
    }
   ],
   "source": [
    "# convert to dict to add expert captions\n",
    "full_annotations_dict = full_annotations_df.to_dict(orient=\"records\")\n",
    "for image in full_annotations_dict:\n",
    "    if image[\"image_id\"] in expert_image_set:\n",
    "        for expert_image in expert_evaluated_captions_data:\n",
    "            if expert_image[\"image_id\"] == image[\"image_id\"]:\n",
    "                image[\"expert_caption\"] = expert_image[\"human_captions\"][0][\"caption\"]\n",
    "                break\n",
    "    else:\n",
    "        image[\"expert_caption\"] = \"\"\n",
    "\n",
    "# convert back to df\n",
    "full_annotations_df = pd.DataFrame.from_dict(full_annotations_dict)\n",
    "print(len(full_annotations_df))\n",
    "full_annotations_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_annotations_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# rename prior variables to image-quality_old\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mfull_annotations_df\u001b[49m.rename(\n\u001b[32m      3\u001b[39m     columns={\n\u001b[32m      4\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33munrecognizable\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33munrecognizable_orig\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mframing\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mframing_orig\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mblur\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mblur_orig\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mobstruction\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mobstruction_orig\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrotation\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mrotation_orig\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtoo dark\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtoo_dark_orig\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtoo bright\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtoo_bright_orig\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mother\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mother_orig\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     },\n\u001b[32m     13\u001b[39m     inplace=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m full_annotations_df.head()\n",
      "\u001b[31mNameError\u001b[39m: name 'full_annotations_df' is not defined"
     ]
    }
   ],
   "source": [
    "# rename prior variables to image-quality_old\n",
    "full_annotations_df.rename(\n",
    "    columns={\n",
    "        \"unrecognizable\": \"unrecognizable_orig\",\n",
    "        \"framing\": \"framing_orig\",\n",
    "        \"blur\": \"blur_orig\",\n",
    "        \"obstruction\": \"obstruction_orig\",\n",
    "        \"rotation\": \"rotation_orig\",\n",
    "        \"too dark\": \"too_dark_orig\",\n",
    "        \"too bright\": \"too_bright_orig\",\n",
    "        \"other\": \"other_orig\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "full_annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_annotations_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# add new image-quality columns that are binary\u001b[39;00m\n\u001b[32m      2\u001b[39m mapping_iq = {\u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33m2\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33m3\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33m4\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33m5\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m full_annotations_df[\u001b[33m\"\u001b[39m\u001b[33munrecognizable\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfull_annotations_df\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33munrecognizable_orig\u001b[39m\u001b[33m\"\u001b[39m].map(\n\u001b[32m      4\u001b[39m     mapping_iq\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m full_annotations_df[\u001b[33m\"\u001b[39m\u001b[33mframing\u001b[39m\u001b[33m\"\u001b[39m] = full_annotations_df[\u001b[33m\"\u001b[39m\u001b[33mframing_orig\u001b[39m\u001b[33m\"\u001b[39m].map(mapping_iq)\n\u001b[32m      7\u001b[39m full_annotations_df[\u001b[33m\"\u001b[39m\u001b[33mblur\u001b[39m\u001b[33m\"\u001b[39m] = full_annotations_df[\u001b[33m\"\u001b[39m\u001b[33mblur_orig\u001b[39m\u001b[33m\"\u001b[39m].map(mapping_iq)\n",
      "\u001b[31mNameError\u001b[39m: name 'full_annotations_df' is not defined"
     ]
    }
   ],
   "source": [
    "# add new image-quality columns that are binary\n",
    "mapping_iq = {\"0\": False, \"1\": False, \"2\": True, \"3\": True, \"4\": True, \"5\": True}\n",
    "full_annotations_df[\"unrecognizable\"] = full_annotations_df[\"unrecognizable_orig\"].map(\n",
    "    mapping_iq\n",
    ")\n",
    "full_annotations_df[\"framing\"] = full_annotations_df[\"framing_orig\"].map(mapping_iq)\n",
    "full_annotations_df[\"blur\"] = full_annotations_df[\"blur_orig\"].map(mapping_iq)\n",
    "full_annotations_df[\"obstruction\"] = full_annotations_df[\"obstruction_orig\"].map(\n",
    "    mapping_iq\n",
    ")\n",
    "full_annotations_df[\"rotation\"] = full_annotations_df[\"rotation_orig\"].map(mapping_iq)\n",
    "full_annotations_df[\"too dark\"] = full_annotations_df[\"too_dark_orig\"].map(mapping_iq)\n",
    "full_annotations_df[\"too bright\"] = full_annotations_df[\"too_bright_orig\"].map(\n",
    "    mapping_iq\n",
    ")\n",
    "full_annotations_df[\"other\"] = full_annotations_df[\"other_orig\"].map(mapping_iq)\n",
    "\n",
    "\n",
    "# rotation is a special case: look at if XT_rotation and AMP_rotation are both X\n",
    "full_annotations_df[\"rotation\"] = False\n",
    "full_annotations_df.loc[\n",
    "    (full_annotations_df[\"XT_rotation\"] == \"x\")\n",
    "    & (full_annotations_df[\"AMP_rotation\"] == \"x\"),\n",
    "    \"rotation\",\n",
    "] = True\n",
    "full_annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_annotations_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# save\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mfull_annotations_df\u001b[49m.to_csv(\n\u001b[32m      3\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./annotated-data/final-annotated-images_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(full_annotations_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-images_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime.now().strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m_\u001b[39m\u001b[33m%\u001b[39m\u001b[33mH-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     index=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m      5\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'full_annotations_df' is not defined"
     ]
    }
   ],
   "source": [
    "# save\n",
    "full_annotations_df.to_csv(\n",
    "    f\"./annotated-data/final-annotated-images_{len(full_annotations_df)}-images_{datetime.now().strftime('%Y-%m-%d_%H-%M')}.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) load expert captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"image_id\": 20,\n",
      "    \"file_name\": \"VizWiz_train_00000020.jpg\",\n",
      "    \"vizwiz_url\": \"https://vizwiz.cs.colorado.edu/VizWiz_visualization_img/VizWiz_train_00000020.jpg\",\n",
      "    \"text_detected\": true,\n",
      "    \"unrecognizable\": 0,\n",
      "    \"framing\": 4,\n",
      "    \"blur\": 0,\n",
      "    \"obstruction\": 1,\n",
      "    \"rotation\": 0,\n",
      "    \"too dark\": 0,\n",
      "    \"too bright\": 0,\n",
      "    \"other\": 0,\n",
      "    \"no issue\": 0,\n",
      "    \"expert_captioner\": \"sm\",\n",
      "    \"human_captions\": [\n",
      "        {\n",
      "            \"caption\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "            \"captioning_issue\": \"\"\n",
      "        }\n",
      "    ],\n",
      "    \"model_captions\": [\n",
      "        {\n",
      "            \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "            \"caption\": \"A PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" with a colorful cover featuring illustrations and the PlayStation logo. There is a black object partially visible on the right side of the image.\"\n",
      "        },\n",
      "        {\n",
      "            \"model_name\": \"Llama-3.2-11B-Vision-Instruct\",\n",
      "            \"caption\": \"The image shows a video game case with the title \\\"Grand Theft Auto: Vice City\\\" in white text, featuring a black background with a collage of colorful images. The PlayStation logo is visible in the top-left corner.\"\n",
      "        },\n",
      "        {\n",
      "            \"model_name\": \"Molmo-7B-O-0924\",\n",
      "            \"caption\": \"A PlayStation 2 game case for Grand Theft Auto: Vice City is visible. The case features the PlayStation logo, game title, and various images of vehicles and characters from the game.\"\n",
      "        }\n",
      "    ],\n",
      "    \"evaluation\": {\n",
      "        \"bleu-1\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"bleu\": 0.41445829855415267,\n",
      "                \"precisions\": [\n",
      "                    0.65\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.6376281516217733,\n",
      "                \"length_ratio\": 0.6896551724137931,\n",
      "                \"translation_length\": 40,\n",
      "                \"reference_length\": 58\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"bleu\": 0.442993377175337,\n",
      "                \"precisions\": [\n",
      "                    0.627906976744186\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.7055079710570181,\n",
      "                \"length_ratio\": 0.7413793103448276,\n",
      "                \"translation_length\": 43,\n",
      "                \"reference_length\": 58\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"bleu\": 0.34675533518825286,\n",
      "                \"precisions\": [\n",
      "                    0.6388888888888888\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.5427474811642219,\n",
      "                \"length_ratio\": 0.6206896551724138,\n",
      "                \"translation_length\": 36,\n",
      "                \"reference_length\": 58\n",
      "            }\n",
      "        },\n",
      "        \"bleu-2\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"bleu\": 0.29679975226370464,\n",
      "                \"precisions\": [\n",
      "                    0.65,\n",
      "                    0.3333333333333333\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.6376281516217733,\n",
      "                \"length_ratio\": 0.6896551724137931,\n",
      "                \"translation_length\": 40,\n",
      "                \"reference_length\": 58\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"bleu\": 0.2727877941702201,\n",
      "                \"precisions\": [\n",
      "                    0.627906976744186,\n",
      "                    0.23809523809523808\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.7055079710570181,\n",
      "                \"length_ratio\": 0.7413793103448276,\n",
      "                \"translation_length\": 43,\n",
      "                \"reference_length\": 58\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"bleu\": 0.2540195165192828,\n",
      "                \"precisions\": [\n",
      "                    0.6388888888888888,\n",
      "                    0.34285714285714286\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.5427474811642219,\n",
      "                \"length_ratio\": 0.6206896551724138,\n",
      "                \"translation_length\": 36,\n",
      "                \"reference_length\": 58\n",
      "            }\n",
      "        },\n",
      "        \"bleu-3\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"bleu\": 0.2533385107951265,\n",
      "                \"precisions\": [\n",
      "                    0.65,\n",
      "                    0.3333333333333333,\n",
      "                    0.2894736842105263\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.6376281516217733,\n",
      "                \"length_ratio\": 0.6896551724137931,\n",
      "                \"translation_length\": 40,\n",
      "                \"reference_length\": 58\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"bleu\": 0.19732088843451168,\n",
      "                \"precisions\": [\n",
      "                    0.627906976744186,\n",
      "                    0.23809523809523808,\n",
      "                    0.14634146341463414\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.7055079710570181,\n",
      "                \"length_ratio\": 0.7413793103448276,\n",
      "                \"translation_length\": 43,\n",
      "                \"reference_length\": 58\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"bleu\": 0.2019827832128965,\n",
      "                \"precisions\": [\n",
      "                    0.6388888888888888,\n",
      "                    0.34285714285714286,\n",
      "                    0.23529411764705882\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.5427474811642219,\n",
      "                \"length_ratio\": 0.6206896551724138,\n",
      "                \"translation_length\": 36,\n",
      "                \"reference_length\": 58\n",
      "            }\n",
      "        },\n",
      "        \"bleu-4\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"bleu\": 0.23007389758045407,\n",
      "                \"precisions\": [\n",
      "                    0.65,\n",
      "                    0.3333333333333333,\n",
      "                    0.2894736842105263,\n",
      "                    0.2702702702702703\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.6376281516217733,\n",
      "                \"length_ratio\": 0.6896551724137931,\n",
      "                \"translation_length\": 40,\n",
      "                \"reference_length\": 58\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"bleu\": 0.16133655569193084,\n",
      "                \"precisions\": [\n",
      "                    0.627906976744186,\n",
      "                    0.23809523809523808,\n",
      "                    0.14634146341463414,\n",
      "                    0.125\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.7055079710570181,\n",
      "                \"length_ratio\": 0.7413793103448276,\n",
      "                \"translation_length\": 43,\n",
      "                \"reference_length\": 58\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"bleu\": 0.16134266807145842,\n",
      "                \"precisions\": [\n",
      "                    0.6388888888888888,\n",
      "                    0.34285714285714286,\n",
      "                    0.23529411764705882,\n",
      "                    0.15151515151515152\n",
      "                ],\n",
      "                \"brevity_penalty\": 0.5427474811642219,\n",
      "                \"length_ratio\": 0.6206896551724138,\n",
      "                \"translation_length\": 36,\n",
      "                \"reference_length\": 58\n",
      "            }\n",
      "        },\n",
      "        \"meteor\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"meteor\": 0.40694746353331535\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"meteor\": 0.3753837818313167\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"meteor\": 0.37003849727864063\n",
      "            }\n",
      "        },\n",
      "        \"rouge\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"rouge1\": 0.6024096385542168,\n",
      "                \"rouge2\": 0.271604938271605,\n",
      "                \"rougeL\": 0.43373493975903615,\n",
      "                \"rougeLsum\": 0.43373493975903615\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"rouge1\": 0.5116279069767442,\n",
      "                \"rouge2\": 0.14285714285714288,\n",
      "                \"rougeL\": 0.3488372093023256,\n",
      "                \"rougeLsum\": 0.3488372093023256\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"rouge1\": 0.5316455696202531,\n",
      "                \"rouge2\": 0.33766233766233766,\n",
      "                \"rougeL\": 0.4050632911392405,\n",
      "                \"rougeLsum\": 0.4050632911392405\n",
      "            }\n",
      "        },\n",
      "        \"cider\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"score\": 0.4791910811641647\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"score\": 0.520852253705722\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"score\": 0.10816904937230937\n",
      "            }\n",
      "        },\n",
      "        \"spice\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"All\": {\n",
      "                    \"pr\": 0.46153846153846156,\n",
      "                    \"re\": 0.4,\n",
      "                    \"f\": 0.42857142857142855,\n",
      "                    \"fn\": 18.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 14.0,\n",
      "                    \"tp\": 12.0\n",
      "                },\n",
      "                \"Relation\": {\n",
      "                    \"pr\": 0.16666666666666666,\n",
      "                    \"re\": 0.16666666666666666,\n",
      "                    \"f\": 0.16666666666666666,\n",
      "                    \"fn\": 5.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 5.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Cardinality\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Attribute\": {\n",
      "                    \"pr\": 0.5833333333333334,\n",
      "                    \"re\": 0.4666666666666667,\n",
      "                    \"f\": 0.5185185185185186,\n",
      "                    \"fn\": 8.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 5.0,\n",
      "                    \"tp\": 7.0\n",
      "                },\n",
      "                \"Size\": {\n",
      "                    \"pr\": 1.0,\n",
      "                    \"re\": 1.0,\n",
      "                    \"f\": 1.0,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Color\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 2.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 1.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Object\": {\n",
      "                    \"pr\": 0.5,\n",
      "                    \"re\": 0.4444444444444444,\n",
      "                    \"f\": 0.47058823529411764,\n",
      "                    \"fn\": 5.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 4.0,\n",
      "                    \"tp\": 4.0\n",
      "                }\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"All\": {\n",
      "                    \"pr\": 0.2962962962962963,\n",
      "                    \"re\": 0.26666666666666666,\n",
      "                    \"f\": 0.28070175438596495,\n",
      "                    \"fn\": 22.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 19.0,\n",
      "                    \"tp\": 8.0\n",
      "                },\n",
      "                \"Relation\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 6.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 6.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Cardinality\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Attribute\": {\n",
      "                    \"pr\": 0.38461538461538464,\n",
      "                    \"re\": 0.3333333333333333,\n",
      "                    \"f\": 0.3571428571428571,\n",
      "                    \"fn\": 10.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 8.0,\n",
      "                    \"tp\": 5.0\n",
      "                },\n",
      "                \"Size\": {\n",
      "                    \"pr\": 1.0,\n",
      "                    \"re\": 1.0,\n",
      "                    \"f\": 1.0,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Color\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 2.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 2.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Object\": {\n",
      "                    \"pr\": 0.375,\n",
      "                    \"re\": 0.3333333333333333,\n",
      "                    \"f\": 0.35294117647058826,\n",
      "                    \"fn\": 6.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 5.0,\n",
      "                    \"tp\": 3.0\n",
      "                }\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"All\": {\n",
      "                    \"pr\": 0.43478260869565216,\n",
      "                    \"re\": 0.3333333333333333,\n",
      "                    \"f\": 0.3773584905660377,\n",
      "                    \"fn\": 20.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 13.0,\n",
      "                    \"tp\": 10.0\n",
      "                },\n",
      "                \"Relation\": {\n",
      "                    \"pr\": 0.16666666666666666,\n",
      "                    \"re\": 0.16666666666666666,\n",
      "                    \"f\": 0.16666666666666666,\n",
      "                    \"fn\": 5.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 5.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Cardinality\": {\n",
      "                    \"pr\": NaN,\n",
      "                    \"re\": NaN,\n",
      "                    \"f\": NaN,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Attribute\": {\n",
      "                    \"pr\": 0.5454545454545454,\n",
      "                    \"re\": 0.4,\n",
      "                    \"f\": 0.4615384615384615,\n",
      "                    \"fn\": 9.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 5.0,\n",
      "                    \"tp\": 6.0\n",
      "                },\n",
      "                \"Size\": {\n",
      "                    \"pr\": 1.0,\n",
      "                    \"re\": 1.0,\n",
      "                    \"f\": 1.0,\n",
      "                    \"fn\": 0.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 1.0\n",
      "                },\n",
      "                \"Color\": {\n",
      "                    \"pr\": 0.0,\n",
      "                    \"re\": 0.0,\n",
      "                    \"f\": 0.0,\n",
      "                    \"fn\": 2.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 0.0,\n",
      "                    \"tp\": 0.0\n",
      "                },\n",
      "                \"Object\": {\n",
      "                    \"pr\": 0.5,\n",
      "                    \"re\": 0.3333333333333333,\n",
      "                    \"f\": 0.4,\n",
      "                    \"fn\": 6.0,\n",
      "                    \"numImages\": 1.0,\n",
      "                    \"fp\": 3.0,\n",
      "                    \"tp\": 3.0\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"bertscore\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"precision\": 0.7909770011901855,\n",
      "                \"recall\": 0.7363928556442261,\n",
      "                \"f1\": 0.7627096176147461,\n",
      "                \"best_ref_indices\": [\n",
      "                    0,\n",
      "                    0,\n",
      "                    0\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"recall_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"f1_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\"\n",
      "                }\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"precision\": 0.7593357563018799,\n",
      "                \"recall\": 0.7069831490516663,\n",
      "                \"f1\": 0.7322248816490173,\n",
      "                \"best_ref_indices\": [\n",
      "                    0,\n",
      "                    0,\n",
      "                    0\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"recall_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"f1_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\"\n",
      "                }\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"precision\": 0.803114116191864,\n",
      "                \"recall\": 0.7201811671257019,\n",
      "                \"f1\": 0.759390115737915,\n",
      "                \"best_ref_indices\": [\n",
      "                    0,\n",
      "                    0,\n",
      "                    0\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"recall_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"f1_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"bertscore_idf\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"precision\": 0.8259095549583435,\n",
      "                \"recall\": 0.7173210382461548,\n",
      "                \"f1\": 0.7677949070930481,\n",
      "                \"best_ref_indices\": [\n",
      "                    0,\n",
      "                    0,\n",
      "                    0\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"recall_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"f1_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\"\n",
      "                }\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"precision\": 0.7543994784355164,\n",
      "                \"recall\": 0.682621419429779,\n",
      "                \"f1\": 0.7167177796363831,\n",
      "                \"best_ref_indices\": [\n",
      "                    0,\n",
      "                    0,\n",
      "                    0\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"recall_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"f1_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\"\n",
      "                }\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"precision\": 0.8208200931549072,\n",
      "                \"recall\": 0.7194167375564575,\n",
      "                \"f1\": 0.766780436038971,\n",
      "                \"best_ref_indices\": [\n",
      "                    0,\n",
      "                    0,\n",
      "                    0\n",
      "                ],\n",
      "                \"reference_captions\": {\n",
      "                    \"precision_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"recall_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\",\n",
      "                    \"f1_reference\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"clipscore\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"score\": 1.001953125\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"score\": 0.93505859375\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"score\": 0.97900390625\n",
      "            }\n",
      "        },\n",
      "        \"clipscore_ref\": {\n",
      "            \"gpt-4o-2024-08-06\": {\n",
      "                \"score\": 0.95458984375\n",
      "            },\n",
      "            \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                \"score\": 0.89892578125\n",
      "            },\n",
      "            \"Molmo-7B-O-0924\": {\n",
      "                \"score\": 0.92138671875\n",
      "            }\n",
      "        },\n",
      "        \"cap_f1\": {\n",
      "            \"parsed_atomics\": [\n",
      "                \"There is a PlayStation 2 game case.\",\n",
      "                \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                \"The cover of the game case is colorful.\",\n",
      "                \"The cover includes characters.\",\n",
      "                \"The cover includes vehicles.\",\n",
      "                \"The cover includes a building.\",\n",
      "                \"There is a 'Rockstar Games' logo on the cover.\",\n",
      "                \"The 'Rockstar Games' logo is yellow.\",\n",
      "                \"The game case is partially off-frame.\",\n",
      "                \"The game case is on a white surface.\",\n",
      "                \"There is a cord nearby.\"\n",
      "            ],\n",
      "            \"T_atomics\": [\n",
      "                \"There is a PlayStation 2 game case.\",\n",
      "                \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                \"The cover of the game case is colorful.\",\n",
      "                \"The cover includes characters.\",\n",
      "                \"The cover includes vehicles.\",\n",
      "                \"The cover includes a building.\",\n",
      "                \"There is a 'Rockstar Games' logo on the cover.\",\n",
      "                \"The 'Rockstar Games' logo is yellow.\",\n",
      "                \"The game case is partially off-frame.\",\n",
      "                \"The game case is on a white surface.\",\n",
      "                \"There is a cord nearby.\"\n",
      "            ],\n",
      "            \"g_atomics\": {\n",
      "                \"gpt-4o-2024-08-06\": [\n",
      "                    \"There is a PlayStation 2 game case.\",\n",
      "                    \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                    \"The cover of the game case is colorful.\",\n",
      "                    \"The cover features illustrations.\",\n",
      "                    \"The PlayStation logo is on the cover.\",\n",
      "                    \"There is a black object in the image.\",\n",
      "                    \"The black object is partially visible.\",\n",
      "                    \"The black object is on the right side of the image.\"\n",
      "                ],\n",
      "                \"Llama-3.2-11B-Vision-Instruct\": [\n",
      "                    \"There is a video game case.\",\n",
      "                    \"The title on the case is 'Grand Theft Auto: Vice City'.\",\n",
      "                    \"The title is in white text.\",\n",
      "                    \"The background is black.\",\n",
      "                    \"There is a collage of colorful images on the case.\",\n",
      "                    \"The PlayStation logo is visible.\",\n",
      "                    \"The PlayStation logo is in the top-left corner.\"\n",
      "                ],\n",
      "                \"Molmo-7B-O-0924\": [\n",
      "                    \"There is a PlayStation 2 game case.\",\n",
      "                    \"The game case is for Grand Theft Auto: Vice City.\",\n",
      "                    \"The PlayStation logo is on the case.\",\n",
      "                    \"The game title is on the case.\",\n",
      "                    \"There are images of vehicles on the case.\",\n",
      "                    \"There are images of characters on the case.\"\n",
      "                ]\n",
      "            },\n",
      "            \"T_org\": [\n",
      "                \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.\"\n",
      "            ],\n",
      "            \"metadata\": {\n",
      "                \"gpt-4o-2024-08-06\": {\n",
      "                    \"recall\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a PlayStation 2 game case.\",\n",
      "                            \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                            \"The cover of the game case is colorful.\"\n",
      "                        ],\n",
      "                        \"FNs\": [\n",
      "                            \"The cover includes characters.\",\n",
      "                            \"The cover includes vehicles.\",\n",
      "                            \"The cover includes a building.\",\n",
      "                            \"There is a 'Rockstar Games' logo on the cover.\",\n",
      "                            \"The 'Rockstar Games' logo is yellow.\",\n",
      "                            \"The game case is partially off-frame.\",\n",
      "                            \"The game case is on a white surface.\",\n",
      "                            \"There is a cord nearby.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a PlayStation 2 game case.\",\n",
      "                                \"g_atomic\": \"There is a PlayStation 2 game case.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                                \"g_atomic\": \"The game case is for 'Grand Theft Auto: Vice City'.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The cover of the game case is colorful.\",\n",
      "                                \"g_atomic\": \"The cover of the game case is colorful.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 3,\n",
      "                            \"FN\": 8\n",
      "                        }\n",
      "                    },\n",
      "                    \"precision\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a PlayStation 2 game case.\",\n",
      "                            \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                            \"The cover of the game case is colorful.\",\n",
      "                            \"The cover features illustrations.\"\n",
      "                        ],\n",
      "                        \"FPs\": [\n",
      "                            \"The PlayStation logo is on the cover.\",\n",
      "                            \"There is a black object in the image.\",\n",
      "                            \"The black object is partially visible.\",\n",
      "                            \"The black object is on the right side of the image.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"g_atomic\": \"There is a PlayStation 2 game case.\",\n",
      "                                \"T_org\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                                \"T_org\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The cover of the game case is colorful.\",\n",
      "                                \"T_org\": \"The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The cover features illustrations.\",\n",
      "                                \"T_org\": \"The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 4,\n",
      "                            \"FP\": 4\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                    \"recall\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a PlayStation 2 game case.\",\n",
      "                            \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                            \"The cover of the game case is colorful.\"\n",
      "                        ],\n",
      "                        \"FNs\": [\n",
      "                            \"The cover includes characters.\",\n",
      "                            \"The cover includes vehicles.\",\n",
      "                            \"The cover includes a building.\",\n",
      "                            \"There is a 'Rockstar Games' logo on the cover.\",\n",
      "                            \"The 'Rockstar Games' logo is yellow.\",\n",
      "                            \"The game case is partially off-frame.\",\n",
      "                            \"The game case is on a white surface.\",\n",
      "                            \"There is a cord nearby.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a PlayStation 2 game case.\",\n",
      "                                \"g_atomic\": \"There is a video game case.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                                \"g_atomic\": \"The title on the case is 'Grand Theft Auto: Vice City'.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The cover of the game case is colorful.\",\n",
      "                                \"g_atomic\": \"There is a collage of colorful images on the case.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 3,\n",
      "                            \"FN\": 8\n",
      "                        }\n",
      "                    },\n",
      "                    \"precision\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a video game case.\",\n",
      "                            \"The title on the case is 'Grand Theft Auto: Vice City'.\",\n",
      "                            \"There is a collage of colorful images on the case.\"\n",
      "                        ],\n",
      "                        \"FPs\": [\n",
      "                            \"The title is in white text.\",\n",
      "                            \"The background is black.\",\n",
      "                            \"The PlayStation logo is visible.\",\n",
      "                            \"The PlayStation logo is in the top-left corner.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"g_atomic\": \"There is a video game case.\",\n",
      "                                \"T_org\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The title on the case is 'Grand Theft Auto: Vice City'.\",\n",
      "                                \"T_org\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"There is a collage of colorful images on the case.\",\n",
      "                                \"T_org\": \"The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 3,\n",
      "                            \"FP\": 4\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"Molmo-7B-O-0924\": {\n",
      "                    \"recall\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a PlayStation 2 game case.\",\n",
      "                            \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                            \"The cover includes characters.\",\n",
      "                            \"The cover includes vehicles.\"\n",
      "                        ],\n",
      "                        \"FNs\": [\n",
      "                            \"The cover of the game case is colorful.\",\n",
      "                            \"The cover includes a building.\",\n",
      "                            \"There is a 'Rockstar Games' logo on the cover.\",\n",
      "                            \"The 'Rockstar Games' logo is yellow.\",\n",
      "                            \"The game case is partially off-frame.\",\n",
      "                            \"The game case is on a white surface.\",\n",
      "                            \"There is a cord nearby.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"T_atomic\": \"There is a PlayStation 2 game case.\",\n",
      "                                \"g_atomic\": \"There is a PlayStation 2 game case.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The game case is for 'Grand Theft Auto: Vice City'.\",\n",
      "                                \"g_atomic\": \"The game case is for Grand Theft Auto: Vice City.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The cover includes characters.\",\n",
      "                                \"g_atomic\": \"There are images of characters on the case.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"T_atomic\": \"The cover includes vehicles.\",\n",
      "                                \"g_atomic\": \"There are images of vehicles on the case.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 4,\n",
      "                            \"FN\": 7\n",
      "                        }\n",
      "                    },\n",
      "                    \"precision\": {\n",
      "                        \"TPs\": [\n",
      "                            \"There is a PlayStation 2 game case.\",\n",
      "                            \"The game case is for Grand Theft Auto: Vice City.\",\n",
      "                            \"There are images of vehicles on the case.\",\n",
      "                            \"There are images of characters on the case.\"\n",
      "                        ],\n",
      "                        \"FPs\": [\n",
      "                            \"The PlayStation logo is on the case.\",\n",
      "                            \"The game title is on the case.\"\n",
      "                        ],\n",
      "                        \"Match\": [\n",
      "                            {\n",
      "                                \"g_atomic\": \"There is a PlayStation 2 game case.\",\n",
      "                                \"T_org\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"The game case is for Grand Theft Auto: Vice City.\",\n",
      "                                \"T_org\": \"The upper portion of a PlayStation 2 game case for \\\"Grand Theft Auto: Vice City\\\" is shown.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"There are images of vehicles on the case.\",\n",
      "                                \"T_org\": \"The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow.\"\n",
      "                            },\n",
      "                            {\n",
      "                                \"g_atomic\": \"There are images of characters on the case.\",\n",
      "                                \"T_org\": \"The colorful illustrated cover includes characters, vehicles, and a building, with a \\\"Rockstar Games\\\" logo in yellow.\"\n",
      "                            }\n",
      "                        ],\n",
      "                        \"Counts\": {\n",
      "                            \"TP\": 4,\n",
      "                            \"FP\": 2\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            \"scores\": {\n",
      "                \"gpt-4o-2024-08-06\": {\n",
      "                    \"recall\": 0.2727272727272727,\n",
      "                    \"precision\": 0.5,\n",
      "                    \"cap_f1\": 0.3529411764705882\n",
      "                },\n",
      "                \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "                    \"recall\": 0.2727272727272727,\n",
      "                    \"precision\": 0.42857142857142855,\n",
      "                    \"cap_f1\": 0.33333333333333326\n",
      "                },\n",
      "                \"Molmo-7B-O-0924\": {\n",
      "                    \"recall\": 0.36363636363636365,\n",
      "                    \"precision\": 0.6666666666666666,\n",
      "                    \"cap_f1\": 0.4705882352941177\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"human_caption_similarity\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "expert_captioned_data = json.load(\n",
    "    open(\n",
    "        \"../../data/study-2-output/final-evaluated-captions/expert-captions_evaluation_600-images_2025-04-13_16-42.json\"\n",
    "    )\n",
    ")\n",
    "print(json.dumps(expert_captioned_data[0], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw expert captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: replace this with the dataset that has metrics run\n",
    "# expert_captioned_data = pd.read_csv(\n",
    "#     \"./labeled-data/Dataset for Shawn _ 04-06-25 - dataset formatted.csv\",\n",
    "#     dtype={\n",
    "#         \"File Name\": str,\n",
    "#         \"Image URL\": str,\n",
    "#         \"Image Preview\": str,\n",
    "#         \"Captioner Name\": str,\n",
    "#         \"Describe all parts of the image that may be important to a person who is blind.\": str,\n",
    "#         \"If you are unable to caption the image, describe the issue in this column.\": str,\n",
    "#     },\n",
    "#     keep_default_na=False,\n",
    "#     encoding=\"utf-8\",\n",
    "# )\n",
    "\n",
    "# # rename columns so they're easier to program with\n",
    "# expert_captioned_data.rename(\n",
    "#     columns={\n",
    "#         \"File Name\": \"file_name\",\n",
    "#         \"Image URL\": \"vizwiz_url\",\n",
    "#         \"Captioner Name\": \"expert_captioner\",\n",
    "#         \"Describe all parts of the image that may be important to a person who is blind.\": \"expert_caption\",\n",
    "#         \"If you are unable to caption the image, describe the issue in this column.\": \"captioning_issue\",\n",
    "#     },\n",
    "#     inplace=True,\n",
    "# )\n",
    "# expert_captioned_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 1: how accurately do VLMs identify products?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the images that were verifable\n",
    "def get_accuracy_counts(dataframe_with_counts):\n",
    "    accuracy_counts_df = pd.concat(\n",
    "        [\n",
    "            dataframe_with_counts[\"gpt4o_code\"].replace(\"yes++\", \"yes\").value_counts(),\n",
    "            dataframe_with_counts[\"llama_code\"].replace(\"yes++\", \"yes\").value_counts(),\n",
    "            dataframe_with_counts[\"molmo_code\"].replace(\"yes++\", \"yes\").value_counts(),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    accuracy_counts_df.columns = MODEL_NAMES.keys()\n",
    "    display(accuracy_counts_df)\n",
    "    display(round(100 * accuracy_counts_df / len(dataframe_with_counts), 1))\n",
    "\n",
    "    return accuracy_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>Llama-3.2-11B-Vision-Instruct</th>\n",
       "      <th>Molmo-7B-O-0924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>842</td>\n",
       "      <td>577</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>378</td>\n",
       "      <td>643</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gpt-4o-2024-08-06  Llama-3.2-11B-Vision-Instruct  Molmo-7B-O-0924\n",
       "yes                842                            577              450\n",
       "no                 378                            643              770"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>Llama-3.2-11B-Vision-Instruct</th>\n",
       "      <th>Molmo-7B-O-0924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>69.0</td>\n",
       "      <td>47.3</td>\n",
       "      <td>36.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>31.0</td>\n",
       "      <td>52.7</td>\n",
       "      <td>63.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gpt-4o-2024-08-06  Llama-3.2-11B-Vision-Instruct  Molmo-7B-O-0924\n",
       "yes               69.0                           47.3             36.9\n",
       "no                31.0                           52.7             63.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>Llama-3.2-11B-Vision-Instruct</th>\n",
       "      <th>Molmo-7B-O-0924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>842</td>\n",
       "      <td>577</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>378</td>\n",
       "      <td>643</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gpt-4o-2024-08-06  Llama-3.2-11B-Vision-Instruct  Molmo-7B-O-0924\n",
       "yes                842                            577              450\n",
       "no                 378                            643              770"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy_counts(annotations_df[annotations_df[\"unable_to_verify\"] == \"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break apart accuracy across image quality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_accuracy_counts(dataframe, model_columns):\n",
    "    \"\"\"Compute accuracy counts for given model columns.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pandas.DataFrame): Input dataframe\n",
    "        model_columns (list): List of model column names\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with accuracy counts for each model\n",
    "    \"\"\"\n",
    "    accuracy_counts = pd.concat(\n",
    "        [\n",
    "            dataframe[col].replace(\"yes++\", \"yes\").value_counts()\n",
    "            for col in model_columns\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    accuracy_counts.columns = MODEL_NAMES.keys()\n",
    "    return accuracy_counts\n",
    "\n",
    "\n",
    "def _create_combined_counts_df(accuracy_counts_df, total_count):\n",
    "    \"\"\"Create a combined dataframe with counts and percentages.\n",
    "\n",
    "    Args:\n",
    "        accuracy_counts_df (pandas.DataFrame): DataFrame with accuracy counts\n",
    "        total_count (int): Total number of samples\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Combined dataframe with counts and percentages\n",
    "    \"\"\"\n",
    "    accuracy_pct_df = round(100 * accuracy_counts_df / total_count, 2)\n",
    "\n",
    "    combined_df = pd.DataFrame(\n",
    "        index=accuracy_counts_df.index, columns=accuracy_counts_df.columns\n",
    "    )\n",
    "\n",
    "    for col in accuracy_counts_df.columns:\n",
    "        combined_df[col] = (\n",
    "            accuracy_counts_df[col].astype(str)\n",
    "            + \" (\"\n",
    "            + accuracy_pct_df[col].astype(str)\n",
    "            + \"%)\"\n",
    "        )\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def _format_issue_text(issue, count, total_count):\n",
    "    \"\"\"Format the issue text with count and percentage.\n",
    "\n",
    "    Args:\n",
    "        issue (str): Issue name\n",
    "        count (int): Number of samples with this issue\n",
    "        total_count (int): Total number of samples\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted issue text\n",
    "    \"\"\"\n",
    "    issue_text = (\n",
    "        issue.replace(\"_\", \" \").title()\n",
    "        if \"only\" in issue\n",
    "        else issue.replace(\"_\", \" and \").title()\n",
    "    )\n",
    "    return f\"{issue_text} (N = {count}; {100 * count / total_count:.2f}%)\"\n",
    "\n",
    "\n",
    "def create_accuracy_table(\n",
    "    dataframe_with_counts,\n",
    "    quality_columns,\n",
    "    include_overall=True,\n",
    "    include_incorrect=False,\n",
    "):\n",
    "    \"\"\"Create a table of accuracy for each image quality issue\n",
    "\n",
    "    Args:\n",
    "        dataframe_with_counts (pandas dataframe): table that includes image quality issues and columns for each model, with values of yes, yes++, or no.\n",
    "        quality_columns (list): list of image quality issues to include in the table\n",
    "        include_overall (bool, optional): whether to include an overall accuracy row. Defaults to True.\n",
    "        include_incorrect (bool, optional): whether to include a row for the number of incorrect predictions. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pandas dataframe: table of accuracy for each image quality issue. Table will have 3 columns (one for each model) and 1-2 rows for each image quality issue (depending if include incorrect is true). If include_overall, then first row will include overall accuracy.\n",
    "    \"\"\"\n",
    "    output_df = pd.DataFrame()\n",
    "    total_count = len(dataframe_with_counts)\n",
    "    model_columns = [\"gpt4o_code\", \"llama_code\", \"molmo_code\"]\n",
    "    to_include = [\"yes\", \"no\"] if include_incorrect else [\"yes\"]\n",
    "\n",
    "    # Add overall row if requested\n",
    "    if include_overall:\n",
    "        accuracy_counts_df = _compute_accuracy_counts(\n",
    "            dataframe_with_counts, model_columns\n",
    "        )\n",
    "        combined_df = _create_combined_counts_df(accuracy_counts_df, total_count)\n",
    "        overall_text = f\"Overall (N = {total_count}; 100.00%)\"\n",
    "\n",
    "        overall_row_df = combined_df.loc[to_include]\n",
    "        overall_row_df[\"issue\"] = overall_text\n",
    "        output_df = pd.concat([output_df, overall_row_df], axis=0)\n",
    "\n",
    "    # Process each quality issue\n",
    "    for issue in quality_columns:\n",
    "        relevant_df = dataframe_with_counts[dataframe_with_counts[issue] == True]\n",
    "        if len(relevant_df) == 0:\n",
    "            continue\n",
    "\n",
    "        accuracy_counts_df = _compute_accuracy_counts(relevant_df, model_columns)\n",
    "        accuracy_counts_df = accuracy_counts_df.fillna(0)\n",
    "        combined_df = _create_combined_counts_df(accuracy_counts_df, len(relevant_df))\n",
    "\n",
    "        issue_text = _format_issue_text(issue, len(relevant_df), total_count)\n",
    "\n",
    "        issue_row_df = combined_df.loc[to_include]\n",
    "        issue_row_df[\"issue\"] = issue_text\n",
    "        output_df = pd.concat([output_df, issue_row_df], axis=0)\n",
    "\n",
    "    # reset index\n",
    "    output_df.reset_index(drop=False, inplace=True)\n",
    "    output_df.rename(columns={\"index\": \"Correct?\"}, inplace=True)\n",
    "\n",
    "    # move issue and index column to the front\n",
    "    output_df = output_df[\n",
    "        [\"issue\", \"Correct?\"]\n",
    "        + [col for col in output_df.columns if col != \"issue\" and col != \"Correct?\"]\n",
    "    ]\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue</th>\n",
       "      <th>Correct?</th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>Llama-3.2-11B-Vision-Instruct</th>\n",
       "      <th>Molmo-7B-O-0924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overall (N = 1220; 100.00%)</td>\n",
       "      <td>yes</td>\n",
       "      <td>842 (69.02%)</td>\n",
       "      <td>577 (47.3%)</td>\n",
       "      <td>450 (36.89%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blur Only (N = 151; 12.38%)</td>\n",
       "      <td>yes</td>\n",
       "      <td>114 (75.5%)</td>\n",
       "      <td>73 (48.34%)</td>\n",
       "      <td>67 (44.37%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Framing Only (N = 263; 21.56%)</td>\n",
       "      <td>yes</td>\n",
       "      <td>196 (74.52%)</td>\n",
       "      <td>147 (55.89%)</td>\n",
       "      <td>122 (46.39%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rotation Only (N = 57; 4.67%)</td>\n",
       "      <td>yes</td>\n",
       "      <td>49 (85.96%)</td>\n",
       "      <td>38 (66.67%)</td>\n",
       "      <td>17 (29.82%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Obstruction Only (N = 6; 0.49%)</td>\n",
       "      <td>yes</td>\n",
       "      <td>3 (50.0%)</td>\n",
       "      <td>4 (66.67%)</td>\n",
       "      <td>4 (66.67%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Too Dark Only (N = 3; 0.25%)</td>\n",
       "      <td>yes</td>\n",
       "      <td>2 (66.67%)</td>\n",
       "      <td>2 (66.67%)</td>\n",
       "      <td>2 (66.67%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Too Bright Only (N = 3; 0.25%)</td>\n",
       "      <td>yes</td>\n",
       "      <td>2 (66.67%)</td>\n",
       "      <td>0.0 (0.0%)</td>\n",
       "      <td>1 (33.33%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>No And Issues (N = 17; 1.39%)</td>\n",
       "      <td>yes</td>\n",
       "      <td>16 (94.12%)</td>\n",
       "      <td>12 (70.59%)</td>\n",
       "      <td>13 (76.47%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Other And Single And Issues (N = 29; 2.38%)</td>\n",
       "      <td>yes</td>\n",
       "      <td>23 (79.31%)</td>\n",
       "      <td>18 (62.07%)</td>\n",
       "      <td>20 (68.97%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Blur And Framing (N = 259; 21.23%)</td>\n",
       "      <td>yes</td>\n",
       "      <td>166 (64.09%)</td>\n",
       "      <td>117 (45.17%)</td>\n",
       "      <td>99 (38.22%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Blur And Rotation (N = 80; 6.56%)</td>\n",
       "      <td>yes</td>\n",
       "      <td>49 (61.25%)</td>\n",
       "      <td>29 (36.25%)</td>\n",
       "      <td>13 (16.25%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Framing And Rotation (N = 156; 12.79%)</td>\n",
       "      <td>yes</td>\n",
       "      <td>115 (73.72%)</td>\n",
       "      <td>79 (50.64%)</td>\n",
       "      <td>55 (35.26%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Blur And Framing And Rotation (N = 141; 11.56%)</td>\n",
       "      <td>yes</td>\n",
       "      <td>80 (56.74%)</td>\n",
       "      <td>53 (37.59%)</td>\n",
       "      <td>34 (24.11%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Other And Cooccurring (N = 84; 6.89%)</td>\n",
       "      <td>yes</td>\n",
       "      <td>50 (59.52%)</td>\n",
       "      <td>23 (27.38%)</td>\n",
       "      <td>23 (27.38%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              issue Correct? gpt-4o-2024-08-06 Llama-3.2-11B-Vision-Instruct Molmo-7B-O-0924\n",
       "0                       Overall (N = 1220; 100.00%)      yes      842 (69.02%)                   577 (47.3%)    450 (36.89%)\n",
       "1                       Blur Only (N = 151; 12.38%)      yes       114 (75.5%)                   73 (48.34%)     67 (44.37%)\n",
       "2                    Framing Only (N = 263; 21.56%)      yes      196 (74.52%)                  147 (55.89%)    122 (46.39%)\n",
       "3                     Rotation Only (N = 57; 4.67%)      yes       49 (85.96%)                   38 (66.67%)     17 (29.82%)\n",
       "4                   Obstruction Only (N = 6; 0.49%)      yes         3 (50.0%)                    4 (66.67%)      4 (66.67%)\n",
       "5                      Too Dark Only (N = 3; 0.25%)      yes        2 (66.67%)                    2 (66.67%)      2 (66.67%)\n",
       "6                    Too Bright Only (N = 3; 0.25%)      yes        2 (66.67%)                    0.0 (0.0%)      1 (33.33%)\n",
       "7                     No And Issues (N = 17; 1.39%)      yes       16 (94.12%)                   12 (70.59%)     13 (76.47%)\n",
       "8       Other And Single And Issues (N = 29; 2.38%)      yes       23 (79.31%)                   18 (62.07%)     20 (68.97%)\n",
       "9                Blur And Framing (N = 259; 21.23%)      yes      166 (64.09%)                  117 (45.17%)     99 (38.22%)\n",
       "10                Blur And Rotation (N = 80; 6.56%)      yes       49 (61.25%)                   29 (36.25%)     13 (16.25%)\n",
       "11           Framing And Rotation (N = 156; 12.79%)      yes      115 (73.72%)                   79 (50.64%)     55 (35.26%)\n",
       "12  Blur And Framing And Rotation (N = 141; 11.56%)      yes       80 (56.74%)                   53 (37.59%)     34 (24.11%)\n",
       "13            Other And Cooccurring (N = 84; 6.89%)      yes       50 (59.52%)                   23 (27.38%)     23 (27.38%)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_issues = [\n",
    "    # individual issues\n",
    "    \"blur_only\",\n",
    "    \"framing_only\",\n",
    "    \"rotation_only\",\n",
    "    \"obstruction_only\",\n",
    "    \"too_dark_only\",\n",
    "    \"too_bright_only\",\n",
    "    \"other_only\",\n",
    "    \"no_issues\",\n",
    "    \"other_single_issues\",\n",
    "    # cooccurring issues\n",
    "    \"blur_framing\",\n",
    "    \"blur_rotation\",\n",
    "    \"framing_rotation\",\n",
    "    \"blur_framing_rotation\",\n",
    "    \"other_cooccurring\",\n",
    "]\n",
    "\n",
    "create_accuracy_table(\n",
    "    annotations_df[(annotations_df[\"unable_to_verify\"] == \"\")],\n",
    "    quality_issues,\n",
    "    include_overall=True,\n",
    "    include_incorrect=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy given rounded products and text panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images with curved label: 355 (29.10%)\n",
      "Number of images with text panel: 172 (14.10%)\n",
      "Number of images with curved label and text panel: 49 (4.02%)\n"
     ]
    }
   ],
   "source": [
    "# let's also look at rounded and text panel images\n",
    "annotations_df_curved = annotations_df[\n",
    "    (annotations_df[\"unable_to_verify\"] == \"\") & (annotations_df[\"curved label\"] == \"x\")\n",
    "]\n",
    "annotations_df_text = annotations_df[\n",
    "    (annotations_df[\"unable_to_verify\"] == \"\") & (annotations_df[\"text panel\"] == \"x\")\n",
    "]\n",
    "\n",
    "annotations_df_curved_text = annotations_df[\n",
    "    (annotations_df[\"unable_to_verify\"] == \"\")\n",
    "    & (annotations_df[\"curved label\"] == \"x\")\n",
    "    & (annotations_df[\"text panel\"] == \"x\")\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Number of images with curved label: {len(annotations_df_curved)} ({len(annotations_df_curved)/len(annotations_df[annotations_df['unable_to_verify'] == '']) * 100:.2f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of images with text panel: {len(annotations_df_text)} ({len(annotations_df_text)/len(annotations_df[annotations_df['unable_to_verify'] == '']) * 100:.2f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of images with curved label and text panel: {len(annotations_df_curved_text)} ({len(annotations_df_curved_text)/len(annotations_df[annotations_df['unable_to_verify'] == '']) * 100:.2f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>Llama-3.2-11B-Vision-Instruct</th>\n",
       "      <th>Molmo-7B-O-0924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>222</td>\n",
       "      <td>156</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>133</td>\n",
       "      <td>199</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gpt-4o-2024-08-06  Llama-3.2-11B-Vision-Instruct  Molmo-7B-O-0924\n",
       "yes                222                            156              136\n",
       "no                 133                            199              219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>Llama-3.2-11B-Vision-Instruct</th>\n",
       "      <th>Molmo-7B-O-0924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>62.5</td>\n",
       "      <td>43.9</td>\n",
       "      <td>38.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>37.5</td>\n",
       "      <td>56.1</td>\n",
       "      <td>61.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gpt-4o-2024-08-06  Llama-3.2-11B-Vision-Instruct  Molmo-7B-O-0924\n",
       "yes               62.5                           43.9             38.3\n",
       "no                37.5                           56.1             61.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>Llama-3.2-11B-Vision-Instruct</th>\n",
       "      <th>Molmo-7B-O-0924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>222</td>\n",
       "      <td>156</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>133</td>\n",
       "      <td>199</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gpt-4o-2024-08-06  Llama-3.2-11B-Vision-Instruct  Molmo-7B-O-0924\n",
       "yes                222                            156              136\n",
       "no                 133                            199              219"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# curved only\n",
    "get_accuracy_counts(annotations_df_curved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>Llama-3.2-11B-Vision-Instruct</th>\n",
       "      <th>Molmo-7B-O-0924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>96</td>\n",
       "      <td>118</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>76</td>\n",
       "      <td>54</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gpt-4o-2024-08-06  Llama-3.2-11B-Vision-Instruct  Molmo-7B-O-0924\n",
       "no                  96                            118              133\n",
       "yes                 76                             54               39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>Llama-3.2-11B-Vision-Instruct</th>\n",
       "      <th>Molmo-7B-O-0924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>55.8</td>\n",
       "      <td>68.6</td>\n",
       "      <td>77.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>44.2</td>\n",
       "      <td>31.4</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gpt-4o-2024-08-06  Llama-3.2-11B-Vision-Instruct  Molmo-7B-O-0924\n",
       "no                55.8                           68.6             77.3\n",
       "yes               44.2                           31.4             22.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>Llama-3.2-11B-Vision-Instruct</th>\n",
       "      <th>Molmo-7B-O-0924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>96</td>\n",
       "      <td>118</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>76</td>\n",
       "      <td>54</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gpt-4o-2024-08-06  Llama-3.2-11B-Vision-Instruct  Molmo-7B-O-0924\n",
       "no                  96                            118              133\n",
       "yes                 76                             54               39"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text panel only\n",
    "get_accuracy_counts(annotations_df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>Llama-3.2-11B-Vision-Instruct</th>\n",
       "      <th>Molmo-7B-O-0924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gpt-4o-2024-08-06  Llama-3.2-11B-Vision-Instruct  Molmo-7B-O-0924\n",
       "no                  28                             33               36\n",
       "yes                 21                             16               13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>Llama-3.2-11B-Vision-Instruct</th>\n",
       "      <th>Molmo-7B-O-0924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>57.1</td>\n",
       "      <td>67.3</td>\n",
       "      <td>73.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>42.9</td>\n",
       "      <td>32.7</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gpt-4o-2024-08-06  Llama-3.2-11B-Vision-Instruct  Molmo-7B-O-0924\n",
       "no                57.1                           67.3             73.5\n",
       "yes               42.9                           32.7             26.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt-4o-2024-08-06</th>\n",
       "      <th>Llama-3.2-11B-Vision-Instruct</th>\n",
       "      <th>Molmo-7B-O-0924</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gpt-4o-2024-08-06  Llama-3.2-11B-Vision-Instruct  Molmo-7B-O-0924\n",
       "no                  28                             33               36\n",
       "yes                 21                             16               13"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# curved and text panel\n",
    "get_accuracy_counts(annotations_df_curved_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 2: how does image quality affect a VLM's ability to accurately identify products?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine annotation data with image quality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in regression df: 1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6w/gkg9vw3d29jglv9knrxxf3r40000gn/T/ipykernel_99112/41215893.py:41: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  regression_df.replace({\"yes\": 1, \"no\": 0}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing_x</th>\n",
       "      <th>blur_x</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation_x</th>\n",
       "      <th>too dark</th>\n",
       "      <th>too bright</th>\n",
       "      <th>other</th>\n",
       "      <th>no issue</th>\n",
       "      <th>human_captions</th>\n",
       "      <th>blur_y</th>\n",
       "      <th>framing_y</th>\n",
       "      <th>rotation_y</th>\n",
       "      <th>gpt4o_caption</th>\n",
       "      <th>gpt4o_code</th>\n",
       "      <th>llama_caption</th>\n",
       "      <th>llama_code</th>\n",
       "      <th>molmo_caption</th>\n",
       "      <th>molmo_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>16588</td>\n",
       "      <td>VizWiz_train_00016588.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>House keys, medicine, and a package with the t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A pack of Pall Mall cigarettes with a green de...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image depicts a green Pall Mall cigarette ...</td>\n",
       "      <td>1</td>\n",
       "      <td>A pack of Pall Mall cigarettes is visible on a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>15621</td>\n",
       "      <td>VizWiz_train_00015621.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a person's hand is covering a bottle of bubble...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A hand is holding a bottle labeled \"moonlight ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The object is a plastic bottle of bubble bath ...</td>\n",
       "      <td>0</td>\n",
       "      <td>A hand with two gold rings is holding a rectan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>7225</td>\n",
       "      <td>VizWiz_train_00007225.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A package of cigarettes resting on black leath...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A pack of Marlboro cigarettes with a red and w...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a pack of Marlboro cigarettes ...</td>\n",
       "      <td>1</td>\n",
       "      <td>A pack of Marlboro cigarettes is visible on a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>3429</td>\n",
       "      <td>VizWiz_train_00003429.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A 2 liter bottle of Pepsi and someone's hand.\\...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A bottle of Pepsi with a red, white, and blue ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a dark brown glass bottle with...</td>\n",
       "      <td>1</td>\n",
       "      <td>A Pepsi bottle is partially visible on a woode...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>17399</td>\n",
       "      <td>VizWiz_train_00017399.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A seasoned steak food product in white packagi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A packaging bag with visible text that reads \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image appears to be a close-up of a white ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a plastic bag containing a foo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id                  file_name                                         vizwiz_url  text_detected  unrecognizable  framing_x  blur_x  obstruction  rotation_x  too dark  too bright  other  no issue                                     human_captions  blur_y  framing_y  rotation_y                                      gpt4o_caption  gpt4o_code                                      llama_caption  llama_code                                      molmo_caption  molmo_code\n",
       "437     16588  VizWiz_train_00016588.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0          0       0            0           0         4           0      0         1  House keys, medicine, and a package with the t...   False      False       False  A pack of Pall Mall cigarettes with a green de...           1  The image depicts a green Pall Mall cigarette ...           1  A pack of Pall Mall cigarettes is visible on a...           1\n",
       "438     15621  VizWiz_train_00015621.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0          0       0            4           0         1           0      1         0  a person's hand is covering a bottle of bubble...   False      False       False  A hand is holding a bottle labeled \"moonlight ...           1  The object is a plastic bottle of bubble bath ...           0  A hand with two gold rings is holding a rectan...           0\n",
       "439      7225  VizWiz_train_00007225.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0          0       0            5           0         0           0      0         0  A package of cigarettes resting on black leath...   False      False       False  A pack of Marlboro cigarettes with a red and w...           1  The image shows a pack of Marlboro cigarettes ...           1  A pack of Marlboro cigarettes is visible on a ...           1\n",
       "440      3429  VizWiz_train_00003429.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0          0       0            4           0         0           0      0         1  A 2 liter bottle of Pepsi and someone's hand.\\...   False      False       False  A bottle of Pepsi with a red, white, and blue ...           1  The image shows a dark brown glass bottle with...           1  A Pepsi bottle is partially visible on a woode...           1\n",
       "441     17399  VizWiz_train_00017399.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True               0          1       0            0           0         4           0      0         1  A seasoned steak food product in white packagi...   False      False       False  A packaging bag with visible text that reads \"...           1  The image appears to be a close-up of a white ...           1  The image shows a plastic bag containing a foo...           1"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine with annotation data\n",
    "columns_to_include = [\n",
    "    \"image_id\",\n",
    "    \"file_name\",\n",
    "    \"vizwiz_url\",\n",
    "    \"human_captions\",\n",
    "    \"unable_to_verify\",\n",
    "    \"double code notes\",\n",
    "    \"double verified\",\n",
    "    \"blur\",\n",
    "    \"framing\",\n",
    "    \"rotation\",\n",
    "    \"gpt4o_caption\",\n",
    "    \"gpt4o_code\",\n",
    "    \"llama_caption\",\n",
    "    \"llama_code\",\n",
    "    \"molmo_caption\",\n",
    "    \"molmo_code\",\n",
    "]\n",
    "regression_df = pd.merge(\n",
    "    filtered_evaluation_data_df,\n",
    "    annotations_df[columns_to_include],\n",
    "    on=[\"image_id\", \"file_name\", \"vizwiz_url\"],\n",
    "    how=\"right\",\n",
    ")\n",
    "\n",
    "# make sure each model has a yes or no\n",
    "regression_df = regression_df[regression_df[\"unable_to_verify\"] == \"\"]\n",
    "regression_df = regression_df[\n",
    "    (regression_df[\"gpt4o_code\"] != \"unsure\") & (regression_df[\"gpt4o_code\"] != \"\")\n",
    "]\n",
    "regression_df = regression_df[\n",
    "    (regression_df[\"llama_code\"] != \"unsure\") & (regression_df[\"llama_code\"] != \"\")\n",
    "]\n",
    "regression_df = regression_df[\n",
    "    (regression_df[\"molmo_code\"] != \"unsure\") & (regression_df[\"molmo_code\"] != \"\")\n",
    "]\n",
    "\n",
    "# combine yes and yes++\n",
    "regression_df.replace({\"yes++\": \"yes\"}, inplace=True)\n",
    "regression_df.replace({\"yes\": 1, \"no\": 0}, inplace=True)\n",
    "regression_df[\"gpt4o_code\"] = pd.to_numeric(regression_df[\"gpt4o_code\"])\n",
    "regression_df[\"llama_code\"] = pd.to_numeric(regression_df[\"llama_code\"])\n",
    "regression_df[\"molmo_code\"] = pd.to_numeric(regression_df[\"molmo_code\"])\n",
    "\n",
    "# cleanup\n",
    "del regression_df[\"unable_to_verify\"]\n",
    "del regression_df[\"double code notes\"]\n",
    "del regression_df[\"double verified\"]\n",
    "\n",
    "print(f\"Number of images in regression df: {len(regression_df)}\")\n",
    "regression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>image_preview</th>\n",
       "      <th>human_captions</th>\n",
       "      <th>annotator</th>\n",
       "      <th>notes</th>\n",
       "      <th>unable_to_verify</th>\n",
       "      <th>double code notes</th>\n",
       "      <th>double verified</th>\n",
       "      <th>gpt4o_caption</th>\n",
       "      <th>gpt4o_code</th>\n",
       "      <th>llama_caption</th>\n",
       "      <th>llama_code</th>\n",
       "      <th>molmo_caption</th>\n",
       "      <th>molmo_code</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable_orig</th>\n",
       "      <th>framing_orig</th>\n",
       "      <th>blur_orig</th>\n",
       "      <th>obstruction_orig</th>\n",
       "      <th>rotation_orig</th>\n",
       "      <th>too_dark_orig</th>\n",
       "      <th>too_bright_orig</th>\n",
       "      <th>other_orig</th>\n",
       "      <th>curved label</th>\n",
       "      <th>text panel</th>\n",
       "      <th>AMP_rotation</th>\n",
       "      <th>XT_rotation</th>\n",
       "      <th>expert_caption</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>too bright</th>\n",
       "      <th>other</th>\n",
       "      <th>blur_framing</th>\n",
       "      <th>blur_rotation</th>\n",
       "      <th>framing_rotation</th>\n",
       "      <th>blur_framing_rotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16253</td>\n",
       "      <td>VizWiz_train_00016253.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A cup of hot chocolate with cookies next to it...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A white mug filled with a frothy drink topped ...</td>\n",
       "      <td></td>\n",
       "      <td>The image shows a white mug with a handle on t...</td>\n",
       "      <td></td>\n",
       "      <td>The image shows a white mug containing a light...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1210</td>\n",
       "      <td>VizWiz_train_00001210.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>The cooking instructions on a package of a foo...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A printed instruction sheet with text and illu...</td>\n",
       "      <td></td>\n",
       "      <td>The image shows a white and green plastic cont...</td>\n",
       "      <td></td>\n",
       "      <td>The image shows a green plastic food storage c...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8939</td>\n",
       "      <td>VizWiz_train_00008939.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A can of something with a lime green and dark ...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A green can with a black lid and design elemen...</td>\n",
       "      <td></td>\n",
       "      <td>The image shows a cylindrical can with a green...</td>\n",
       "      <td></td>\n",
       "      <td>A green cylindrical can with a black lid, like...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8607</td>\n",
       "      <td>VizWiz_train_00008607.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>Quality issues are too severe to recognize vis...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A can with a partially visible label featuring...</td>\n",
       "      <td></td>\n",
       "      <td>The object is a silver can with a red label fe...</td>\n",
       "      <td></td>\n",
       "      <td>A can of diced tomatoes is visible on a granit...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16752</td>\n",
       "      <td>VizWiz_train_00016752.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A white bag of instant flour mix for preparing...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>Nutrition facts and ingredient list from a foo...</td>\n",
       "      <td></td>\n",
       "      <td>The image shows a nutrition label on a food pr...</td>\n",
       "      <td></td>\n",
       "      <td>The image shows a nutrition label on a food pa...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>17557</td>\n",
       "      <td>VizWiz_train_00017557.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>Back of a box of hot tamales showing the flavo...</td>\n",
       "      <td></td>\n",
       "      <td>hot tamales candy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A box with a red and yellow design features th...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows the back of a box of Hot Tamal...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a box of Hot Tamales candy. Th...</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>Back of a box of hot tamales showing the flavo...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>11995</td>\n",
       "      <td>VizWiz_train_00011995.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>Green and white fabric clothing with a trophy ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A graphic of a trophy in black and white, with...</td>\n",
       "      <td></td>\n",
       "      <td>The image depicts a trophy with a round base, ...</td>\n",
       "      <td></td>\n",
       "      <td>The image depicts a trophy with a round top an...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Green and white fabric clothing with a trophy ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>5029</td>\n",
       "      <td>VizWiz_train_00005029.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A Marie Callender's frozen entree rests on a w...</td>\n",
       "      <td></td>\n",
       "      <td>marie callenders country fried pork chop</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A packaged meal with an image of breaded chick...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image appears to be a frozen food package,...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a box of mashed potatoes. The ...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>A Marie Callender's frozen entree rests on a w...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>9975</td>\n",
       "      <td>VizWiz_train_00009975.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A can or container of a food product called Ru...</td>\n",
       "      <td></td>\n",
       "      <td>wray and nephew rum cream</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A bottle with the text \"WRAY &amp; NEPHEW\" on a gr...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a cylindrical container with a...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a bottle of rum cream. The bot...</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>A can or container of a food product called Ru...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>14006</td>\n",
       "      <td>VizWiz_train_00014006.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A package of Jimmy Dean fully cooked maple por...</td>\n",
       "      <td></td>\n",
       "      <td>jimmy dean maple pork sausage patties</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A box labeled \"Jimmy Dean Fully Cooked Maple P...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a red box of Jimmy Dean fully ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a box of frozen chicken tender...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>A package of Jimmy Dean fully cooked maple por...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1696 rows  42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id                  file_name                                         vizwiz_url image_preview                                     human_captions   annotator                                     notes unable_to_verify double code notes double verified                                      gpt4o_caption gpt4o_code                                      llama_caption llama_code                                      molmo_caption molmo_code text_detected  unrecognizable_orig  framing_orig  blur_orig  obstruction_orig  rotation_orig  too_dark_orig  too_bright_orig  other_orig curved label text panel AMP_rotation XT_rotation                                     expert_caption  unrecognizable  framing   blur  obstruction  rotation  too dark  too bright  other  blur_framing  blur_rotation  framing_rotation  blur_framing_rotation\n",
       "0        16253  VizWiz_train_00016253.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A cup of hot chocolate with cookies next to it...  Anne Marie                                                        yes                                 x  A white mug filled with a frothy drink topped ...             The image shows a white mug with a handle on t...             The image shows a white mug containing a light...                     True                    0             4          0                 2              0              2                1           0                                                                                                               False     True  False         True     False      True       False      0         False           True             False                  False\n",
       "1         1210  VizWiz_train_00001210.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                The cooking instructions on a package of a foo...  Anne Marie                                                        yes                                 x  A printed instruction sheet with text and illu...             The image shows a white and green plastic cont...             The image shows a green plastic food storage c...                     True                    0             4          0                 0              0              0                0           0                       x                                                                                       False     True  False        False     False     False       False      0         False           True             False                  False\n",
       "2         8939  VizWiz_train_00008939.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A can of something with a lime green and dark ...  Anne Marie                                                        yes                                 x  A green can with a black lid and design elemen...             The image shows a cylindrical can with a green...             A green cylindrical can with a black lid, like...                     True                    1             4          0                 0              0              0                0           0            x          x                                                                                       False     True  False        False     False     False       False      0         False           True             False                  False\n",
       "3         8607  VizWiz_train_00008607.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                Quality issues are too severe to recognize vis...  Anne Marie                                                        yes                                 x  A can with a partially visible label featuring...             The object is a silver can with a red label fe...             A can of diced tomatoes is visible on a granit...                     True                    1             4          0                 0              0              0                0           0            x                                                                                                  False     True  False        False     False     False       False      0         False           True             False                  False\n",
       "4        16752  VizWiz_train_00016752.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A white bag of instant flour mix for preparing...  Anne Marie                                                        yes                                 x  Nutrition facts and ingredient list from a foo...             The image shows a nutrition label on a food pr...             The image shows a nutrition label on a food pa...                     True                    0             4          0                 0              0              0                0           0                       x                                                                                       False     True  False        False     False     False       False      0         False           True             False                  False\n",
       "...        ...                        ...                                                ...           ...                                                ...         ...                                       ...              ...               ...             ...                                                ...        ...                                                ...        ...                                                ...        ...           ...                  ...           ...        ...               ...            ...            ...              ...         ...          ...        ...          ...         ...                                                ...             ...      ...    ...          ...       ...       ...         ...    ...           ...            ...               ...                    ...\n",
       "1691     17557  VizWiz_train_00017557.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                Back of a box of hot tamales showing the flavo...                                     hot tamales candy                                                  x  A box with a red and yellow design features th...         no  The image shows the back of a box of Hot Tamal...        yes  The image shows a box of Hot Tamales candy. Th...        yes          True                    0             2          4                 0              3              0                0           0                                    x           x  Back of a box of hot tamales showing the flavo...           False     True   True        False      True     False       False      0          True           True              True                   True\n",
       "1692     11995  VizWiz_train_00011995.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                Green and white fabric clothing with a trophy ...                                                                    yes                                 x  A graphic of a trophy in black and white, with...             The image depicts a trophy with a round base, ...             The image depicts a trophy with a round top an...                     True                    0             4          2                 0              0              0                0           0                                                   Green and white fabric clothing with a trophy ...           False     True   True        False     False     False       False      0          True          False             False                  False\n",
       "1693      5029  VizWiz_train_00005029.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A Marie Callender's frozen entree rests on a w...              marie callenders country fried pork chop                                                  x  A packaged meal with an image of breaded chick...         no  The image appears to be a frozen food package,...         no  The image shows a box of mashed potatoes. The ...         no          True                    0             1          5                 0              4              0                0           0                                    x           x  A Marie Callender's frozen entree rests on a w...           False    False   True        False      True     False       False      0         False           True             False                  False\n",
       "1694      9975  VizWiz_train_00009975.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A can or container of a food product called Ru...                             wray and nephew rum cream                                                  x  A bottle with the text \"WRAY & NEPHEW\" on a gr...        yes  The image shows a cylindrical container with a...         no  The image shows a bottle of rum cream. The bot...        yes          True                    1             4          2                 0              5              0                0           0            x                       x           x  A can or container of a food product called Ru...           False     True   True        False      True     False       False      0          True           True              True                   True\n",
       "1695     14006  VizWiz_train_00014006.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A package of Jimmy Dean fully cooked maple por...                 jimmy dean maple pork sausage patties                                                  x  A box labeled \"Jimmy Dean Fully Cooked Maple P...        yes  The image shows a red box of Jimmy Dean fully ...        yes  The image shows a box of frozen chicken tender...         no          True                    0             1          0                 0              4              0                1           0                                    x           x  A package of Jimmy Dean fully cooked maple por...           False    False  False        False      True     False       False      0          True          False             False                  False\n",
       "\n",
       "[1696 rows x 42 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save regression df\n",
    "os.makedirs(\n",
    "    \"./intermediate-data\",\n",
    "    exist_ok=True,\n",
    ")\n",
    "regression_df.to_csv(\n",
    "    f\"./intermediate-data/regression-continuious-df_{len(regression_df)}-images.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bins for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_quality_columns = [\n",
    "    \"unrecognizable\",\n",
    "    \"framing\",\n",
    "    \"blur\",\n",
    "    \"obstruction\",\n",
    "    \"rotation\",\n",
    "    \"too dark\",\n",
    "    \"too bright\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>too bright</th>\n",
       "      <th>other</th>\n",
       "      <th>no issue</th>\n",
       "      <th>human_captions</th>\n",
       "      <th>gpt4o_caption</th>\n",
       "      <th>gpt4o_code</th>\n",
       "      <th>llama_caption</th>\n",
       "      <th>llama_code</th>\n",
       "      <th>molmo_caption</th>\n",
       "      <th>molmo_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9886</td>\n",
       "      <td>VizWiz_train_00009886.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A box of frozen food sits on a table top that ...</td>\n",
       "      <td>A package of Trader Joe's Paneer Tikka Masala ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a frozen food package with a g...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a food package for a Tikka Mas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12066</td>\n",
       "      <td>VizWiz_train_00012066.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A Kroger grocery store tag for a caramel iced ...</td>\n",
       "      <td>A caramel iced cake with a label featuring the...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a white label with the blue an...</td>\n",
       "      <td>0</td>\n",
       "      <td>The image shows a plastic container of apple c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1908</td>\n",
       "      <td>VizWiz_train_00001908.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A description on a box of herbal tea.\\nA print...</td>\n",
       "      <td>A label with the text \"A delicious CAFFEINE FR...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a white box with the words \"A ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a sideways view of a product l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15399</td>\n",
       "      <td>VizWiz_train_00015399.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A green and white box of Lean Pockets frozen r...</td>\n",
       "      <td>Box of Lean Pockets with garlic chicken white ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a green and white box of Lean ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a box of Lean Pockets on a whi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4380</td>\n",
       "      <td>VizWiz_train_00004380.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>issue present</td>\n",
       "      <td>no issue</td>\n",
       "      <td>no issue</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>garlic spinach hummus possibly in a green cont...</td>\n",
       "      <td>A plastic container with a green lid, featurin...</td>\n",
       "      <td>0</td>\n",
       "      <td>The image shows a plastic container with a gre...</td>\n",
       "      <td>0</td>\n",
       "      <td>The image shows a plastic food container on a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                  file_name                                         vizwiz_url  text_detected unrecognizable        framing           blur obstruction       rotation  too dark too bright  other  no issue                                     human_captions                                      gpt4o_caption  gpt4o_code                                      llama_caption  llama_code                                      molmo_caption  molmo_code\n",
       "0      9886  VizWiz_train_00009886.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True       no issue       no issue  issue present    no issue  issue present  no issue   no issue      0         1  A box of frozen food sits on a table top that ...  A package of Trader Joe's Paneer Tikka Masala ...           1  The image shows a frozen food package with a g...           1  The image shows a food package for a Tikka Mas...           0\n",
       "1     12066  VizWiz_train_00012066.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True       no issue  issue present  issue present    no issue       no issue  no issue   no issue      0         0  A Kroger grocery store tag for a caramel iced ...  A caramel iced cake with a label featuring the...           1  The image shows a white label with the blue an...           0  The image shows a plastic container of apple c...           0\n",
       "2      1908  VizWiz_train_00001908.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True       no issue  issue present  issue present    no issue  issue present  no issue   no issue      0         0  A description on a box of herbal tea.\\nA print...  A label with the text \"A delicious CAFFEINE FR...           1  The image shows a white box with the words \"A ...           1  The image shows a sideways view of a product l...           1\n",
       "3     15399  VizWiz_train_00015399.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True       no issue  issue present       no issue    no issue  issue present  no issue   no issue      0         1  A green and white box of Lean Pockets frozen r...  Box of Lean Pockets with garlic chicken white ...           1  The image shows a green and white box of Lean ...           1  The image shows a box of Lean Pockets on a whi...           0\n",
       "4      4380  VizWiz_train_00004380.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True       no issue  issue present       no issue    no issue  issue present  no issue   no issue      0         0  garlic spinach hummus possibly in a green cont...  A plastic container with a green lid, featurin...           0  The image shows a plastic container with a gre...           0  The image shows a plastic food container on a ...           0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bin image quality issues into 2 bins\n",
    "regression_two_bins_df = regression_df.copy()\n",
    "for iq in image_quality_columns:\n",
    "    regression_two_bins_df[iq] = regression_two_bins_df[iq].astype(str)\n",
    "    regression_two_bins_df[iq] = regression_two_bins_df[iq].map(\n",
    "        {\n",
    "            \"0\": \"no issue\",\n",
    "            \"1\": \"no issue\",\n",
    "            \"2\": \"issue present\",\n",
    "            \"3\": \"issue present\",\n",
    "            \"4\": \"issue present\",\n",
    "            \"5\": \"issue present\",\n",
    "        }\n",
    "    )\n",
    "display(regression_two_bins_df.head())\n",
    "regression_two_bins_df.to_csv(\n",
    "    f\"./intermediate-data/regression-two-bins-df_{len(regression_two_bins_df)}-images.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>too bright</th>\n",
       "      <th>other</th>\n",
       "      <th>no issue</th>\n",
       "      <th>human_captions</th>\n",
       "      <th>gpt4o_caption</th>\n",
       "      <th>gpt4o_code</th>\n",
       "      <th>llama_caption</th>\n",
       "      <th>llama_code</th>\n",
       "      <th>molmo_caption</th>\n",
       "      <th>molmo_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9886</td>\n",
       "      <td>VizWiz_train_00009886.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>.medium</td>\n",
       "      <td>.low</td>\n",
       "      <td>.high</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A box of frozen food sits on a table top that ...</td>\n",
       "      <td>A package of Trader Joe's Paneer Tikka Masala ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a frozen food package with a g...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a food package for a Tikka Mas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12066</td>\n",
       "      <td>VizWiz_train_00012066.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>.low</td>\n",
       "      <td>.high</td>\n",
       "      <td>.medium</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A Kroger grocery store tag for a caramel iced ...</td>\n",
       "      <td>A caramel iced cake with a label featuring the...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a white label with the blue an...</td>\n",
       "      <td>0</td>\n",
       "      <td>The image shows a plastic container of apple c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1908</td>\n",
       "      <td>VizWiz_train_00001908.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>.low</td>\n",
       "      <td>.medium</td>\n",
       "      <td>.high</td>\n",
       "      <td>.low</td>\n",
       "      <td>.medium</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A description on a box of herbal tea.\\nA print...</td>\n",
       "      <td>A label with the text \"A delicious CAFFEINE FR...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a white box with the words \"A ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a sideways view of a product l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15399</td>\n",
       "      <td>VizWiz_train_00015399.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>.low</td>\n",
       "      <td>.high</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>.medium</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A green and white box of Lean Pockets frozen r...</td>\n",
       "      <td>Box of Lean Pockets with garlic chicken white ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a green and white box of Lean ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a box of Lean Pockets on a whi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4380</td>\n",
       "      <td>VizWiz_train_00004380.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>.low</td>\n",
       "      <td>.high</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>.medium</td>\n",
       "      <td>.low</td>\n",
       "      <td>.low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>garlic spinach hummus possibly in a green cont...</td>\n",
       "      <td>A plastic container with a green lid, featurin...</td>\n",
       "      <td>0</td>\n",
       "      <td>The image shows a plastic container with a gre...</td>\n",
       "      <td>0</td>\n",
       "      <td>The image shows a plastic food container on a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                  file_name                                         vizwiz_url  text_detected unrecognizable  framing     blur obstruction rotation too dark too bright  other  no issue                                     human_captions                                      gpt4o_caption  gpt4o_code                                      llama_caption  llama_code                                      molmo_caption  molmo_code\n",
       "0      9886  VizWiz_train_00009886.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True           .low     .low  .medium        .low    .high     .low       .low      0         1  A box of frozen food sits on a table top that ...  A package of Trader Joe's Paneer Tikka Masala ...           1  The image shows a frozen food package with a g...           1  The image shows a food package for a Tikka Mas...           0\n",
       "1     12066  VizWiz_train_00012066.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True           .low    .high  .medium        .low     .low     .low       .low      0         0  A Kroger grocery store tag for a caramel iced ...  A caramel iced cake with a label featuring the...           1  The image shows a white label with the blue an...           0  The image shows a plastic container of apple c...           0\n",
       "2      1908  VizWiz_train_00001908.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True           .low  .medium    .high        .low  .medium     .low       .low      0         0  A description on a box of herbal tea.\\nA print...  A label with the text \"A delicious CAFFEINE FR...           1  The image shows a white box with the words \"A ...           1  The image shows a sideways view of a product l...           1\n",
       "3     15399  VizWiz_train_00015399.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True           .low    .high     .low        .low  .medium     .low       .low      0         1  A green and white box of Lean Pockets frozen r...  Box of Lean Pockets with garlic chicken white ...           1  The image shows a green and white box of Lean ...           1  The image shows a box of Lean Pockets on a whi...           0\n",
       "4      4380  VizWiz_train_00004380.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True           .low    .high     .low        .low  .medium     .low       .low      0         0  garlic spinach hummus possibly in a green cont...  A plastic container with a green lid, featurin...           0  The image shows a plastic container with a gre...           0  The image shows a plastic food container on a ...           0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bin image quality issues into 2 bins\n",
    "regression_three_bins_df = regression_df.copy()\n",
    "for iq in image_quality_columns:\n",
    "    regression_three_bins_df[iq] = regression_three_bins_df[iq].astype(str)\n",
    "    regression_three_bins_df[iq] = regression_three_bins_df[iq].map(\n",
    "        {\n",
    "            \"0\": \".low\",\n",
    "            \"1\": \".low\",\n",
    "            \"2\": \".medium\",\n",
    "            \"3\": \".medium\",\n",
    "            \"4\": \".high\",\n",
    "            \"5\": \".high\",\n",
    "        }\n",
    "    )\n",
    "display(regression_three_bins_df.head())\n",
    "regression_three_bins_df.to_csv(\n",
    "    f\"./intermediate-data/regression-three-bins-df_{len(regression_three_bins_df)}-images.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final regression table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6w/gkg9vw3d29jglv9knrxxf3r40000gn/T/ipykernel_99112/1356024679.py:38: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  regression_df.replace({\"yes\": 1, \"no\": 0}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>human_captions</th>\n",
       "      <th>blur</th>\n",
       "      <th>framing</th>\n",
       "      <th>rotation</th>\n",
       "      <th>blur_framing</th>\n",
       "      <th>blur_rotation</th>\n",
       "      <th>framing_rotation</th>\n",
       "      <th>blur_framing_rotation</th>\n",
       "      <th>gpt4o_caption</th>\n",
       "      <th>gpt4o_code</th>\n",
       "      <th>llama_caption</th>\n",
       "      <th>llama_code</th>\n",
       "      <th>molmo_caption</th>\n",
       "      <th>molmo_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>16588</td>\n",
       "      <td>VizWiz_train_00016588.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>House keys, medicine, and a package with the t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A pack of Pall Mall cigarettes with a green de...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image depicts a green Pall Mall cigarette ...</td>\n",
       "      <td>1</td>\n",
       "      <td>A pack of Pall Mall cigarettes is visible on a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>15621</td>\n",
       "      <td>VizWiz_train_00015621.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>a person's hand is covering a bottle of bubble...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A hand is holding a bottle labeled \"moonlight ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The object is a plastic bottle of bubble bath ...</td>\n",
       "      <td>0</td>\n",
       "      <td>A hand with two gold rings is holding a rectan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>7225</td>\n",
       "      <td>VizWiz_train_00007225.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>A package of cigarettes resting on black leath...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A pack of Marlboro cigarettes with a red and w...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a pack of Marlboro cigarettes ...</td>\n",
       "      <td>1</td>\n",
       "      <td>A pack of Marlboro cigarettes is visible on a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>3429</td>\n",
       "      <td>VizWiz_train_00003429.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>A 2 liter bottle of Pepsi and someone's hand.\\...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A bottle of Pepsi with a red, white, and blue ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a dark brown glass bottle with...</td>\n",
       "      <td>1</td>\n",
       "      <td>A Pepsi bottle is partially visible on a woode...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>17399</td>\n",
       "      <td>VizWiz_train_00017399.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>A seasoned steak food product in white packagi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A packaging bag with visible text that reads \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image appears to be a close-up of a white ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The image shows a plastic bag containing a foo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id                  file_name                                         vizwiz_url                                     human_captions   blur  framing  rotation  blur_framing  blur_rotation  framing_rotation  blur_framing_rotation                                      gpt4o_caption  gpt4o_code                                      llama_caption  llama_code                                      molmo_caption  molmo_code\n",
       "437     16588  VizWiz_train_00016588.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...  House keys, medicine, and a package with the t...  False    False     False         False          False             False                  False  A pack of Pall Mall cigarettes with a green de...           1  The image depicts a green Pall Mall cigarette ...           1  A pack of Pall Mall cigarettes is visible on a...           1\n",
       "438     15621  VizWiz_train_00015621.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...  a person's hand is covering a bottle of bubble...  False    False     False         False          False             False                  False  A hand is holding a bottle labeled \"moonlight ...           1  The object is a plastic bottle of bubble bath ...           0  A hand with two gold rings is holding a rectan...           0\n",
       "439      7225  VizWiz_train_00007225.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...  A package of cigarettes resting on black leath...  False    False     False         False          False             False                  False  A pack of Marlboro cigarettes with a red and w...           1  The image shows a pack of Marlboro cigarettes ...           1  A pack of Marlboro cigarettes is visible on a ...           1\n",
       "440      3429  VizWiz_train_00003429.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...  A 2 liter bottle of Pepsi and someone's hand.\\...  False    False     False         False          False             False                  False  A bottle of Pepsi with a red, white, and blue ...           1  The image shows a dark brown glass bottle with...           1  A Pepsi bottle is partially visible on a woode...           1\n",
       "441     17399  VizWiz_train_00017399.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...  A seasoned steak food product in white packagi...  False    False     False         False          False             False                  False  A packaging bag with visible text that reads \"...           1  The image appears to be a close-up of a white ...           1  The image shows a plastic bag containing a foo...           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns_to_include = [\n",
    "    \"image_id\",\n",
    "    \"file_name\",\n",
    "    \"vizwiz_url\",\n",
    "    \"human_captions\",\n",
    "    \"unable_to_verify\",\n",
    "    \"double code notes\",\n",
    "    \"double verified\",\n",
    "    \"blur\",\n",
    "    \"framing\",\n",
    "    \"rotation\",\n",
    "    \"blur_framing\",\n",
    "    \"blur_rotation\",\n",
    "    \"framing_rotation\",\n",
    "    \"blur_framing_rotation\",\n",
    "    \"gpt4o_caption\",\n",
    "    \"gpt4o_code\",\n",
    "    \"llama_caption\",\n",
    "    \"llama_code\",\n",
    "    \"molmo_caption\",\n",
    "    \"molmo_code\",\n",
    "]\n",
    "\n",
    "# get only verified images and cases where models have a valid code\n",
    "regression_df = annotations_df[annotations_df[\"unable_to_verify\"] == \"\"]\n",
    "regression_df = regression_df[\n",
    "    (regression_df[\"gpt4o_code\"] != \"unsure\") & (regression_df[\"gpt4o_code\"] != \"\")\n",
    "]\n",
    "regression_df = regression_df[\n",
    "    (regression_df[\"llama_code\"] != \"unsure\") & (regression_df[\"llama_code\"] != \"\")\n",
    "]\n",
    "regression_df = regression_df[\n",
    "    (regression_df[\"molmo_code\"] != \"unsure\") & (regression_df[\"molmo_code\"] != \"\")\n",
    "]\n",
    "\n",
    "# combine yes and yes++\n",
    "regression_df.replace({\"yes++\": \"yes\"}, inplace=True)\n",
    "regression_df.replace({\"yes\": 1, \"no\": 0}, inplace=True)\n",
    "regression_df[\"gpt4o_code\"] = pd.to_numeric(regression_df[\"gpt4o_code\"])\n",
    "regression_df[\"llama_code\"] = pd.to_numeric(regression_df[\"llama_code\"])\n",
    "regression_df[\"molmo_code\"] = pd.to_numeric(regression_df[\"molmo_code\"])\n",
    "\n",
    "# filter columns\n",
    "regression_df = regression_df[columns_to_include]\n",
    "\n",
    "# cleanup\n",
    "del regression_df[\"unable_to_verify\"]\n",
    "del regression_df[\"double code notes\"]\n",
    "del regression_df[\"double verified\"]\n",
    "\n",
    "display(regression_df.head())\n",
    "regression_df.to_csv(\n",
    "    f\"./intermediate-data/regression-final-df_{len(regression_df)}-images.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create contingency tables for each image quality issue pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>blur</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>framing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>7.13</td>\n",
       "      <td>20.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>36.48</td>\n",
       "      <td>35.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "blur     False  True \n",
       "framing              \n",
       "False     7.13  20.74\n",
       "True     36.48  35.66"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\"\n",
    ")\n",
    "pd.crosstab(\n",
    "    regression_df[\"framing\"],\n",
    "    regression_df[\"blur\"],\n",
    "    normalize=True,\n",
    ").round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'obstruction'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/local-blurred-captioning-exploration-4LZKhcfn/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'obstruction'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[274]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mPercentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m )\n\u001b[32m      4\u001b[39m pd.crosstab(\n\u001b[32m      5\u001b[39m     regression_df[\u001b[33m\"\u001b[39m\u001b[33mframing\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43mregression_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mobstruction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m      7\u001b[39m     normalize=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      8\u001b[39m ).round(\u001b[32m4\u001b[39m) * \u001b[32m100\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/local-blurred-captioning-exploration-4LZKhcfn/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/local-blurred-captioning-exploration-4LZKhcfn/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'obstruction'"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\"\n",
    ")\n",
    "pd.crosstab(\n",
    "    regression_df[\"framing\"],\n",
    "    regression_df[\"obstruction\"],\n",
    "    normalize=True,\n",
    ").round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rotation</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>framing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>16.07</td>\n",
       "      <td>11.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>46.31</td>\n",
       "      <td>25.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rotation  False  True \n",
       "framing               \n",
       "False     16.07  11.80\n",
       "True      46.31  25.82"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\"\n",
    ")\n",
    "pd.crosstab(\n",
    "    regression_df[\"framing\"],\n",
    "    regression_df[\"rotation\"],\n",
    "    normalize=True,\n",
    ").round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'obstruction'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/local-blurred-captioning-exploration-4LZKhcfn/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'obstruction'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[276]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mPercentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m )\n\u001b[32m      4\u001b[39m pd.crosstab(\n\u001b[32m      5\u001b[39m     regression_df[\u001b[33m\"\u001b[39m\u001b[33mblur\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43mregression_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mobstruction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m      7\u001b[39m     normalize=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      8\u001b[39m ).round(\u001b[32m4\u001b[39m) * \u001b[32m100\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/local-blurred-captioning-exploration-4LZKhcfn/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/local-blurred-captioning-exploration-4LZKhcfn/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'obstruction'"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\"\n",
    ")\n",
    "pd.crosstab(\n",
    "    regression_df[\"blur\"],\n",
    "    regression_df[\"obstruction\"],\n",
    "    normalize=True,\n",
    ").round(4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rotation</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blur</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.13</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.39</td>\n",
       "      <td>7.62</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.46</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.23</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.61</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.11</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.98</td>\n",
       "      <td>3.36</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.52</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rotation      0     1     2     3     4     5\n",
       "blur                                         \n",
       "0         12.13  2.13  2.38  1.39  7.62  2.70\n",
       "1          7.46  1.07  0.66  1.23  4.26  0.57\n",
       "2          3.61  0.66  0.57  0.25  2.95  0.74\n",
       "3          3.11  0.49  0.49  0.25  1.72  0.49\n",
       "4         15.98  3.36  1.64  1.72  1.23  0.66\n",
       "5          8.52  2.46  1.89  1.89  1.64  0.08"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    \"Percentage of images with framing and blur issues, by vote from crowdworker (divided by total number of images with framing or blur issues)\"\n",
    ")\n",
    "pd.crosstab(\n",
    "    regression_df[\"blur\"],\n",
    "    regression_df[\"rotation\"],\n",
    "    normalize=True,\n",
    ").round(4) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis 3: co-occurrence of image quality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>framing</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blur</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>7.13</td>\n",
       "      <td>36.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>20.74</td>\n",
       "      <td>35.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "framing  False  True \n",
       "blur                 \n",
       "False     7.13  36.48\n",
       "True     20.74  35.66"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occurrence_df = annotations_df[annotations_df[\"unable_to_verify\"] == \"\"]\n",
    "pd.crosstab(\n",
    "    co_occurrence_df[\"blur\"],\n",
    "    co_occurrence_df[\"framing\"],\n",
    "    normalize=True,\n",
    ").round(4) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BACKLOGGED -- Analysis 3: expert captions and sensitivity of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_metrics(dataset, metric):\n",
    "    \"\"\"\n",
    "    Computes average precision, recall, and f1 for BERTScore for each model.\n",
    "    \"\"\"\n",
    "    total_scores = {}\n",
    "    for image in dataset:\n",
    "        if metric == \"bertscore\":\n",
    "            curr_evaluation = image[\"evaluation\"][metric]\n",
    "            f1_name = \"f1\"\n",
    "        elif metric == \"cap_f1\":\n",
    "            curr_evaluation = image[\"evaluation\"][metric][\"scores\"]\n",
    "            f1_name = \"cap_f1\"\n",
    "\n",
    "        for model_name, scores in curr_evaluation.items():\n",
    "            if model_name in total_scores:\n",
    "                total_scores[model_name] = {\n",
    "                    \"total_count\": total_scores[model_name][\"total_count\"] + 1,\n",
    "                    \"total_precision\": total_scores[model_name][\"total_precision\"]\n",
    "                    + scores[\"precision\"],\n",
    "                    \"total_recall\": total_scores[model_name][\"total_recall\"]\n",
    "                    + scores[\"recall\"],\n",
    "                    \"total_f1\": total_scores[model_name][\"total_f1\"] + scores[f1_name],\n",
    "                }\n",
    "            else:\n",
    "                total_scores[model_name] = {\n",
    "                    \"total_count\": 1,\n",
    "                    \"total_precision\": scores[\"precision\"],\n",
    "                    \"total_recall\": scores[\"recall\"],\n",
    "                    \"total_f1\": scores[f1_name],\n",
    "                }\n",
    "\n",
    "    # compute averages and f1\n",
    "    output = {}\n",
    "    for model_name, values in total_scores.items():\n",
    "        output[model_name] = {\n",
    "            \"avg_precision\": values[\"total_precision\"] / float(values[\"total_count\"]),\n",
    "            \"avg_recall\": values[\"total_recall\"] / float(values[\"total_count\"]),\n",
    "            \"avg_f1\": values[\"total_f1\"] / float(values[\"total_count\"]),\n",
    "        }\n",
    "        output[model_name][\"f1\"] = s.harmonic_mean(\n",
    "            [output[model_name][\"avg_precision\"], output[model_name][\"avg_recall\"]]\n",
    "        )\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can only merge Series or DataFrame objects, a <class 'list'> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# create an expert file to evaluate\u001b[39;00m\n\u001b[32m     23\u001b[39m expert_data_to_eval_df = pd.DataFrame.from_dict(evaluation_data_expert)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m expert_data_to_eval_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexpert_data_to_eval_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexpert_captioned_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvizwiz_url\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mright\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m expert_data_to_eval_df[\u001b[33m\"\u001b[39m\u001b[33mImage Preview\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     31\u001b[39m expert_data_to_eval_df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/local-blurred-captioning-exploration-4LZKhcfn/lib/python3.11/site-packages/pandas/core/reshape/merge.py:153\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mleft : DataFrame or named Series\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents=\u001b[32m0\u001b[39m)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmerge\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m     validate: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    151\u001b[39m ) -> DataFrame:\n\u001b[32m    152\u001b[39m     left_df = _validate_operand(left)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     right_df = \u001b[43m_validate_operand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m how == \u001b[33m\"\u001b[39m\u001b[33mcross\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[32m    156\u001b[39m             left_df,\n\u001b[32m    157\u001b[39m             right_df,\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/local-blurred-captioning-exploration-4LZKhcfn/lib/python3.11/site-packages/pandas/core/reshape/merge.py:2692\u001b[39m, in \u001b[36m_validate_operand\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m   2690\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.to_frame()\n\u001b[32m   2691\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2692\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   2693\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCan only merge Series or DataFrame objects, a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m was passed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2694\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: Can only merge Series or DataFrame objects, a <class 'list'> was passed"
     ]
    }
   ],
   "source": [
    "# get only the data we need for the expert file\n",
    "target_keys = [\n",
    "    \"image_id\",\n",
    "    \"file_name\",\n",
    "    \"vizwiz_url\",\n",
    "    \"text_detected\",\n",
    "    \"unrecognizable\",\n",
    "    \"framing\",\n",
    "    \"blur\",\n",
    "    \"obstruction\",\n",
    "    \"rotation\",\n",
    "    \"too dark\",\n",
    "    \"too bright\",\n",
    "    \"other\",\n",
    "    \"no issue\",\n",
    "]\n",
    "evaluation_data_expert = [\n",
    "    {x: y for x, y in image.items() if x in target_keys}\n",
    "    for image in evaluated_captions_data\n",
    "]\n",
    "\n",
    "# create an expert file to evaluate\n",
    "expert_data_to_eval_df = pd.DataFrame.from_dict(evaluation_data_expert)\n",
    "expert_data_to_eval_df = pd.merge(\n",
    "    expert_data_to_eval_df,\n",
    "    expert_captioned_data,\n",
    "    on=[\"file_name\", \"vizwiz_url\"],\n",
    "    how=\"right\",\n",
    ")\n",
    "del expert_data_to_eval_df[\"Image Preview\"]\n",
    "expert_data_to_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'expert_caption'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(expert_data_to_eval_dict):\n\u001b[32m     18\u001b[39m     matching_image = find_matching_image(image[\u001b[33m\"\u001b[39m\u001b[33mimage_id\u001b[39m\u001b[33m\"\u001b[39m], evaluated_captions_data)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     expert_caption = \u001b[43mimage\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexpert_caption\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     20\u001b[39m     captioning_challenge = image[\u001b[33m\"\u001b[39m\u001b[33mcaptioning_issue\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     21\u001b[39m     model_captions = matching_image[\u001b[33m\"\u001b[39m\u001b[33mmodel_captions\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mKeyError\u001b[39m: 'expert_caption'"
     ]
    }
   ],
   "source": [
    "# convert to a dict\n",
    "expert_data_to_eval_dict = expert_data_to_eval_df.to_dict(orient=\"records\")\n",
    "\n",
    "# sort dict by image_id\n",
    "expert_data_to_eval_dict = sorted(expert_data_to_eval_dict, key=lambda x: x[\"image_id\"])\n",
    "evaluated_captions_data = sorted(evaluated_captions_data, key=lambda x: x[\"image_id\"])\n",
    "\n",
    "\n",
    "def find_matching_image(image_id, data):\n",
    "    for image in data:\n",
    "        if image[\"image_id\"] == image_id:\n",
    "            return image\n",
    "    return None\n",
    "\n",
    "\n",
    "# add extra columns to the dict\n",
    "for index, image in enumerate(expert_data_to_eval_dict):\n",
    "    matching_image = find_matching_image(image[\"image_id\"], evaluated_captions_data)\n",
    "    expert_caption = image[\"expert_caption\"]\n",
    "    captioning_challenge = image[\"captioning_issue\"]\n",
    "    model_captions = matching_image[\"model_captions\"]\n",
    "\n",
    "    image[\"human_captions\"] = [\n",
    "        {\n",
    "            \"caption\": expert_caption.strip(),\n",
    "            \"captioning_issue\": captioning_challenge,\n",
    "        }\n",
    "    ]\n",
    "    image[\"model_captions\"] = model_captions\n",
    "    del image[\"expert_caption\"]\n",
    "    del image[\"captioning_issue\"]\n",
    "\n",
    "# save the dict\n",
    "with open(\n",
    "    f\"./intermediate-data/expert_data_{len(expert_data_to_eval_dict)}-images_{datetime.now().strftime('%Y-%m-%d_%H-%M')}.json\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    json.dump(expert_data_to_eval_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at subgroups for expert captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>image_preview</th>\n",
       "      <th>human_captions</th>\n",
       "      <th>annotator</th>\n",
       "      <th>notes</th>\n",
       "      <th>unable_to_verify</th>\n",
       "      <th>double code notes</th>\n",
       "      <th>double verified</th>\n",
       "      <th>gpt4o_caption</th>\n",
       "      <th>gpt4o_code</th>\n",
       "      <th>llama_caption</th>\n",
       "      <th>llama_code</th>\n",
       "      <th>molmo_caption</th>\n",
       "      <th>molmo_code</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>too bright</th>\n",
       "      <th>other</th>\n",
       "      <th>curved label</th>\n",
       "      <th>text panel</th>\n",
       "      <th>expert_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12066</td>\n",
       "      <td>VizWiz_train_00012066.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A Kroger grocery store tag for a caramel iced ...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>kroger iced carmel cake</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A caramel iced cake with a label featuring the...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a white label with the blue an...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a plastic container of apple c...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12884</td>\n",
       "      <td>VizWiz_train_00012884.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>The backside of a green plastic bottle with wo...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>nourishing shampoo</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>Green tube labeled \"Nourishing Shampoo\" with i...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a green tube with white text, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a green tube lying on its side...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8670</td>\n",
       "      <td>VizWiz_train_00008670.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A package of Kellogg's brand granola cereal wi...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>kellogg's low fat granola with raisens</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A box of Kelloggs Low Fat Granola with Raisin...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a box of Kellogg's Low Fat Gra...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a box of Kellogg's low-fat gra...</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13799</td>\n",
       "      <td>VizWiz_train_00013799.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A package for Macaroni and cheese on a kitchen...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>macaroni and cheese</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A food package with a label that includes part...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image appears to be a close-up of a person...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a box of Lipton iced tea. The ...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16729</td>\n",
       "      <td>VizWiz_train_00016729.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>the back of a Unilever brand product listing i...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>(Unilever) vasaline lotion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A bottle with a barcode and text showing ingre...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a white plastic bottle with a ...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a bottle of Vaseline lotion be...</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id                  file_name                                         vizwiz_url image_preview                                     human_captions   annotator                                   notes unable_to_verify double code notes double verified                                      gpt4o_caption gpt4o_code                                      llama_caption llama_code                                      molmo_caption molmo_code  text_detected  unrecognizable  framing  blur  obstruction  rotation  too dark  too bright  other curved label text panel expert_caption\n",
       "1      12066  VizWiz_train_00012066.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A Kroger grocery store tag for a caramel iced ...  Anne Marie                 kroger iced carmel cake                                                  x  A caramel iced cake with a label featuring the...        yes  The image shows a white label with the blue an...         no  The image shows a plastic container of apple c...         no           True               0        4     2            0         1         0           0      0                                       \n",
       "6      12884  VizWiz_train_00012884.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                The backside of a green plastic bottle with wo...  Anne Marie                      nourishing shampoo                                                  x  Green tube labeled \"Nourishing Shampoo\" with i...        yes  The image shows a green tube with white text, ...        yes  The image shows a green tube lying on its side...         no           True               0        1     0            0         4         0           0      0            x                          \n",
       "9       8670  VizWiz_train_00008670.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A package of Kellogg's brand granola cereal wi...  Anne Marie  kellogg's low fat granola with raisens                                                  x  A box of Kelloggs Low Fat Granola with Raisin...        yes  The image shows a box of Kellogg's Low Fat Gra...        yes  The image shows a box of Kellogg's low-fat gra...        yes           True               0        0     5            0         0         0           0      0                                       \n",
       "13     13799  VizWiz_train_00013799.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A package for Macaroni and cheese on a kitchen...  Anne Marie                     macaroni and cheese                                                  x  A food package with a label that includes part...         no  The image appears to be a close-up of a person...         no  The image shows a box of Lipton iced tea. The ...         no           True               0        4     5            1         1         0           1      0                                       \n",
       "17     16729  VizWiz_train_00016729.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                the back of a Unilever brand product listing i...  Anne Marie              (Unilever) vasaline lotion                                                  x  A bottle with a barcode and text showing ingre...         no  The image shows a white plastic bottle with a ...         no  The image shows a bottle of Vaseline lotion be...        yes           True               0        4     0            0         0         0           0      0                       x               "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_image_set = {x[\"image_id\"] for x in expert_captioned_data}\n",
    "expert_annotations_df = annotations_df[\n",
    "    (annotations_df[\"image_id\"].isin(expert_image_set))\n",
    "    & (annotations_df[\"unable_to_verify\"] == \"\")\n",
    "]\n",
    "print(len(expert_annotations_df))\n",
    "expert_annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Performance for bertscore ---\n",
      "gpt4o -- correct count = 185; incorrect count = 83\n",
      "[13799, 16729, 6341, 1646, 763, 5711, 4629, 5368, 14683, 15302, 18234, 20318, 13687, 11856, 2030, 2002, 15338, 1471, 16393, 16060, 944, 1950, 10733, 7498, 19322, 23160, 10504, 19212, 11989, 12265, 7632, 5209, 18833, 981, 7902, 6048, 12113, 20178, 6719, 8055, 5656, 14146, 16379, 3462, 21997, 10689, 13355, 15949, 9159, 13702, 2390, 14578, 11510, 9584, 18225, 4356, 20540, 143, 4474, 7866, 16052, 19303, 14975, 16007, 9718, 13286, 16479, 15240, 17913, 2015, 9831, 2294, 860, 10709, 21209, 3380, 3552, 3737, 6693, 3493, 2235, 17557, 5029]\n",
      "Performance Correct -- Avg Precision: 0.7629, Avg Recall: 0.6906\n",
      "Performance incorrect -- Avg Precision: 0.7449, Avg Recall: 0.6653\n",
      "\n",
      "llama -- correct count = 117; incorrect count = 151\n",
      "[12066, 13799, 16729, 6341, 1646, 763, 5711, 4629, 22396, 5368, 14683, 14321, 15302, 18234, 20318, 14833, 13687, 11856, 2030, 4191, 327, 5824, 7367, 15338, 1471, 1386, 16393, 15008, 9431, 16830, 16060, 944, 16570, 1404, 7185, 1950, 13189, 661, 17565, 3598, 17994, 19585, 20014, 11256, 10733, 21099, 10251, 15289, 8072, 5347, 1573, 7498, 10504, 19212, 3535, 18203, 4928, 7605, 13729, 10973, 12265, 10130, 7632, 5209, 18833, 981, 14116, 7902, 637, 16411, 2597, 16469, 12113, 2968, 14416, 20178, 6719, 20018, 9682, 14577, 8055, 5656, 9070, 14146, 16379, 20892, 17455, 10633, 3462, 21997, 10689, 13355, 1353, 15949, 9159, 11625, 11675, 13702, 2390, 20056, 14578, 14044, 11510, 9584, 18225, 4356, 20540, 6810, 143, 18152, 4474, 8760, 7473, 7866, 19486, 7285, 16052, 13070, 19303, 14975, 16007, 9718, 13286, 16479, 17585, 15240, 2015, 9831, 19761, 2294, 5941, 860, 21209, 13437, 2970, 189, 16316, 2948, 22131, 3380, 10309, 3552, 3737, 6693, 3493, 12650, 259, 2235, 422, 5029, 9975]\n",
      "Performance Correct -- Avg Precision: 0.6996, Avg Recall: 0.6588\n",
      "Performance incorrect -- Avg Precision: 0.6893, Avg Recall: 0.6522\n",
      "\n",
      "molmo -- correct count = 96; incorrect count = 172\n",
      "[12066, 12884, 13799, 6341, 1646, 763, 5711, 4629, 22396, 5368, 22462, 14683, 14321, 15302, 18234, 20318, 14833, 10570, 13687, 2030, 4191, 327, 5824, 7367, 15338, 5918, 7908, 1471, 903, 19515, 6910, 16393, 15008, 9431, 16830, 16060, 944, 13665, 16570, 1404, 1950, 5659, 11878, 13189, 661, 136, 17565, 19585, 2259, 11256, 7880, 14584, 13641, 15492, 21099, 8578, 10251, 15289, 8072, 5347, 1573, 16613, 7498, 23160, 10504, 19212, 3535, 17422, 18203, 4928, 11989, 7605, 14803, 13729, 10973, 14074, 7632, 5209, 981, 14116, 8263, 7902, 8078, 16411, 2597, 8833, 16469, 12113, 8836, 9046, 14416, 19604, 20178, 6719, 20018, 9682, 2350, 14577, 8055, 5656, 9070, 16379, 18471, 5781, 3462, 21997, 10689, 10336, 13355, 1353, 589, 7634, 4790, 9159, 11675, 13702, 2390, 20056, 6272, 14578, 2774, 14044, 11510, 9584, 4356, 20540, 143, 18152, 9299, 4474, 7473, 7866, 19486, 7285, 16052, 13070, 20818, 19303, 14975, 2004, 9718, 16479, 17585, 15240, 2015, 9831, 19761, 2294, 860, 10709, 21209, 13437, 2970, 189, 16316, 2948, 17782, 3324, 3380, 10309, 3552, 3737, 6693, 13313, 12827, 3493, 7032, 12650, 259, 422, 5029, 14006]\n",
      "Performance Correct -- Avg Precision: 0.7486, Avg Recall: 0.6707\n",
      "Performance incorrect -- Avg Precision: 0.7197, Avg Recall: 0.6403\n",
      "\n",
      "--- Performance for cap_f1 ---\n",
      "gpt4o -- correct count = 185; incorrect count = 83\n",
      "[13799, 16729, 6341, 1646, 763, 5711, 4629, 5368, 14683, 15302, 18234, 20318, 13687, 11856, 2030, 2002, 15338, 1471, 16393, 16060, 944, 1950, 10733, 7498, 19322, 23160, 10504, 19212, 11989, 12265, 7632, 5209, 18833, 981, 7902, 6048, 12113, 20178, 6719, 8055, 5656, 14146, 16379, 3462, 21997, 10689, 13355, 15949, 9159, 13702, 2390, 14578, 11510, 9584, 18225, 4356, 20540, 143, 4474, 7866, 16052, 19303, 14975, 16007, 9718, 13286, 16479, 15240, 17913, 2015, 9831, 2294, 860, 10709, 21209, 3380, 3552, 3737, 6693, 3493, 2235, 17557, 5029]\n",
      "Performance Correct -- Avg Precision: 0.7001, Avg Recall: 0.4607\n",
      "Performance incorrect -- Avg Precision: 0.7014, Avg Recall: 0.4455\n",
      "\n",
      "llama -- correct count = 117; incorrect count = 151\n",
      "[12066, 13799, 16729, 6341, 1646, 763, 5711, 4629, 22396, 5368, 14683, 14321, 15302, 18234, 20318, 14833, 13687, 11856, 2030, 4191, 327, 5824, 7367, 15338, 1471, 1386, 16393, 15008, 9431, 16830, 16060, 944, 16570, 1404, 7185, 1950, 13189, 661, 17565, 3598, 17994, 19585, 20014, 11256, 10733, 21099, 10251, 15289, 8072, 5347, 1573, 7498, 10504, 19212, 3535, 18203, 4928, 7605, 13729, 10973, 12265, 10130, 7632, 5209, 18833, 981, 14116, 7902, 637, 16411, 2597, 16469, 12113, 2968, 14416, 20178, 6719, 20018, 9682, 14577, 8055, 5656, 9070, 14146, 16379, 20892, 17455, 10633, 3462, 21997, 10689, 13355, 1353, 15949, 9159, 11625, 11675, 13702, 2390, 20056, 14578, 14044, 11510, 9584, 18225, 4356, 20540, 6810, 143, 18152, 4474, 8760, 7473, 7866, 19486, 7285, 16052, 13070, 19303, 14975, 16007, 9718, 13286, 16479, 17585, 15240, 2015, 9831, 19761, 2294, 5941, 860, 21209, 13437, 2970, 189, 16316, 2948, 22131, 3380, 10309, 3552, 3737, 6693, 3493, 12650, 259, 2235, 422, 5029, 9975]\n",
      "Performance Correct -- Avg Precision: 0.5080, Avg Recall: 0.3719\n",
      "Performance incorrect -- Avg Precision: 0.4579, Avg Recall: 0.3299\n",
      "\n",
      "molmo -- correct count = 96; incorrect count = 172\n",
      "[12066, 12884, 13799, 6341, 1646, 763, 5711, 4629, 22396, 5368, 22462, 14683, 14321, 15302, 18234, 20318, 14833, 10570, 13687, 2030, 4191, 327, 5824, 7367, 15338, 5918, 7908, 1471, 903, 19515, 6910, 16393, 15008, 9431, 16830, 16060, 944, 13665, 16570, 1404, 1950, 5659, 11878, 13189, 661, 136, 17565, 19585, 2259, 11256, 7880, 14584, 13641, 15492, 21099, 8578, 10251, 15289, 8072, 5347, 1573, 16613, 7498, 23160, 10504, 19212, 3535, 17422, 18203, 4928, 11989, 7605, 14803, 13729, 10973, 14074, 7632, 5209, 981, 14116, 8263, 7902, 8078, 16411, 2597, 8833, 16469, 12113, 8836, 9046, 14416, 19604, 20178, 6719, 20018, 9682, 2350, 14577, 8055, 5656, 9070, 16379, 18471, 5781, 3462, 21997, 10689, 10336, 13355, 1353, 589, 7634, 4790, 9159, 11675, 13702, 2390, 20056, 6272, 14578, 2774, 14044, 11510, 9584, 4356, 20540, 143, 18152, 9299, 4474, 7473, 7866, 19486, 7285, 16052, 13070, 20818, 19303, 14975, 2004, 9718, 16479, 17585, 15240, 2015, 9831, 19761, 2294, 860, 10709, 21209, 13437, 2970, 189, 16316, 2948, 17782, 3324, 3380, 10309, 3552, 3737, 6693, 13313, 12827, 3493, 7032, 12650, 259, 422, 5029, 14006]\n",
      "Performance Correct -- Avg Precision: 0.5888, Avg Recall: 0.3622\n",
      "Performance incorrect -- Avg Precision: 0.4672, Avg Recall: 0.2610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# expert annotations\n",
    "for metric in [\"bertscore\", \"cap_f1\"]:\n",
    "    print(f\"--- Performance for {metric} ---\")\n",
    "    for model, model_short_name in MODEL_NAMES.items():\n",
    "        correct_predictions = expert_annotations_df[\n",
    "            expert_annotations_df[f\"{model_short_name}_code\"] != \"no\"\n",
    "        ]\n",
    "        ids_for_correct = list(correct_predictions[\"image_id\"])\n",
    "\n",
    "        incorrect_predictions = expert_annotations_df[\n",
    "            expert_annotations_df[f\"{model_short_name}_code\"] == \"no\"\n",
    "        ]\n",
    "        ids_for_incorrect = list(incorrect_predictions[\"image_id\"])\n",
    "        print(\n",
    "            f\"{model_short_name} -- correct count = {len(ids_for_correct)}; incorrect count = {len(ids_for_incorrect)}\"\n",
    "        )\n",
    "        print(ids_for_incorrect)\n",
    "\n",
    "        # filter expert captioned data\n",
    "        filted_expert_data_correct = [\n",
    "            x for x in expert_captioned_data if x[\"image_id\"] in ids_for_correct\n",
    "        ]\n",
    "        filted_expert_data_incorrect = [\n",
    "            x for x in expert_captioned_data if x[\"image_id\"] in ids_for_incorrect\n",
    "        ]\n",
    "\n",
    "        # print metrics\n",
    "        performance_correct = compute_average_metrics(\n",
    "            filted_expert_data_correct, metric\n",
    "        )[model]\n",
    "        performance_incorrect = compute_average_metrics(\n",
    "            filted_expert_data_incorrect, metric\n",
    "        )[model]\n",
    "\n",
    "        # print\n",
    "        print(\n",
    "            f\"Performance Correct -- Avg Precision: {performance_correct['avg_precision']:.4f}, Avg Recall: {performance_correct['avg_recall']:.4f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Performance incorrect -- Avg Precision: {performance_incorrect['avg_precision']:.4f}, Avg Recall: {performance_incorrect['avg_recall']:.4f}\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>image_preview</th>\n",
       "      <th>human_captions</th>\n",
       "      <th>annotator</th>\n",
       "      <th>notes</th>\n",
       "      <th>unable_to_verify</th>\n",
       "      <th>double code notes</th>\n",
       "      <th>double verified</th>\n",
       "      <th>gpt4o_caption</th>\n",
       "      <th>gpt4o_code</th>\n",
       "      <th>llama_caption</th>\n",
       "      <th>llama_code</th>\n",
       "      <th>molmo_caption</th>\n",
       "      <th>molmo_code</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>too bright</th>\n",
       "      <th>other</th>\n",
       "      <th>curved label</th>\n",
       "      <th>text panel</th>\n",
       "      <th>expert_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12066</td>\n",
       "      <td>VizWiz_train_00012066.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A Kroger grocery store tag for a caramel iced ...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>kroger iced carmel cake</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A caramel iced cake with a label featuring the...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a white label with the blue an...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a plastic container of apple c...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12884</td>\n",
       "      <td>VizWiz_train_00012884.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>The backside of a green plastic bottle with wo...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>nourishing shampoo</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>Green tube labeled \"Nourishing Shampoo\" with i...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a green tube with white text, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a green tube lying on its side...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8670</td>\n",
       "      <td>VizWiz_train_00008670.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A package of Kellogg's brand granola cereal wi...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>kellogg's low fat granola with raisens</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A box of Kelloggs Low Fat Granola with Raisin...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a box of Kellogg's Low Fat Gra...</td>\n",
       "      <td>yes</td>\n",
       "      <td>The image shows a box of Kellogg's low-fat gra...</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13799</td>\n",
       "      <td>VizWiz_train_00013799.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>A package for Macaroni and cheese on a kitchen...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>macaroni and cheese</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A food package with a label that includes part...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image appears to be a close-up of a person...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a box of Lipton iced tea. The ...</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16729</td>\n",
       "      <td>VizWiz_train_00016729.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td></td>\n",
       "      <td>the back of a Unilever brand product listing i...</td>\n",
       "      <td>Anne Marie</td>\n",
       "      <td>(Unilever) vasaline lotion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>A bottle with a barcode and text showing ingre...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a white plastic bottle with a ...</td>\n",
       "      <td>no</td>\n",
       "      <td>The image shows a bottle of Vaseline lotion be...</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id                  file_name                                         vizwiz_url image_preview                                     human_captions   annotator                                   notes unable_to_verify double code notes double verified                                      gpt4o_caption gpt4o_code                                      llama_caption llama_code                                      molmo_caption molmo_code  text_detected  unrecognizable  framing  blur  obstruction  rotation  too dark  too bright  other curved label text panel expert_caption\n",
       "1      12066  VizWiz_train_00012066.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A Kroger grocery store tag for a caramel iced ...  Anne Marie                 kroger iced carmel cake                                                  x  A caramel iced cake with a label featuring the...        yes  The image shows a white label with the blue an...         no  The image shows a plastic container of apple c...         no           True               0        4     2            0         1         0           0      0                                       \n",
       "6      12884  VizWiz_train_00012884.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                The backside of a green plastic bottle with wo...  Anne Marie                      nourishing shampoo                                                  x  Green tube labeled \"Nourishing Shampoo\" with i...        yes  The image shows a green tube with white text, ...        yes  The image shows a green tube lying on its side...         no           True               0        1     0            0         4         0           0      0            x                          \n",
       "9       8670  VizWiz_train_00008670.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A package of Kellogg's brand granola cereal wi...  Anne Marie  kellogg's low fat granola with raisens                                                  x  A box of Kelloggs Low Fat Granola with Raisin...        yes  The image shows a box of Kellogg's Low Fat Gra...        yes  The image shows a box of Kellogg's low-fat gra...        yes           True               0        0     5            0         0         0           0      0                                       \n",
       "13     13799  VizWiz_train_00013799.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                A package for Macaroni and cheese on a kitchen...  Anne Marie                     macaroni and cheese                                                  x  A food package with a label that includes part...         no  The image appears to be a close-up of a person...         no  The image shows a box of Lipton iced tea. The ...         no           True               0        4     5            1         1         0           1      0                                       \n",
       "17     16729  VizWiz_train_00016729.jpg  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...                the back of a Unilever brand product listing i...  Anne Marie              (Unilever) vasaline lotion                                                  x  A bottle with a barcode and text showing ingre...         no  The image shows a white plastic bottle with a ...         no  The image shows a bottle of Vaseline lotion be...        yes           True               0        4     0            0         0         0           0      0                       x               "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on the same dataset, look at crowdworker annotations\n",
    "crowdworker_annotations_df = annotations_df[\n",
    "    (annotations_df[\"image_id\"].isin(expert_image_set))\n",
    "    & (annotations_df[\"unable_to_verify\"] == \"\")\n",
    "]\n",
    "print(len(crowdworker_annotations_df))\n",
    "crowdworker_annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Performance for bertscore ---\n",
      "gpt4o -- correct count = 185 (69%); incorrect count = 83 (31%)\n",
      "Performance Correct -- Avg Precision: 0.6398, Avg Recall: 0.7958\n",
      "Performance incorrect -- Avg Precision: 0.6377, Avg Recall: 0.7692\n",
      "\n",
      "llama -- correct count = 117 (44%); incorrect count = 151 (56%)\n",
      "Performance Correct -- Avg Precision: 0.5921, Avg Recall: 0.7603\n",
      "Performance incorrect -- Avg Precision: 0.5946, Avg Recall: 0.7402\n",
      "\n",
      "molmo -- correct count = 96 (36%); incorrect count = 172 (64%)\n",
      "Performance Correct -- Avg Precision: 0.6638, Avg Recall: 0.8006\n",
      "Performance incorrect -- Avg Precision: 0.6448, Avg Recall: 0.7676\n",
      "\n",
      "--- Performance for cap_f1 ---\n",
      "gpt4o -- correct count = 185 (69%); incorrect count = 83 (31%)\n",
      "Performance Correct -- Avg Precision: 0.5186, Avg Recall: 0.4206\n",
      "Performance incorrect -- Avg Precision: 0.5018, Avg Recall: 0.3407\n",
      "\n",
      "llama -- correct count = 117 (44%); incorrect count = 151 (56%)\n",
      "Performance Correct -- Avg Precision: 0.4062, Avg Recall: 0.4000\n",
      "Performance incorrect -- Avg Precision: 0.3571, Avg Recall: 0.2903\n",
      "\n",
      "molmo -- correct count = 96 (36%); incorrect count = 172 (64%)\n",
      "Performance Correct -- Avg Precision: 0.5134, Avg Recall: 0.4085\n",
      "Performance incorrect -- Avg Precision: 0.4203, Avg Recall: 0.2765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for metric in [\"bertscore\", \"cap_f1\"]:\n",
    "    print(f\"--- Performance for {metric} ---\")\n",
    "    for model, model_short_name in MODEL_NAMES.items():\n",
    "        correct_predictions = crowdworker_annotations_df[\n",
    "            crowdworker_annotations_df[f\"{model_short_name}_code\"] != \"no\"\n",
    "        ]\n",
    "        ids_for_correct = list(correct_predictions[\"image_id\"])\n",
    "\n",
    "        incorrect_predictions = crowdworker_annotations_df[\n",
    "            crowdworker_annotations_df[f\"{model_short_name}_code\"] == \"no\"\n",
    "        ]\n",
    "        ids_for_incorrect = list(incorrect_predictions[\"image_id\"])\n",
    "        print(\n",
    "            f\"{model_short_name} -- correct count = {len(ids_for_correct)} ({100 * len(ids_for_correct) / len(crowdworker_annotations_df):.0f}%); incorrect count = {len(ids_for_incorrect)} ({100 * len(ids_for_incorrect) / len(crowdworker_annotations_df):.0f}%)\"\n",
    "        )\n",
    "        # print(ids_for_incorrect)\n",
    "\n",
    "        # filter crowdworker captioned data\n",
    "        filted_crowdworker_data_correct = [\n",
    "            x for x in evaluated_captions_data if x[\"image_id\"] in ids_for_correct\n",
    "        ]\n",
    "        filted_crowdworker_data_incorrect = [\n",
    "            x for x in evaluated_captions_data if x[\"image_id\"] in ids_for_incorrect\n",
    "        ]\n",
    "\n",
    "        # print metrics\n",
    "        performance_correct = compute_average_metrics(\n",
    "            filted_crowdworker_data_correct, metric\n",
    "        )[model]\n",
    "        performance_incorrect = compute_average_metrics(\n",
    "            filted_crowdworker_data_incorrect, metric\n",
    "        )[model]\n",
    "\n",
    "        # print\n",
    "        print(\n",
    "            f\"Performance Correct -- Avg Precision: {performance_correct['avg_precision']:.4f}, Avg Recall: {performance_correct['avg_recall']:.4f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Performance incorrect -- Avg Precision: {performance_incorrect['avg_precision']:.4f}, Avg Recall: {performance_incorrect['avg_recall']:.4f}\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-2024-08-06': 'gpt4o',\n",
       " 'Llama-3.2-11B-Vision-Instruct': 'llama',\n",
       " 'Molmo-7B-O-0924': 'molmo'}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=5432, minmax=(np.float64(0.3801501393318176), np.float64(0.90423983335495)), mean=np.float64(0.6410437088092139), variance=np.float64(0.00351636410091269), skewness=np.float64(0.13506593282533155), kurtosis=np.float64(0.38863508604686503))\n",
      "DescribeResult(nobs=5432, minmax=(np.float64(0.5880314707756042), np.float64(0.9440022110939026)), mean=np.float64(0.7789125641443065), variance=np.float64(0.002378888823964874), skewness=np.float64(-0.10485067445019737), kurtosis=np.float64(-0.09655775360738117))\n",
      "\n",
      "DescribeResult(nobs=5432, minmax=(np.float64(0.18891480565071106), np.float64(0.8394327163696289)), mean=np.float64(0.6055959118296981), variance=np.float64(0.0028518755754962633), skewness=np.float64(-0.05755974845593788), kurtosis=np.float64(0.9191530939957211))\n",
      "DescribeResult(nobs=5432, minmax=(np.float64(0.5791395902633667), np.float64(0.8977669477462769)), mean=np.float64(0.7485131648244318), variance=np.float64(0.002095130992444404), skewness=np.float64(-0.004731030420948404), kurtosis=np.float64(-0.03372707051547463))\n",
      "\n",
      "DescribeResult(nobs=5432, minmax=(np.float64(0.45671236515045166), np.float64(0.8330786824226379)), mean=np.float64(0.6515604777149143), variance=np.float64(0.002435263382471827), skewness=np.float64(-0.025090048556009187), kurtosis=np.float64(0.2756568894027298))\n",
      "DescribeResult(nobs=5432, minmax=(np.float64(0.5999084711074829), np.float64(0.9167557954788208)), mean=np.float64(0.7760883432666227), variance=np.float64(0.0021158568795428896), skewness=np.float64(-0.13117391244654), kurtosis=np.float64(-0.13425293690367512))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in MODEL_NAMES.keys():\n",
    "    bert_precisions = [\n",
    "        x[\"evaluation\"][\"bertscore\"][model][\"precision\"]\n",
    "        for x in evaluated_captions_data\n",
    "    ]\n",
    "    bert_recalls = [\n",
    "        x[\"evaluation\"][\"bertscore\"][model][\"recall\"] for x in evaluated_captions_data\n",
    "    ]\n",
    "    print(stats.describe(bert_precisions))\n",
    "    print(stats.describe(bert_recalls))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_NAMES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[43mMODEL_NAMES\u001b[49m.keys():\n\u001b[32m      2\u001b[39m     cap_f1_precisions = [\n\u001b[32m      3\u001b[39m         x[\u001b[33m\"\u001b[39m\u001b[33mevaluation\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcap_f1\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mscores\u001b[39m\u001b[33m\"\u001b[39m][model][\u001b[33m\"\u001b[39m\u001b[33mprecision\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      4\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m evaluated_captions_data\n\u001b[32m      5\u001b[39m     ]\n\u001b[32m      6\u001b[39m     cap_f1_recalls = [\n\u001b[32m      7\u001b[39m         x[\u001b[33m\"\u001b[39m\u001b[33mevaluation\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcap_f1\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mscores\u001b[39m\u001b[33m\"\u001b[39m][model][\u001b[33m\"\u001b[39m\u001b[33mrecall\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      8\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m evaluated_captions_data\n\u001b[32m      9\u001b[39m     ]\n",
      "\u001b[31mNameError\u001b[39m: name 'MODEL_NAMES' is not defined"
     ]
    }
   ],
   "source": [
    "for model in MODEL_NAMES.keys():\n",
    "    cap_f1_precisions = [\n",
    "        x[\"evaluation\"][\"cap_f1\"][\"scores\"][model][\"precision\"]\n",
    "        for x in evaluated_captions_data\n",
    "    ]\n",
    "    cap_f1_recalls = [\n",
    "        x[\"evaluation\"][\"cap_f1\"][\"scores\"][model][\"recall\"]\n",
    "        for x in evaluated_captions_data\n",
    "    ]\n",
    "    print(stats.describe(cap_f1_precisions))\n",
    "    print(stats.describe(cap_f1_recalls))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-blurred-captioning-exploration-4LZKhcfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
