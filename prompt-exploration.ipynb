{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Exploration for Image Captioning\n",
    "We explore different prompts and their impact on image captions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyter_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyter_black\n"
     ]
    }
   ],
   "source": [
    "%load_ext jupyter_black\n",
    "\n",
    "# Libraries\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# for showing image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Load Model\n",
    "For this experiment, all the same model will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# setup pytorch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # for multi-GPU systems, force single GPU\n",
    "if torch.cuda.is_available():\n",
    "    device_map = \"cuda:0\"  # force single, first GPU\n",
    "    device_type = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device_map = \"auto\"\n",
    "    device_type = \"mps\"\n",
    "else:\n",
    "    device_map = \"auto\"\n",
    "    device_type = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2dedc77ce644e89b613d3678622678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID:  allenai/Molmo-7B-O-0924\n",
      "Device:  cuda:0\n",
      "Dtype:  torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model_id = \"allenai/Molmo-7B-O-0924\"\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "# print model properties\n",
    "print(\"Model ID: \", model_id)\n",
    "print(\"Device: \", model.device)\n",
    "print(\"Dtype: \", model.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# captioning function\n",
    "def generate_caption(\n",
    "    image_object, model, processor, prompt, temperature=1.0, do_sample=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a caption for an image.\n",
    "\n",
    "    Inputs:\n",
    "    - image_object (pil Image): image to caption.\n",
    "    - model (torch model): loaded model to use for captioning.\n",
    "    - processor (torch processor): loaded processor for pre-processing inputs.\n",
    "    - temperature (float; optional): temperature setting for model, greater than 0. Defaults to 1.0; lower values are more deterministic.\n",
    "    - do_sample (boolean; optional): whether model should sample probabilities. Defaults to False -- greedy decoding.\n",
    "\n",
    "    Output:\n",
    "    - (str): caption for image.\n",
    "    \"\"\"\n",
    "    # process the image and text\n",
    "    inputs = processor.process(\n",
    "        images=[image_object],\n",
    "        text=prompt,\n",
    "    )\n",
    "\n",
    "    # move inputs to the correct device and make a batch of size 1\n",
    "    inputs = {k: v.to(model.device).unsqueeze(0) for k, v in inputs.items()}\n",
    "\n",
    "    # generate output; maximum 200 new tokens; stop generation when <|endoftext|> is generated\n",
    "    output = \"\"\n",
    "    with torch.autocast(device_type=device_type, enabled=True, dtype=torch.bfloat16):\n",
    "        output = model.generate_from_batch(\n",
    "            inputs,\n",
    "            GenerationConfig(max_new_tokens=200, stop_strings=\"<|endoftext|>\"),\n",
    "            tokenizer=processor.tokenizer,\n",
    "            use_cache=False,\n",
    "            temperature=temperature,\n",
    "            do_sample=do_sample,\n",
    "        )\n",
    "\n",
    "        # only get generated tokens; decode them to text\n",
    "        generated_tokens = output[0, inputs[\"input_ids\"].size(1) :]\n",
    "        generated_text = processor.tokenizer.decode(\n",
    "            generated_tokens, skip_special_tokens=True\n",
    "        )\n",
    "        output = generated_text.strip()\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def generate_target_dataset(caption_dataset_filename, image_quality_dataset_filename):\n",
    "    \"\"\"\n",
    "    Generates a target dataset for captioning based on VizWiz's image captioning dataset and image quality assessment dataset.\n",
    "\n",
    "    Inputs:\n",
    "    - caption_dataset_filename (str): path to caption dataset.\n",
    "    - image_quality_dataset_filename (str): path to image quality dataset.\n",
    "\n",
    "    Output:\n",
    "    - (pd.DataFrame): dataframe containing image annotations and image quality.\n",
    "    \"\"\"\n",
    "    # get images and annotations in one dataframe\n",
    "    image_annotation_df = None\n",
    "    with open(caption_dataset_filename) as f:\n",
    "        # load caption dataset\n",
    "        caption_dataset_json = json.load(f)\n",
    "\n",
    "        # combine image files and annotations\n",
    "        images_df = pd.DataFrame.from_dict(caption_dataset_json[\"images\"])\n",
    "        annotations_df = pd.DataFrame.from_dict(caption_dataset_json[\"annotations\"])\n",
    "        grouped_annotations = (\n",
    "            annotations_df.groupby([\"image_id\"]).agg(tuple).map(list).reset_index()\n",
    "        )\n",
    "        image_annotation_df = images_df.merge(\n",
    "            grouped_annotations[[\"image_id\", \"caption\", \"is_precanned\", \"is_rejected\"]],\n",
    "            left_on=\"id\",\n",
    "            right_on=\"image_id\",\n",
    "        )\n",
    "\n",
    "        # vizwiz_url is broken, so fix with https://vizwiz.cs.colorado.edu/*\n",
    "        image_annotation_df[\"vizwiz_url\"] = image_annotation_df[\"vizwiz_url\"].apply(\n",
    "            lambda x: x.replace(\n",
    "                \"https://ivc.ischool.utexas.edu/\", \"https://vizwiz.cs.colorado.edu/\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # get image quality\n",
    "    with open(image_quality_dataset_filename) as f:\n",
    "        # load image quality annotation dataset\n",
    "        image_quality_dataset_json = json.load(f)\n",
    "        image_quality_df = pd.DataFrame.from_dict(image_quality_dataset_json)\n",
    "\n",
    "        # expand object of flaws into individual columns and rename\n",
    "        image_quality_df = pd.concat(\n",
    "            [\n",
    "                image_quality_df.drop([\"flaws\"], axis=1),\n",
    "                pd.json_normalize(image_quality_df[\"flaws\"]),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        image_quality_df.rename(\n",
    "            columns={\n",
    "                \"FRM\": \"framing\",\n",
    "                \"BLR\": \"blur\",\n",
    "                \"DRK\": \"too dark\",\n",
    "                \"BRT\": \"too bright\",\n",
    "                \"OBS\": \"obstruction\",\n",
    "                \"OTH\": \"other\",\n",
    "                \"NON\": \"no issue\",\n",
    "                \"ROT\": \"rotation\",\n",
    "                \"caption\": \"human_captions\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "    # combine image and quality datasets together\n",
    "    image_captioning_input = image_annotation_df.merge(\n",
    "        image_quality_df, left_on=\"file_name\", right_on=\"image\"\n",
    "    ).drop([\"image\"], axis=1)\n",
    "\n",
    "    # remove duplicate id column\n",
    "    image_captioning_input.drop([\"id\"], axis=1, inplace=True)\n",
    "\n",
    "    # reorder columns\n",
    "    image_captioning_input = image_captioning_input[\n",
    "        [\n",
    "            \"image_id\",\n",
    "            \"file_name\",\n",
    "            \"vizwiz_url\",\n",
    "            \"text_detected\",\n",
    "            \"unrecognizable\",\n",
    "            \"framing\",\n",
    "            \"blur\",\n",
    "            \"obstruction\",\n",
    "            \"rotation\",\n",
    "            \"too dark\",\n",
    "            \"too bright\",\n",
    "            \"other\",\n",
    "            \"no issue\",\n",
    "            \"caption\",\n",
    "            \"is_precanned\",\n",
    "            \"is_rejected\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # convert image_captioning_input to a list of dictionaries\n",
    "    image_captioning_input = image_captioning_input.to_dict(orient=\"records\")\n",
    "\n",
    "    # expand captions, is_precanned, and is_rejected into individual columns\n",
    "    for index, row in enumerate(image_captioning_input):\n",
    "        curr_captions = row[\"caption\"]\n",
    "        curr_precanned = row[\"is_precanned\"]\n",
    "        curr_rejected = row[\"is_rejected\"]\n",
    "\n",
    "        # expand captions\n",
    "        for caption_index in range(0, len(curr_captions)):\n",
    "            # expand caption\n",
    "            image_captioning_input[index][f\"human_caption_{caption_index + 1}\"] = (\n",
    "                curr_captions[caption_index]\n",
    "            )\n",
    "\n",
    "            # expand caption\n",
    "            image_captioning_input[index][f\"is_precanned_{caption_index + 1}\"] = (\n",
    "                curr_precanned[caption_index]\n",
    "            )\n",
    "\n",
    "            # expand caption\n",
    "            image_captioning_input[index][f\"is_rejected_{caption_index + 1}\"] = (\n",
    "                curr_rejected[caption_index]\n",
    "            )\n",
    "\n",
    "        # remove old rows\n",
    "        del image_captioning_input[index][\"caption\"]\n",
    "        del image_captioning_input[index][\"is_precanned\"]\n",
    "        del image_captioning_input[index][\"is_rejected\"]\n",
    "\n",
    "    return image_captioning_input\n",
    "\n",
    "\n",
    "def generate_caption_output(\n",
    "    image_captioning_input, prompts, image_folder, scratch_path=\"\", use_scratch=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a caption for an image.\n",
    "\n",
    "    Inputs:\n",
    "    - image_captioning_input (pd.DataFrame): dataframe containing image annotations and image quality.\n",
    "    - prompts (list of tuples): prompts to try. each tuple includes (prompt_name, prompt).\n",
    "    - image_folder (str): path to image folder.\n",
    "    - scratch_path (str): path to scratch folder where intermediate files will be stored.\n",
    "    - use_scratch (bool): whether to save intermediate files\n",
    "\n",
    "    Output:\n",
    "    - (list): list of dictionaries containing image annotations and image quality.\n",
    "    \"\"\"\n",
    "    # deepclone input where labels will be\n",
    "    caption_output = copy.deepcopy(image_captioning_input)\n",
    "\n",
    "    # create scratch path if it doesn't exist\n",
    "    if use_scratch:\n",
    "        os.makedirs(scratch_path, exist_ok=True)\n",
    "\n",
    "    for index, row in enumerate(tqdm(image_captioning_input)):\n",
    "        # get image for current annotation\n",
    "        image_file = os.path.join(image_folder, caption_output[index][\"file_name\"])\n",
    "        image = Image.open(image_file)\n",
    "\n",
    "        # repeat per prompt\n",
    "        for prompt_name, prompt in prompts:\n",
    "            # generate caption and store for output\n",
    "            caption_output[index][f\"caption_for_prompt_{prompt_name}\"] = (\n",
    "                generate_caption(image, model, processor, prompt)\n",
    "            )\n",
    "\n",
    "        # save scratch file for every 100 images\n",
    "        if use_scratch:\n",
    "            if index % 100 == 0:\n",
    "                with open(\n",
    "                    os.path.join(scratch_path, f\"caption_output_{index}.json\"), \"w\"\n",
    "                ) as f:\n",
    "                    json.dump(caption_output, f, indent=4, separators=(\",\", \": \"))\n",
    "\n",
    "    return caption_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>...</th>\n",
       "      <th>is_rejected_2</th>\n",
       "      <th>human_caption_3</th>\n",
       "      <th>is_precanned_3</th>\n",
       "      <th>is_rejected_3</th>\n",
       "      <th>human_caption_4</th>\n",
       "      <th>is_precanned_4</th>\n",
       "      <th>is_rejected_4</th>\n",
       "      <th>human_caption_5</th>\n",
       "      <th>is_precanned_5</th>\n",
       "      <th>is_rejected_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>VizWiz_train_00000000.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Quality issues are too severe to recognize vis...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A bottle of spices in a plastic container layi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>some basil leaves in a container on a counter</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>VizWiz_train_00000001.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>A kitchen counter the various items on top inc...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>a black tin of Coca Cola placed on a black sur...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Black counter with canisters, kettle and can o...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>VizWiz_train_00000002.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>a can of crushed tomatoes in puree from price ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>a Price Chopper branded can of crushed tomatoes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Image is a can of crushed tomatoes in view.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VizWiz_train_00000003.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Screenshot from a smartphone with a case insen...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>image shows a screenshot of a page required ca...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A screenshot of Spotify page on a cell phone s...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>VizWiz_train_00000004.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>A garden book is sitting on a person's lap.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>a box for a solar garden light laying on someo...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A blue and yellow box with lights for the gard...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                  file_name  \\\n",
       "0         0  VizWiz_train_00000000.jpg   \n",
       "1         1  VizWiz_train_00000001.jpg   \n",
       "2         2  VizWiz_train_00000002.jpg   \n",
       "3         3  VizWiz_train_00000003.jpg   \n",
       "4         4  VizWiz_train_00000004.jpg   \n",
       "\n",
       "                                          vizwiz_url  text_detected  \\\n",
       "0  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "1  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "2  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "3  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "4  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "\n",
       "   unrecognizable  framing  blur  obstruction  rotation  too dark  ...  \\\n",
       "0               1        3     1            0         0         0  ...   \n",
       "1               0        0     5            0         0         0  ...   \n",
       "2               0        0     0            0         0         0  ...   \n",
       "3               0        0     0            0         0         0  ...   \n",
       "4               0        3     0            0         0         0  ...   \n",
       "\n",
       "   is_rejected_2                                    human_caption_3  \\\n",
       "0          False  Quality issues are too severe to recognize vis...   \n",
       "1          False  A kitchen counter the various items on top inc...   \n",
       "2          False  a can of crushed tomatoes in puree from price ...   \n",
       "3          False  Screenshot from a smartphone with a case insen...   \n",
       "4          False        A garden book is sitting on a person's lap.   \n",
       "\n",
       "   is_precanned_3 is_rejected_3  \\\n",
       "0            True          True   \n",
       "1           False         False   \n",
       "2           False         False   \n",
       "3           False         False   \n",
       "4           False         False   \n",
       "\n",
       "                                     human_caption_4  is_precanned_4  \\\n",
       "0  A bottle of spices in a plastic container layi...           False   \n",
       "1  a black tin of Coca Cola placed on a black sur...           False   \n",
       "2    a Price Chopper branded can of crushed tomatoes           False   \n",
       "3  image shows a screenshot of a page required ca...           False   \n",
       "4  a box for a solar garden light laying on someo...           False   \n",
       "\n",
       "  is_rejected_4                                    human_caption_5  \\\n",
       "0         False      some basil leaves in a container on a counter   \n",
       "1         False  Black counter with canisters, kettle and can o...   \n",
       "2         False        Image is a can of crushed tomatoes in view.   \n",
       "3         False  A screenshot of Spotify page on a cell phone s...   \n",
       "4         False  A blue and yellow box with lights for the gard...   \n",
       "\n",
       "   is_precanned_5 is_rejected_5  \n",
       "0           False         False  \n",
       "1           False         False  \n",
       "2           False         False  \n",
       "3           False         False  \n",
       "4           False         False  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_to_caption = generate_target_dataset(\n",
    "    \"./data/caption-dataset/annotations/train.json\",\n",
    "    \"./data/image-quality-assessment/annotations/train.json\",\n",
    ")\n",
    "dataset_to_caption_df = pd.DataFrame.from_dict(dataset_to_caption)\n",
    "dataset_to_caption_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset which images we want to\n",
    "There's no need to caption all the images with the set of prompts we want to try. Allow the user to select which images to try using `file_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_subset = [\n",
    "    \"VizWiz_train_00002685.jpg\",\n",
    "    \"VizWiz_train_00004360.jpg\",\n",
    "    \"VizWiz_train_00005236.jpg\",\n",
    "    \"VizWiz_train_00018277.jpg\",\n",
    "    \"VizWiz_train_00008241.jpg\",\n",
    "    \"VizWiz_train_00015593.jpg\",\n",
    "    \"VizWiz_train_00005191.jpg\",\n",
    "    \"VizWiz_train_00002033.jpg\",\n",
    "    \"VizWiz_train_00012474.jpg\",\n",
    "    \"VizWiz_train_00004571.jpg\",\n",
    "    \"VizWiz_train_00020191.jpg\",\n",
    "    \"VizWiz_train_00016717.jpg\",\n",
    "    \"VizWiz_train_00007812.jpg\",\n",
    "    \"VizWiz_train_00000428.jpg\",\n",
    "    \"VizWiz_train_00011077.jpg\",\n",
    "    \"VizWiz_train_00012338.jpg\",\n",
    "    \"VizWiz_train_00012570.jpg\",\n",
    "    \"VizWiz_train_00009241.jpg\",\n",
    "    \"VizWiz_train_00002353.jpg\",\n",
    "    \"VizWiz_train_00000575.jpg\",\n",
    "    \"VizWiz_train_00013633.jpg\",\n",
    "    \"VizWiz_train_00008078.jpg\",\n",
    "    \"VizWiz_train_00000140.jpg\",\n",
    "    \"VizWiz_train_00008867.jpg\",\n",
    "    \"VizWiz_train_00000078.jpg\",\n",
    "    \"VizWiz_train_00000192.jpg\",\n",
    "    \"VizWiz_train_00011842.jpg\",\n",
    "    \"VizWiz_train_00022167.jpg\",\n",
    "    \"VizWiz_train_00003433.jpg\",\n",
    "    \"VizWiz_train_00017296.jpg\",\n",
    "    \"VizWiz_train_00010915.jpg\",\n",
    "    \"VizWiz_train_00000145.jpg\",\n",
    "    \"VizWiz_train_00008162.jpg\",\n",
    "    \"VizWiz_train_00005952.jpg\",\n",
    "    \"VizWiz_train_00000139.jpg\",\n",
    "    \"VizWiz_train_00012215.jpg\",\n",
    "    \"VizWiz_train_00004920.jpg\",\n",
    "    \"VizWiz_train_00010826.jpg\",\n",
    "    \"VizWiz_train_00006570.jpg\",\n",
    "    \"VizWiz_train_00000070.jpg\",\n",
    "    \"VizWiz_train_00009603.jpg\",\n",
    "    \"VizWiz_train_00023166.jpg\",\n",
    "    \"VizWiz_train_00000621.jpg\",\n",
    "    \"VizWiz_train_00010902.jpg\",\n",
    "    \"VizWiz_train_00000131.jpg\",\n",
    "    \"VizWiz_train_00017219.jpg\",\n",
    "    \"VizWiz_train_00015043.jpg\",\n",
    "    \"VizWiz_train_00000051.jpg\",\n",
    "    \"VizWiz_train_00000149.jpg\",\n",
    "    \"VizWiz_train_00012203.jpg\",\n",
    "    \"VizWiz_train_00001485.jpg\",\n",
    "    \"VizWiz_train_00000142.jpg\",\n",
    "    \"VizWiz_train_00000126.jpg\",\n",
    "    \"VizWiz_train_00000155.jpg\",\n",
    "    \"VizWiz_train_00000558.jpg\",\n",
    "    \"VizWiz_train_00000560.jpg\",\n",
    "    \"VizWiz_train_00000637.jpg\",\n",
    "    \"VizWiz_train_00000506.jpg\",\n",
    "    \"VizWiz_train_00000193.jpg\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered_df = dataset_to_caption_df[\n",
    "    dataset_to_caption_df[\"file_name\"].isin(image_subset)\n",
    "]\n",
    "dataset_filtered = dataset_filtered_df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processor\n",
    "Below, we process all selected data across all prompts. Some constants across runs:\n",
    "1. `temperature = 1.0` which should balance determinism and randomness.\n",
    "2. `use_cache = False` to make sure new responses are always generated.\n",
    "3. `do_sample = False` to use greedy decoding to reduce sampling variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    # (\"plain\", \"What's in this image?\"),\n",
    "    # (\"plain-succinct\", \"What is in this image? Please provide a succinct description.\"),\n",
    "    # (\"blv-baseline\", \"Describe the image for blind and low-vision users.\"),\n",
    "    # (\n",
    "    #     \"original\",\n",
    "    #     \"\"\"You are a program designed to help blind and low-vision users understand images. Generate an accessible image description that includes key visual and contextual details of the image for blind and low-vision people. Focus on the following principles:\n",
    "    #     Clarity and Conciseness: Use simple, straightforward language to describe the main subjects and their relationships.;\n",
    "    #     Relevance: Highlight only essential visual elements that contribute to understanding the image or its purpose.;\n",
    "    #     Context: Provide contextual information when necessary, such as emotional tone, setting, or action. Avoid assumptions or subjective interpretations.;\n",
    "    #     Specificity: Include important details like colors, shapes, textures, or text visible in the image, if relevant. Avoid overly general terms or unnecessary details.\n",
    "    #     Once you generate your caption, shorten it to a succinct, single sentence. Output only the final sentence.\n",
    "    #     \"\"\",\n",
    "    # ),\n",
    "    # (\n",
    "    #     \"no-blv-ref\",\n",
    "    #     \"\"\"You are a program designed to help users understand images. Generate an image description that includes key visual and contextual details of the image. Focus on the following principles:\n",
    "    #     Clarity and Conciseness: Use simple, straightforward language to describe the main subjects and their relationships.;\n",
    "    #     Relevance: Highlight only essential visual elements that contribute to understanding the image or its purpose.;\n",
    "    #     Context: Provide contextual information when necessary, such as emotional tone, setting, or action. Avoid assumptions or subjective interpretations.;\n",
    "    #     Specificity: Include important details like colors, shapes, textures, or text visible in the image, if relevant. Avoid overly general terms or unnecessary details.\n",
    "    #     Once you generate your caption, shorten it to a succinct, single sentence. Output only the final sentence.\n",
    "    #     \"\"\",\n",
    "    # ),\n",
    "    # (\n",
    "    #     \"abstain\",\n",
    "    #     \"You are a helpful assistant for describing images for blind and low-vision individuals. Do not hallucinate with incorrect answers if the image is indescribable. An image is indescribable if the provided image is too blurry, too bright or dark, obstructed, or too ill-framed to recognize correctly. Abstain from providing descriptions if the question is unanswerable.\",\n",
    "    # ),\n",
    "    (\n",
    "        \"abstain-v2\",\n",
    "        \"\"\"You are a program designed to help users understand images. Generate an image description that includes key visual and contextual details of the image. Focus on the following principles:\n",
    "        Clarity and Conciseness: Use simple, straightforward language to describe the main subjects and their relationships.;\n",
    "        Relevance: Highlight only essential visual elements that contribute to understanding the image or its purpose.;\n",
    "        Context: Provide contextual information when necessary, such as emotional tone, setting, or action. Avoid assumptions or subjective interpretations.;\n",
    "        Specificity: Include important details like colors, shapes, textures, or text visible in the image, if relevant. Avoid overly general terms or unnecessary details.\n",
    "        Abstain: Do not hallucinate with incorrect answers if the image is too blurry, too bright or dark, obstructed, or too ill-framed to recognize correctly. Attempt to generate a caption before abstaining.\n",
    "        \n",
    "        Once you generate your caption, shorten it to a succinct, single sentence. Output only the final sentence.\n",
    "        \"\"\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11cd10418f0a482c91a9008413cd572e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "captions_per_prompt = generate_caption_output(\n",
    "    dataset_filtered, prompts, \"./data/caption-dataset/train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A blurry image shows a hand holding a cylindrical object with a barcode and text, likely in a grocery store setting.',\n",
       " 'A blurry, dark image shows a blue rectangle with \"Frequency Audio\" text, likely a screen or display in a dimly lit room.',\n",
       " 'A blurry image of a soda can on a white surface with a purple wall and brown door in the background.',\n",
       " 'A blurry image shows a finger partially obscuring a painting with blue, yellow, and white colors.',\n",
       " 'A blurry image shows a white bag with red text on a wooden surface, possibly a table or floor, with a red object in the background.',\n",
       " 'A blurry image shows a hand holding a jar of food, with a purple sleeve visible against a dark background.',\n",
       " 'A blurry image of a cereal box, likely Froot Loops, with a bowl of colorful cereal and milk in the bottom right corner.',\n",
       " 'A blurry image shows a bottle of medicine on a white surface, with a finger partially obscuring the view.',\n",
       " 'A blurry image of a Folgers coffee can on a wooden table, with a partially visible barcode and text.',\n",
       " 'A blurry image shows a cylindrical object with a black top and silver bottom, possibly a battery, in a red container with various tools.',\n",
       " 'A blurry, out-of-focus image shows a partially visible spherical object, likely a finger, against a dark background.',\n",
       " 'A blurry, dark image shows a CD with \"Estate\" written on it, featuring a white-haired man and a yellow-haired woman on the cover.',\n",
       " 'A blurry image shows a red menu on a white tablecloth with a floral pattern, likely in a restaurant setting.',\n",
       " 'A blurry image shows a hand holding a bottle of vitamin D3 supplements on a brown table, with other bottles and boxes visible in the background.',\n",
       " 'A blurry image of a grocery store shelf with various packaged meats and sausages.',\n",
       " 'A blurry image shows a hand holding a green box labeled \"Club\" with yellow text, surrounded by indistinct objects on a dark surface.',\n",
       " \"A blurry image shows a gold earring on a wooden surface, with a person's foot in a sandal visible on a patterned rug.\",\n",
       " 'A blurry image shows a red box on a black and white surface, possibly a countertop, with indistinct food items visible.',\n",
       " 'A hand holds a can of soup against a dark background, with a bright light illuminating the can and creating a contrast between the visible and obscured portions of the image.',\n",
       " 'A blurry image shows a person holding an orange juice box on a wooden table with scattered crumbs and a pen holder nearby.',\n",
       " 'A blurry kitchen scene with a white bag containing utensils and a purple vertical stripe on the left side.',\n",
       " 'A sideways image of a hand holding a bottle of Booster Lotion with a green label and peach color, taken outdoors in a residential area with mountains, clouds, and a white car visible.',\n",
       " 'A blurry image shows a hand holding a bottle of juice in a cluttered room with shelves and various items.',\n",
       " 'A blurry image of a white and red bottle labeled \"cleaner\" against a white background, with a hand icon and unreadable text.',\n",
       " 'A blurry close-up of a hand holding a partially visible candy bar with blue and white packaging against a dark background.',\n",
       " 'A blurry image of a juice bottle on a wooden table, with a red label and fruit illustrations.',\n",
       " 'A blurry image shows a red box with a yellow stripe, likely containing food, against a white background.',\n",
       " 'A blurry image of a hand holding a bottle of Clorox bleach cleaner against a white background.',\n",
       " 'A blurry image shows a can on a stove with a dirty background.',\n",
       " 'A sideways image of a desk with a notebook, Gatorade bottle, and computer monitor showing a DVD player interface.',\n",
       " 'A blurry, dark image shows a red package of butter cookies on a reflective surface, with the word \"butter\" visible in white text.',\n",
       " 'A blurry image shows a hand holding a can with a red label, surrounded by scattered objects on a brown floor.',\n",
       " \"A blurry image shows a person's legs and feet on a beige floor, with a can of Nestle juice and a white lid nearby.\",\n",
       " 'A blurry image shows a hand holding a can of Red Club brand fruit topping, with a silver object and bottles visible on a dark surface.',\n",
       " 'A blurry, dark image of a $2 bill on a brown surface, with the White House and \"America\" visible despite the poor quality.',\n",
       " 'A blurry close-up of a food package with \"pocket\" visible at the top, showing a ham and cheese sandwich on a red background.',\n",
       " 'A blurry, dark image with a purple background and a partially visible white logo with red text.',\n",
       " 'A blurry image of a food package on a white surface, with a partially visible silver object in the corner.',\n",
       " \"A blurry image of a Trader Joe's sparkling lemon mineral water bottle on a wooden table, with a white object in the background.\",\n",
       " 'A blurry image shows a wooden surface with a white card containing text about serving and experience.',\n",
       " \"A blurry image shows a person's hand wearing a beaded bracelet in a kitchen setting.\",\n",
       " 'A blurry image of a salt shaker with a green cap and yellow label, containing brown granules.',\n",
       " 'A blurry image shows a white bowl of brown food on a white surface, with a green and white can nearby.',\n",
       " 'A blurry, sideways image of a white wall with a red and blue object, possibly a fire extinguisher, in the foreground.',\n",
       " 'A blurry image shows a hand holding a can with a barcode and nutritional information, likely in a kitchen setting.',\n",
       " 'A blurry image shows a brown bottle on a tiled surface, with a white label containing unreadable text.',\n",
       " 'A blurry image shows a can of food on a white surface, with a black object partially visible on the right side.',\n",
       " 'A blurry image shows a red can on a wooden table with a white piece of paper nearby.',\n",
       " \"A blurry image of a Campbell's beef noodle soup can with a red background and white text, surrounded by indistinct food items.\",\n",
       " 'A blurry image shows a hand holding a box of Honey Bunches of Oats cereal, with a price tag visible.',\n",
       " 'A blurry image shows a hand holding a yellow box with \"vanilla\" written on it, possibly containing a dessert mix.',\n",
       " \"A blurry image shows a red and white can, likely Campbell's soup, with a blue banner and white text, partially obscured by a person's finger.\",\n",
       " \"A blurry image shows a person's leg in blue jeans, with a red and yellow object on a wooden surface, possibly a table.\",\n",
       " 'A blurry image shows a red box with white text, possibly a food product, on a reflective black surface.',\n",
       " 'A blurry image shows a bowl of cereal with a green background and partial text visible.',\n",
       " 'A blurry image of a red box of spaghetti on a wooden table, with text and a bowl of spaghetti visible.',\n",
       " 'A blurry image shows a hand holding a red box with white text, possibly containing candy, against a white wall background.',\n",
       " 'A blurry, overexposed image of a blue and white box against a dark background, with the word \"care\" visible in blue text.',\n",
       " 'A blurry image of a food package with a black background, white text, and a gold dragon logo.']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(captions_per_prompt)[\"caption_for_prompt_abstain-v2\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>...</th>\n",
       "      <th>is_rejected_4</th>\n",
       "      <th>human_caption_5</th>\n",
       "      <th>is_precanned_5</th>\n",
       "      <th>is_rejected_5</th>\n",
       "      <th>caption_for_prompt_plain</th>\n",
       "      <th>caption_for_prompt_plain-succinct</th>\n",
       "      <th>caption_for_prompt_blv-baseline</th>\n",
       "      <th>caption_for_prompt_original</th>\n",
       "      <th>caption_for_prompt_no-blv-ref</th>\n",
       "      <th>caption_for_prompt_abstain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>VizWiz_train_00000051.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>some sort of cream that someone is holding</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The image shows a close-up view of someone hol...</td>\n",
       "      <td>The image shows a close-up of a person's hand ...</td>\n",
       "      <td>The image shows a close-up view of a person's ...</td>\n",
       "      <td>A hand holds a cylindrical package with a barc...</td>\n",
       "      <td>A blurry image shows a hand holding a cylindri...</td>\n",
       "      <td>I apologize, but I cannot provide a descriptio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>VizWiz_train_00000070.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Quality issues are too severe to recognize vis...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>The image shows a digital display or sign with...</td>\n",
       "      <td>The image shows a blurry, dark scene with a bl...</td>\n",
       "      <td>The image shows a dark blue background with a ...</td>\n",
       "      <td>The image shows a blurry, dark scene with a bl...</td>\n",
       "      <td>The image shows a blurry, dark photograph of a...</td>\n",
       "      <td>I apologize, but I cannot provide a descriptio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>VizWiz_train_00000078.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Image contain a partial part of a mountain dew...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The image shows a close-up of an open can of M...</td>\n",
       "      <td>The image shows a close-up of an open can of M...</td>\n",
       "      <td>The image shows a close-up view of an open can...</td>\n",
       "      <td>A partially visible soda can with \"Mountain\" t...</td>\n",
       "      <td>A blurry image of a soda can on a white surfac...</td>\n",
       "      <td>I apologize, but I cannot provide a descriptio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>VizWiz_train_00000126.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>A orange on a gray cloth with the photographer...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The image shows a close-up view of a painting ...</td>\n",
       "      <td>The image shows a close-up view of a person's ...</td>\n",
       "      <td>The image shows a close-up view of a painting,...</td>\n",
       "      <td>A partially obscured image shows a person's fi...</td>\n",
       "      <td>A partially obscured image shows a person's fi...</td>\n",
       "      <td>I apologize, but I cannot provide a meaningful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131</td>\n",
       "      <td>VizWiz_train_00000131.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>some type of liquid that is in a container</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The image shows a blurry interior scene with a...</td>\n",
       "      <td>The image shows a blurry interior scene with a...</td>\n",
       "      <td>The image shows a blurry interior scene with a...</td>\n",
       "      <td>A blurry image shows a white bag with red text...</td>\n",
       "      <td>A blurry image shows a white bag with red text...</td>\n",
       "      <td>I apologize, but I cannot provide a descriptio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                  file_name  \\\n",
       "0        51  VizWiz_train_00000051.jpg   \n",
       "1        70  VizWiz_train_00000070.jpg   \n",
       "2        78  VizWiz_train_00000078.jpg   \n",
       "3       126  VizWiz_train_00000126.jpg   \n",
       "4       131  VizWiz_train_00000131.jpg   \n",
       "\n",
       "                                          vizwiz_url  text_detected  \\\n",
       "0  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "1  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "2  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "3  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...          False   \n",
       "4  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "\n",
       "   unrecognizable  framing  blur  obstruction  rotation  too dark  ...  \\\n",
       "0               2        2     3            0         0         0  ...   \n",
       "1               2        3     5            1         4         1  ...   \n",
       "2               0        4     5            0         0         0  ...   \n",
       "3               3        1     4            5         0         0  ...   \n",
       "4               1        2     5            0         0         0  ...   \n",
       "\n",
       "   is_rejected_4                                    human_caption_5  \\\n",
       "0          False         some sort of cream that someone is holding   \n",
       "1          False  Quality issues are too severe to recognize vis...   \n",
       "2          False  Image contain a partial part of a mountain dew...   \n",
       "3          False  A orange on a gray cloth with the photographer...   \n",
       "4          False         some type of liquid that is in a container   \n",
       "\n",
       "   is_precanned_5 is_rejected_5  \\\n",
       "0           False         False   \n",
       "1            True         False   \n",
       "2           False         False   \n",
       "3           False         False   \n",
       "4           False         False   \n",
       "\n",
       "                            caption_for_prompt_plain  \\\n",
       "0  The image shows a close-up view of someone hol...   \n",
       "1  The image shows a digital display or sign with...   \n",
       "2  The image shows a close-up of an open can of M...   \n",
       "3  The image shows a close-up view of a painting ...   \n",
       "4  The image shows a blurry interior scene with a...   \n",
       "\n",
       "                   caption_for_prompt_plain-succinct  \\\n",
       "0  The image shows a close-up of a person's hand ...   \n",
       "1  The image shows a blurry, dark scene with a bl...   \n",
       "2  The image shows a close-up of an open can of M...   \n",
       "3  The image shows a close-up view of a person's ...   \n",
       "4  The image shows a blurry interior scene with a...   \n",
       "\n",
       "                     caption_for_prompt_blv-baseline  \\\n",
       "0  The image shows a close-up view of a person's ...   \n",
       "1  The image shows a dark blue background with a ...   \n",
       "2  The image shows a close-up view of an open can...   \n",
       "3  The image shows a close-up view of a painting,...   \n",
       "4  The image shows a blurry interior scene with a...   \n",
       "\n",
       "                         caption_for_prompt_original  \\\n",
       "0  A hand holds a cylindrical package with a barc...   \n",
       "1  The image shows a blurry, dark scene with a bl...   \n",
       "2  A partially visible soda can with \"Mountain\" t...   \n",
       "3  A partially obscured image shows a person's fi...   \n",
       "4  A blurry image shows a white bag with red text...   \n",
       "\n",
       "                       caption_for_prompt_no-blv-ref  \\\n",
       "0  A blurry image shows a hand holding a cylindri...   \n",
       "1  The image shows a blurry, dark photograph of a...   \n",
       "2  A blurry image of a soda can on a white surfac...   \n",
       "3  A partially obscured image shows a person's fi...   \n",
       "4  A blurry image shows a white bag with red text...   \n",
       "\n",
       "                          caption_for_prompt_abstain  \n",
       "0  I apologize, but I cannot provide a descriptio...  \n",
       "1  I apologize, but I cannot provide a descriptio...  \n",
       "2  I apologize, but I cannot provide a descriptio...  \n",
       "3  I apologize, but I cannot provide a meaningful...  \n",
       "4  I apologize, but I cannot provide a descriptio...  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe\n",
    "output_df = pd.DataFrame.from_dict(captions_per_prompt)\n",
    "\n",
    "# save file\n",
    "outdir = \"./data/labeled-data/molmo-model/prompt-testing\"\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "output_df.to_csv(\n",
    "    f\"{outdir}/prompt-testing_03-21-25.csv\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "# print dataframe\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>...</th>\n",
       "      <th>is_rejected_2</th>\n",
       "      <th>human_caption_3</th>\n",
       "      <th>is_precanned_3</th>\n",
       "      <th>is_rejected_3</th>\n",
       "      <th>human_caption_4</th>\n",
       "      <th>is_precanned_4</th>\n",
       "      <th>is_rejected_4</th>\n",
       "      <th>human_caption_5</th>\n",
       "      <th>is_precanned_5</th>\n",
       "      <th>is_rejected_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>VizWiz_train_00000000.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Quality issues are too severe to recognize vis...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A bottle of spices in a plastic container layi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>some basil leaves in a container on a counter</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>VizWiz_train_00000001.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>A kitchen counter the various items on top inc...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>a black tin of Coca Cola placed on a black sur...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Black counter with canisters, kettle and can o...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>VizWiz_train_00000002.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>a can of crushed tomatoes in puree from price ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>a Price Chopper branded can of crushed tomatoes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Image is a can of crushed tomatoes in view.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VizWiz_train_00000003.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Screenshot from a smartphone with a case insen...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>image shows a screenshot of a page required ca...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A screenshot of Spotify page on a cell phone s...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>VizWiz_train_00000004.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>A garden book is sitting on a person's lap.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>a box for a solar garden light laying on someo...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A blue and yellow box with lights for the gard...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23426</th>\n",
       "      <td>23426</td>\n",
       "      <td>VizWiz_train_00023426.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>A case for the PlayStation two game Major Leag...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A video game of playing basketball sits on a p...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>PlayStation 2 game, MLB 2k7, sitting on someon...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23427</th>\n",
       "      <td>23427</td>\n",
       "      <td>VizWiz_train_00023427.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>A person may be standing behind a bar with bot...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The portrait section of a bill of paper money.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Quality issues are too severe to recognize vis...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23428</th>\n",
       "      <td>23428</td>\n",
       "      <td>VizWiz_train_00023428.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>a white box with the date may 02 2012 printed ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>corner of a white cardboard box with a black b...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A white box with black label with the date May...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23429</th>\n",
       "      <td>23429</td>\n",
       "      <td>VizWiz_train_00023429.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>A bottle of supplements are laying on a brown ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>White plastic bottle of healthy hair skin and ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>White bottle of Healthy Hair Skin and Nails su...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23430</th>\n",
       "      <td>23430</td>\n",
       "      <td>VizWiz_train_00023430.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>The back of a gift card without the silver str...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The back of a plastic money or credit card wit...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A gift card is on top of a table.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23431 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                  file_name  \\\n",
       "0             0  VizWiz_train_00000000.jpg   \n",
       "1             1  VizWiz_train_00000001.jpg   \n",
       "2             2  VizWiz_train_00000002.jpg   \n",
       "3             3  VizWiz_train_00000003.jpg   \n",
       "4             4  VizWiz_train_00000004.jpg   \n",
       "...         ...                        ...   \n",
       "23426     23426  VizWiz_train_00023426.jpg   \n",
       "23427     23427  VizWiz_train_00023427.jpg   \n",
       "23428     23428  VizWiz_train_00023428.jpg   \n",
       "23429     23429  VizWiz_train_00023429.jpg   \n",
       "23430     23430  VizWiz_train_00023430.jpg   \n",
       "\n",
       "                                              vizwiz_url  text_detected  \\\n",
       "0      https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "1      https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "2      https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "3      https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "4      https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "...                                                  ...            ...   \n",
       "23426  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "23427  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...          False   \n",
       "23428  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "23429  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "23430  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "\n",
       "       unrecognizable  framing  blur  obstruction  rotation  too dark  ...  \\\n",
       "0                   1        3     1            0         0         0  ...   \n",
       "1                   0        0     5            0         0         0  ...   \n",
       "2                   0        0     0            0         0         0  ...   \n",
       "3                   0        0     0            0         0         0  ...   \n",
       "4                   0        3     0            0         0         0  ...   \n",
       "...               ...      ...   ...          ...       ...       ...  ...   \n",
       "23426               0        0     1            0         0         0  ...   \n",
       "23427               2        4     5            0         0         0  ...   \n",
       "23428               0        4     0            0         1         1  ...   \n",
       "23429               0        0     0            0         0         0  ...   \n",
       "23430               0        1     0            0         1         0  ...   \n",
       "\n",
       "       is_rejected_2                                    human_caption_3  \\\n",
       "0              False  Quality issues are too severe to recognize vis...   \n",
       "1              False  A kitchen counter the various items on top inc...   \n",
       "2              False  a can of crushed tomatoes in puree from price ...   \n",
       "3              False  Screenshot from a smartphone with a case insen...   \n",
       "4              False        A garden book is sitting on a person's lap.   \n",
       "...              ...                                                ...   \n",
       "23426          False  A case for the PlayStation two game Major Leag...   \n",
       "23427          False  A person may be standing behind a bar with bot...   \n",
       "23428          False  a white box with the date may 02 2012 printed ...   \n",
       "23429          False  A bottle of supplements are laying on a brown ...   \n",
       "23430          False  The back of a gift card without the silver str...   \n",
       "\n",
       "       is_precanned_3 is_rejected_3  \\\n",
       "0                True          True   \n",
       "1               False         False   \n",
       "2               False         False   \n",
       "3               False         False   \n",
       "4               False         False   \n",
       "...               ...           ...   \n",
       "23426           False         False   \n",
       "23427           False         False   \n",
       "23428           False         False   \n",
       "23429           False         False   \n",
       "23430           False         False   \n",
       "\n",
       "                                         human_caption_4  is_precanned_4  \\\n",
       "0      A bottle of spices in a plastic container layi...           False   \n",
       "1      a black tin of Coca Cola placed on a black sur...           False   \n",
       "2        a Price Chopper branded can of crushed tomatoes           False   \n",
       "3      image shows a screenshot of a page required ca...           False   \n",
       "4      a box for a solar garden light laying on someo...           False   \n",
       "...                                                  ...             ...   \n",
       "23426  A video game of playing basketball sits on a p...           False   \n",
       "23427     The portrait section of a bill of paper money.           False   \n",
       "23428  corner of a white cardboard box with a black b...           False   \n",
       "23429  White plastic bottle of healthy hair skin and ...           False   \n",
       "23430  The back of a plastic money or credit card wit...           False   \n",
       "\n",
       "      is_rejected_4                                    human_caption_5  \\\n",
       "0             False      some basil leaves in a container on a counter   \n",
       "1             False  Black counter with canisters, kettle and can o...   \n",
       "2             False        Image is a can of crushed tomatoes in view.   \n",
       "3             False  A screenshot of Spotify page on a cell phone s...   \n",
       "4             False  A blue and yellow box with lights for the gard...   \n",
       "...             ...                                                ...   \n",
       "23426         False  PlayStation 2 game, MLB 2k7, sitting on someon...   \n",
       "23427         False  Quality issues are too severe to recognize vis...   \n",
       "23428         False  A white box with black label with the date May...   \n",
       "23429         False  White bottle of Healthy Hair Skin and Nails su...   \n",
       "23430         False                  A gift card is on top of a table.   \n",
       "\n",
       "       is_precanned_5 is_rejected_5  \n",
       "0               False         False  \n",
       "1               False         False  \n",
       "2               False         False  \n",
       "3               False         False  \n",
       "4               False         False  \n",
       "...               ...           ...  \n",
       "23426           False         False  \n",
       "23427            True         False  \n",
       "23428           False         False  \n",
       "23429           False         False  \n",
       "23430           False         False  \n",
       "\n",
       "[23431 rows x 28 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_to_caption_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
