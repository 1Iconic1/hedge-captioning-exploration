{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb22b5a-af25-406f-b102-dc33ec7a32bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import statistics as s\n",
    "from bert_score import score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61354ce8-f3ee-4e06-9049-7fe3efaa9b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_id': 1,\n",
       "  'file_name': 'VizWiz_train_00000001.jpg',\n",
       "  'vizwiz_url': 'https://vizwiz.cs.colorado.edu/VizWiz_visualization_img/VizWiz_train_00000001.jpg',\n",
       "  'text_detected': True,\n",
       "  'unrecognizable': 0,\n",
       "  'framing': 0,\n",
       "  'blur': 5,\n",
       "  'obstruction': 0,\n",
       "  'rotation': 0,\n",
       "  'too dark': 0,\n",
       "  'too bright': 0,\n",
       "  'other': 0,\n",
       "  'no issue': 0,\n",
       "  'human_captions': [{'caption': 'A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.',\n",
       "    'is_precanned': False,\n",
       "    'is_rejected': False},\n",
       "   {'caption': 'A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.',\n",
       "    'is_precanned': False,\n",
       "    'is_rejected': False},\n",
       "   {'caption': 'A kitchen counter the various items on top including a can of Coca-Cola, metal containers, and a teapot.',\n",
       "    'is_precanned': False,\n",
       "    'is_rejected': False},\n",
       "   {'caption': 'a black tin of Coca Cola placed on a black surface',\n",
       "    'is_precanned': False,\n",
       "    'is_rejected': False},\n",
       "   {'caption': 'Black counter with canisters, kettle and can of soda.',\n",
       "    'is_precanned': False,\n",
       "    'is_rejected': False}],\n",
       "  'model_captions': [{'model_name': 'gpt-4o-2024-08-06',\n",
       "    'caption': 'A can of Coca-Cola Zero is on a kitchen countertop, next to a white mug and a black kettle. Three silver canisters are aligned against the wall, along with a visible electrical outlet above them.'},\n",
       "   {'model_name': 'Llama-3.2-11B-Vision-Instruct',\n",
       "    'caption': 'The image shows a black can with a yellow band and red writing, likely a beverage can, on a kitchen counter. The can has a white label with indistinct writing.'},\n",
       "   {'model_name': 'Molmo-7B-O-0924',\n",
       "    'caption': 'A black and yellow can of Coca-Cola is prominently displayed on a black countertop. The can features the Coca-Cola logo in red and white text.'}]}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in combined caption data\n",
    "captioned_data = None\n",
    "filepath = \"../data/study-2-output/labeled-data/combined-caption-output/combined-caption-output_7304-images_2025-03-29_21:40:00.json\"\n",
    "with open(\n",
    "    filepath,\n",
    "    \"r\",\n",
    ") as f:\n",
    "    captioned_data = json.load(f)\n",
    "captioned_data[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73fb8d86-b712-4b5e-ad10-0f9772c455b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bertscore(dataset, model_type=\"microsoft/deberta-xlarge-mnli\", lang=\"en\"):\n",
    "    \"\"\"\n",
    "    Computes BERTScore for each model against human captions as reference.\n",
    "    Saves precision, recall, and f1 scores by reference to original input.\n",
    "    \"\"\"\n",
    "    for image in tqdm(dataset):\n",
    "        curr_references = [\n",
    "            caption[\"caption\"]\n",
    "            for caption in image[\"human_captions\"]\n",
    "            if caption[\"caption\"]\n",
    "            != \"Quality issues are too severe to recognize visual content.\"\n",
    "        ]\n",
    "        curr_output = {}\n",
    "        for model in image[\"model_captions\"]:\n",
    "            curr_model_name = model[\"model_name\"]\n",
    "\n",
    "            # compute scores for current model\n",
    "            curr_candidate = [model[\"caption\"]]\n",
    "            P, R, F1 = score(\n",
    "                curr_candidate, [curr_references], model_type=model_type, lang=lang\n",
    "            )\n",
    "            curr_output[curr_model_name] = {\n",
    "                \"scores\": {\n",
    "                    \"precision\": float(P[0]),\n",
    "                    \"recall\": float(R[0]),\n",
    "                    \"f1\": float(F1[0]),\n",
    "                }\n",
    "            }\n",
    "\n",
    "        # check if evaluation exists and save score\n",
    "        if \"evaluation\" not in image:\n",
    "            image[\"evaluation\"] = {}\n",
    "        image[\"evaluation\"][\"bertscore\"] = curr_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfbd19a1-3ad0-4a9c-b83a-f12d1882fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_metrics_bertscore(dataset):\n",
    "    \"\"\"\n",
    "    Computes average precision, recall, and f1 for BERTScore for each model.\n",
    "    \"\"\"\n",
    "    total_scores = {}\n",
    "    for image in tqdm(dataset):\n",
    "        curr_evaluation = image[\"evaluation\"][\"bertscore\"]\n",
    "        for model_name, scores in curr_evaluation.items():\n",
    "            scores = scores[\"scores\"]\n",
    "            if model_name in total_scores:\n",
    "                total_scores[model_name] = {\n",
    "                    \"total_count\": total_scores[model_name][\"total_count\"] + 1,\n",
    "                    \"total_precision\": total_scores[model_name][\"total_precision\"]\n",
    "                    + scores[\"precision\"],\n",
    "                    \"total_recall\": total_scores[model_name][\"total_recall\"]\n",
    "                    + scores[\"recall\"],\n",
    "                    \"total_f1\": total_scores[model_name][\"total_f1\"] + scores[\"f1\"],\n",
    "                }\n",
    "            else:\n",
    "                total_scores[model_name] = {\n",
    "                    \"total_count\": 1,\n",
    "                    \"total_precision\": scores[\"precision\"],\n",
    "                    \"total_recall\": scores[\"recall\"],\n",
    "                    \"total_f1\": scores[\"f1\"],\n",
    "                }\n",
    "\n",
    "    # compute averages and f1\n",
    "    output = {}\n",
    "    for model_name, values in total_scores.items():\n",
    "        output[model_name] = {\n",
    "            \"avg_precision\": values[\"total_precision\"] / float(values[\"total_count\"]),\n",
    "            \"avg_recall\": values[\"total_recall\"] / float(values[\"total_count\"]),\n",
    "            \"avg_f1\": values[\"total_f1\"] / float(values[\"total_count\"]),\n",
    "        }\n",
    "        output[model_name][\"f1\"] = s.harmonic_mean(\n",
    "            [output[model_name][\"avg_precision\"], output[model_name][\"avg_recall\"]]\n",
    "        )\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d4c6fc2-be8c-4559-a838-1827947e8cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eda6553f4c44e3dad1c344654054e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_bertscore(captioned_data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d2e568d-1bd9-432c-a7b6-081e68b9e7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc20375d6d14d9da7daa732a84bfb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"gpt-4o-2024-08-06\": {\n",
      "        \"avg_precision\": 0.6272800266742706,\n",
      "        \"avg_recall\": 0.780607956647873,\n",
      "        \"avg_f1\": 0.6917834937572479,\n",
      "        \"f1\": 0.6955947996839815\n",
      "    },\n",
      "    \"Llama-3.2-11B-Vision-Instruct\": {\n",
      "        \"avg_precision\": 0.6076797366142273,\n",
      "        \"avg_recall\": 0.760029011964798,\n",
      "        \"avg_f1\": 0.6693472445011139,\n",
      "        \"f1\": 0.6753692703797957\n",
      "    },\n",
      "    \"Molmo-7B-O-0924\": {\n",
      "        \"avg_precision\": 0.6660487532615662,\n",
      "        \"avg_recall\": 0.7902890324592591,\n",
      "        \"avg_f1\": 0.7159294486045837,\n",
      "        \"f1\": 0.7228694193706547\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(compute_average_metrics_bertscore(captioned_data[0:10]), indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-blurred-captioning-exploration-4LZKhcfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
