{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3cd039e-3207-4b4d-97c5-7981c59d6011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyter_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyter_black\n"
     ]
    }
   ],
   "source": [
    "%load_ext jupyter_black\n",
    "\n",
    "# Libraries\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from transformers import MllamaForConditionalGeneration, AutoProcessor, GenerationConfig\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19346e1-6a57-4a84-8676-bfd7c264a5e6",
   "metadata": {},
   "source": [
    "### Load Model\n",
    "For this experiment, all the same model will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9785eeb-6635-43c4-9afa-f56bbef410bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# setup pytorch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # for multi-GPU systems, force single GPU\n",
    "if torch.cuda.is_available():\n",
    "    device_map = \"cuda:0\"  # force single, first GPU\n",
    "    device_type = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device_map = \"auto\"\n",
    "    device_type = \"mps\"\n",
    "else:\n",
    "    device_map = \"auto\"\n",
    "    device_type = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9652e96f-9fbd-4d93-861b-aa574a08e108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377df9d8c8914584887b98049553d7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID:  meta-llama/Llama-3.2-11B-Vision-Instruct\n",
      "Device:  cuda:0\n",
      "Dtype:  torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n",
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# print model properties\n",
    "print(\"Model ID: \", model_id)\n",
    "print(\"Device: \", model.device)\n",
    "print(\"Dtype: \", model.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2d0d2-0e01-4515-910a-224479ad2c4b",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5ed0d97-2d70-4d68-bd7a-bdd2e1fa59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_target_dataset(caption_dataset_filename, image_quality_dataset_filename):\n",
    "    \"\"\"\n",
    "    Generates a target dataset for captioning based on VizWiz's image captioning dataset and image quality assessment dataset.\n",
    "\n",
    "    Inputs:\n",
    "    - caption_dataset_filename (str): path to caption dataset.\n",
    "    - image_quality_dataset_filename (str): path to image quality dataset.\n",
    "\n",
    "    Output:\n",
    "    - (pd.DataFrame): dataframe containing image annotations and image quality.\n",
    "    \"\"\"\n",
    "    # get images and annotations in one dataframe\n",
    "    image_annotation_df = None\n",
    "    with open(caption_dataset_filename) as f:\n",
    "        # load caption dataset\n",
    "        caption_dataset_json = json.load(f)\n",
    "\n",
    "        # combine image files and annotations\n",
    "        images_df = pd.DataFrame.from_dict(caption_dataset_json[\"images\"])\n",
    "        annotations_df = pd.DataFrame.from_dict(caption_dataset_json[\"annotations\"])\n",
    "        grouped_annotations = (\n",
    "            annotations_df.groupby([\"image_id\"]).agg(tuple).map(list).reset_index()\n",
    "        )\n",
    "        image_annotation_df = images_df.merge(\n",
    "            grouped_annotations[[\"image_id\", \"caption\", \"is_precanned\", \"is_rejected\"]],\n",
    "            left_on=\"id\",\n",
    "            right_on=\"image_id\",\n",
    "        )\n",
    "\n",
    "        # vizwiz_url is broken, so fix with https://vizwiz.cs.colorado.edu/*\n",
    "        image_annotation_df[\"vizwiz_url\"] = image_annotation_df[\"vizwiz_url\"].apply(\n",
    "            lambda x: x.replace(\n",
    "                \"https://ivc.ischool.utexas.edu/\", \"https://vizwiz.cs.colorado.edu/\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # get image quality\n",
    "    with open(image_quality_dataset_filename) as f:\n",
    "        # load image quality annotation dataset\n",
    "        image_quality_dataset_json = json.load(f)\n",
    "        image_quality_df = pd.DataFrame.from_dict(image_quality_dataset_json)\n",
    "\n",
    "        # expand object of flaws into individual columns and rename\n",
    "        image_quality_df = pd.concat(\n",
    "            [\n",
    "                image_quality_df.drop([\"flaws\"], axis=1),\n",
    "                pd.json_normalize(image_quality_df[\"flaws\"]),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        image_quality_df.rename(\n",
    "            columns={\n",
    "                \"FRM\": \"framing\",\n",
    "                \"BLR\": \"blur\",\n",
    "                \"DRK\": \"too dark\",\n",
    "                \"BRT\": \"too bright\",\n",
    "                \"OBS\": \"obstruction\",\n",
    "                \"OTH\": \"other\",\n",
    "                \"NON\": \"no issue\",\n",
    "                \"ROT\": \"rotation\",\n",
    "                \"caption\": \"human_captions\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "    # combine image and quality datasets together\n",
    "    image_captioning_input = image_annotation_df.merge(\n",
    "        image_quality_df, left_on=\"file_name\", right_on=\"image\"\n",
    "    ).drop([\"image\"], axis=1)\n",
    "\n",
    "    # remove duplicate id column\n",
    "    image_captioning_input.drop([\"id\"], axis=1, inplace=True)\n",
    "\n",
    "    # reorder columns\n",
    "    image_captioning_input = image_captioning_input[\n",
    "        [\n",
    "            \"image_id\",\n",
    "            \"file_name\",\n",
    "            \"vizwiz_url\",\n",
    "            \"text_detected\",\n",
    "            \"unrecognizable\",\n",
    "            \"framing\",\n",
    "            \"blur\",\n",
    "            \"obstruction\",\n",
    "            \"rotation\",\n",
    "            \"too dark\",\n",
    "            \"too bright\",\n",
    "            \"other\",\n",
    "            \"no issue\",\n",
    "            \"caption\",\n",
    "            \"is_precanned\",\n",
    "            \"is_rejected\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # convert image_captioning_input to a list of dictionaries\n",
    "    image_captioning_input = image_captioning_input.to_dict(orient=\"records\")\n",
    "\n",
    "    # expand captions, is_precanned, and is_rejected into individual columns\n",
    "    for index, row in enumerate(image_captioning_input):\n",
    "        curr_captions = row[\"caption\"]\n",
    "        curr_precanned = row[\"is_precanned\"]\n",
    "        curr_rejected = row[\"is_rejected\"]\n",
    "\n",
    "        # expand captions\n",
    "        for caption_index in range(0, len(curr_captions)):\n",
    "            # expand caption\n",
    "            image_captioning_input[index][f\"human_caption_{caption_index + 1}\"] = (\n",
    "                curr_captions[caption_index]\n",
    "            )\n",
    "\n",
    "            # expand caption\n",
    "            image_captioning_input[index][f\"is_precanned_{caption_index + 1}\"] = (\n",
    "                curr_precanned[caption_index]\n",
    "            )\n",
    "\n",
    "            # expand caption\n",
    "            image_captioning_input[index][f\"is_rejected_{caption_index + 1}\"] = (\n",
    "                curr_rejected[caption_index]\n",
    "            )\n",
    "\n",
    "        # remove old rows\n",
    "        del image_captioning_input[index][\"caption\"]\n",
    "        del image_captioning_input[index][\"is_precanned\"]\n",
    "        del image_captioning_input[index][\"is_rejected\"]\n",
    "\n",
    "    return image_captioning_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5732e19d-d526-484a-b7ae-2eac65830fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# captioning function\n",
    "def generate_caption(\n",
    "    image_object, model, processor, prompt, temperature=1.0, do_sample=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a caption for an image.\n",
    "\n",
    "    Inputs:\n",
    "    - image_object (pil Image): image to caption.\n",
    "    - model (torch model): loaded model to use for captioning.\n",
    "    - processor (torch processor): loaded processor for pre-processing inputs.\n",
    "    - temperature (float; optional): temperature setting for model, greater than 0. Defaults to 1.0; lower values are more deterministic.\n",
    "    - do_sample (boolean; optional): whether model should sample probabilities. Defaults to False -- greedy decoding.\n",
    "\n",
    "    Output:\n",
    "    - (str): caption for image.\n",
    "    \"\"\"\n",
    "    # process the image and text\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                prompt,\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(\n",
    "        image_object, input_text, add_special_tokens=False, return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    # generate output; maximum 300 new tokens; stop generation when <|endoftext|> is generated\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        generation_config=GenerationConfig(\n",
    "            max_new_tokens=300,\n",
    "            stop_strings=\"<|endoftext|>\",\n",
    "            use_cache=False,\n",
    "            temperature=temperature,\n",
    "            do_sample=do_sample,\n",
    "        ),\n",
    "        tokenizer=processor.tokenizer,\n",
    "    )\n",
    "\n",
    "    # only get generated tokens; decode them to text\n",
    "    generated_tokens = output[0, inputs[\"input_ids\"].size(1) :]\n",
    "    generated_text = processor.tokenizer.decode(\n",
    "        generated_tokens, skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    return generated_text.strip()\n",
    "\n",
    "\n",
    "def generate_caption_output(\n",
    "    image_captioning_input, prompt, image_folder, scratch_path=\"\", use_scratch=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a caption for an image.\n",
    "\n",
    "    Inputs:\n",
    "    - image_captioning_input (pd.DataFrame): dataframe containing image annotations and image quality.\n",
    "    - prompt (str): prompt to provide model.\n",
    "    - image_folder (str): path to image folder.\n",
    "    - scratch_path (str): path to scratch folder where intermediate files will be stored.\n",
    "    - use_scratch (bool): whether to save intermediate files\n",
    "\n",
    "    Output:\n",
    "    - (list): list of dictionaries containing image annotations and image quality.\n",
    "    \"\"\"\n",
    "    # deepclone input where labels will be\n",
    "    caption_output = copy.deepcopy(image_captioning_input)\n",
    "\n",
    "    # create scratch path if it doesn't exist\n",
    "    if use_scratch:\n",
    "        os.makedirs(scratch_path, exist_ok=True)\n",
    "\n",
    "    for index, row in enumerate(tqdm(image_captioning_input)):\n",
    "        # get image for current annotation\n",
    "        image_file = os.path.join(image_folder, caption_output[index][\"file_name\"])\n",
    "        image = Image.open(image_file)\n",
    "\n",
    "        # generate caption and store for output\n",
    "        caption_output[index][\"model_caption\"] = generate_caption(\n",
    "            image, model, processor, prompt\n",
    "        )\n",
    "\n",
    "        # save scratch file for every 100 images\n",
    "        if use_scratch:\n",
    "            if index % 100 == 0:\n",
    "                with open(\n",
    "                    os.path.join(scratch_path, f\"caption_output_{index}.json\"), \"w\"\n",
    "                ) as f:\n",
    "                    json.dump(caption_output, f, indent=4, separators=(\",\", \": \"))\n",
    "\n",
    "    return caption_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b4e6d-8034-4cab-ad22-bc9a829af383",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4521a326-4ac7-400a-98c4-d0af1bd33b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>...</th>\n",
       "      <th>is_rejected_2</th>\n",
       "      <th>human_caption_3</th>\n",
       "      <th>is_precanned_3</th>\n",
       "      <th>is_rejected_3</th>\n",
       "      <th>human_caption_4</th>\n",
       "      <th>is_precanned_4</th>\n",
       "      <th>is_rejected_4</th>\n",
       "      <th>human_caption_5</th>\n",
       "      <th>is_precanned_5</th>\n",
       "      <th>is_rejected_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>VizWiz_train_00000000.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Quality issues are too severe to recognize vis...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>A bottle of spices in a plastic container layi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>some basil leaves in a container on a counter</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>VizWiz_train_00000001.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>A kitchen counter the various items on top inc...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>a black tin of Coca Cola placed on a black sur...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Black counter with canisters, kettle and can o...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>VizWiz_train_00000002.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>a can of crushed tomatoes in puree from price ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>a Price Chopper branded can of crushed tomatoes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Image is a can of crushed tomatoes in view.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VizWiz_train_00000003.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Screenshot from a smartphone with a case insen...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>image shows a screenshot of a page required ca...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A screenshot of Spotify page on a cell phone s...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>VizWiz_train_00000004.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>A garden book is sitting on a person's lap.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>a box for a solar garden light laying on someo...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A blue and yellow box with lights for the gard...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                  file_name  \\\n",
       "0         0  VizWiz_train_00000000.jpg   \n",
       "1         1  VizWiz_train_00000001.jpg   \n",
       "2         2  VizWiz_train_00000002.jpg   \n",
       "3         3  VizWiz_train_00000003.jpg   \n",
       "4         4  VizWiz_train_00000004.jpg   \n",
       "\n",
       "                                          vizwiz_url  text_detected  \\\n",
       "0  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "1  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "2  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "3  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "4  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "\n",
       "   unrecognizable  framing  blur  obstruction  rotation  too dark  ...  \\\n",
       "0               1        3     1            0         0         0  ...   \n",
       "1               0        0     5            0         0         0  ...   \n",
       "2               0        0     0            0         0         0  ...   \n",
       "3               0        0     0            0         0         0  ...   \n",
       "4               0        3     0            0         0         0  ...   \n",
       "\n",
       "   is_rejected_2                                    human_caption_3  \\\n",
       "0          False  Quality issues are too severe to recognize vis...   \n",
       "1          False  A kitchen counter the various items on top inc...   \n",
       "2          False  a can of crushed tomatoes in puree from price ...   \n",
       "3          False  Screenshot from a smartphone with a case insen...   \n",
       "4          False        A garden book is sitting on a person's lap.   \n",
       "\n",
       "   is_precanned_3 is_rejected_3  \\\n",
       "0            True          True   \n",
       "1           False         False   \n",
       "2           False         False   \n",
       "3           False         False   \n",
       "4           False         False   \n",
       "\n",
       "                                     human_caption_4  is_precanned_4  \\\n",
       "0  A bottle of spices in a plastic container layi...           False   \n",
       "1  a black tin of Coca Cola placed on a black sur...           False   \n",
       "2    a Price Chopper branded can of crushed tomatoes           False   \n",
       "3  image shows a screenshot of a page required ca...           False   \n",
       "4  a box for a solar garden light laying on someo...           False   \n",
       "\n",
       "  is_rejected_4                                    human_caption_5  \\\n",
       "0         False      some basil leaves in a container on a counter   \n",
       "1         False  Black counter with canisters, kettle and can o...   \n",
       "2         False        Image is a can of crushed tomatoes in view.   \n",
       "3         False  A screenshot of Spotify page on a cell phone s...   \n",
       "4         False  A blue and yellow box with lights for the gard...   \n",
       "\n",
       "   is_precanned_5 is_rejected_5  \n",
       "0           False         False  \n",
       "1           False         False  \n",
       "2           False         False  \n",
       "3           False         False  \n",
       "4           False         False  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_captioning_input = generate_target_dataset(\n",
    "    \"../data/caption-dataset/annotations/train.json\",\n",
    "    \"../data/image-quality-assessment/annotations/train.json\",\n",
    ")\n",
    "image_captioning_input_df = pd.DataFrame.from_dict(dataset_to_caption)\n",
    "image_captioning_input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10230f03-6832-4d5b-ba7e-a439bdae0e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1926197/471210135.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_images_df[\"model_caption\"] = \"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6696"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter input for only blurred images\n",
    "filtered_images_df = image_captioning_input_df[image_captioning_input_df[\"blur\"] >= 3]\n",
    "filtered_images_df[\"model_caption\"] = \"\"\n",
    "\n",
    "dataset_to_caption = filtered_images_df.to_dict(\"records\")\n",
    "len(dataset_to_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23638d39-672a-491b-a4a3-75e98df8b63e",
   "metadata": {},
   "source": [
    "## Batch Processing of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4de5a9dc-c63d-4fd3-8387-6f6897f008df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model prompt\n",
    "prompt = {\n",
    "    \"type\": \"text\",\n",
    "    \"text\": \"\\n\".join(\n",
    "        [\n",
    "            \"You are a helpful assistant who describes objects in images to a blind and low-vision person. Please describe the objects in the image and any essential details necessary for identifying them.\",\n",
    "            \"\",\n",
    "            \"Follow these guidelines:\",\n",
    "            \"- Relevance and Specificity: Include visible text (including brand names), shapes, colors, textures, spatial relationships, or notable features only if they convey essential information about what is in the image.\",\n",
    "            \"- Structure of Response: Provide a description of the object with essential details. Only include details about the surrounding environment if it helps to identify the object.\",\n",
    "            \"- Clarity: Use simple, straightforward, objective language. Avoid unnecessary details.\",\n",
    "            '- Format: Describe the object with a concise, 1-2 sentence caption. DO NOT mention camera blur or if an object is partially visible. DO NOT use \"it\" to refer to the object. DO NOT include statements like \"The image shows\" or \"The object is\".',\n",
    "            \"\",\n",
    "            \"Output only the final caption.\",\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e89bc8e0-1995-4853-a6c7-03f4595d35d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8eaeb4beae4b22bf9f58eb5b4339d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>vizwiz_url</th>\n",
       "      <th>text_detected</th>\n",
       "      <th>unrecognizable</th>\n",
       "      <th>framing</th>\n",
       "      <th>blur</th>\n",
       "      <th>obstruction</th>\n",
       "      <th>rotation</th>\n",
       "      <th>too dark</th>\n",
       "      <th>...</th>\n",
       "      <th>human_caption_3</th>\n",
       "      <th>is_precanned_3</th>\n",
       "      <th>is_rejected_3</th>\n",
       "      <th>human_caption_4</th>\n",
       "      <th>is_precanned_4</th>\n",
       "      <th>is_rejected_4</th>\n",
       "      <th>human_caption_5</th>\n",
       "      <th>is_precanned_5</th>\n",
       "      <th>is_rejected_5</th>\n",
       "      <th>model_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>VizWiz_train_00000001.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>A kitchen counter the various items on top inc...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>a black tin of Coca Cola placed on a black sur...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Black counter with canisters, kettle and can o...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A black countertop with a row of four silver c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>VizWiz_train_00000007.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>A package containing cleaning items to clean a...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A packaged set of cleaning supplies for a devi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A cleaning kit is shown in plastic packaging o...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The image shows a person's legs and a monitor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>VizWiz_train_00000016.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>A group of small coins are on top of the table.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Two quarters, a nickel, and a dime sitting on ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Three quarters and one nickel on a wooden table.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The image features four silver coins, each wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>VizWiz_train_00000021.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Quality issues are too severe to recognize vis...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Quality issues are too severe to recognize vis...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Quality issues are too severe to recognize vis...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>The image appears to be a blurry, out-of-focus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>VizWiz_train_00000025.jpg</td>\n",
       "      <td>https://vizwiz.cs.colorado.edu/VizWiz_visualiz...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>close up of a grey poodle with a chain collar.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>grey short haired dog from behind with choker ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A gray dog looking forward with a silver collar.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The image features a dog with a distinctive si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                  file_name  \\\n",
       "0         1  VizWiz_train_00000001.jpg   \n",
       "1         7  VizWiz_train_00000007.jpg   \n",
       "2        16  VizWiz_train_00000016.jpg   \n",
       "3        21  VizWiz_train_00000021.jpg   \n",
       "4        25  VizWiz_train_00000025.jpg   \n",
       "\n",
       "                                          vizwiz_url  text_detected  \\\n",
       "0  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "1  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...           True   \n",
       "2  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...          False   \n",
       "3  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...          False   \n",
       "4  https://vizwiz.cs.colorado.edu/VizWiz_visualiz...          False   \n",
       "\n",
       "   unrecognizable  framing  blur  obstruction  rotation  too dark  ...  \\\n",
       "0               0        0     5            0         0         0  ...   \n",
       "1               0        1     3            0         1         1  ...   \n",
       "2               0        0     3            0         1         0  ...   \n",
       "3               4        2     4            1         0         0  ...   \n",
       "4               0        1     3            0         0         0  ...   \n",
       "\n",
       "                                     human_caption_3  is_precanned_3  \\\n",
       "0  A kitchen counter the various items on top inc...           False   \n",
       "1  A package containing cleaning items to clean a...           False   \n",
       "2    A group of small coins are on top of the table.           False   \n",
       "3  Quality issues are too severe to recognize vis...            True   \n",
       "4     close up of a grey poodle with a chain collar.           False   \n",
       "\n",
       "   is_rejected_3                                    human_caption_4  \\\n",
       "0          False  a black tin of Coca Cola placed on a black sur...   \n",
       "1          False  A packaged set of cleaning supplies for a devi...   \n",
       "2          False  Two quarters, a nickel, and a dime sitting on ...   \n",
       "3          False  Quality issues are too severe to recognize vis...   \n",
       "4          False  grey short haired dog from behind with choker ...   \n",
       "\n",
       "   is_precanned_4  is_rejected_4  \\\n",
       "0           False          False   \n",
       "1           False          False   \n",
       "2           False          False   \n",
       "3            True          False   \n",
       "4           False          False   \n",
       "\n",
       "                                     human_caption_5  is_precanned_5  \\\n",
       "0  Black counter with canisters, kettle and can o...           False   \n",
       "1  A cleaning kit is shown in plastic packaging o...           False   \n",
       "2   Three quarters and one nickel on a wooden table.           False   \n",
       "3  Quality issues are too severe to recognize vis...            True   \n",
       "4   A gray dog looking forward with a silver collar.           False   \n",
       "\n",
       "   is_rejected_5                                      model_caption  \n",
       "0          False  A black countertop with a row of four silver c...  \n",
       "1          False  The image shows a person's legs and a monitor ...  \n",
       "2          False  The image features four silver coins, each wit...  \n",
       "3          False  The image appears to be a blurry, out-of-focus...  \n",
       "4          False  The image features a dog with a distinctive si...  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captioned_data = generate_caption_output(\n",
    "    dataset_to_caption[0:5], prompt, \"../data/caption-dataset/train\"\n",
    ")\n",
    "\n",
    "pd.DataFrame.from_dict(captioned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f80c9-e9c8-4885-9262-0a3f72609261",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_to_caption_fixed = None\n",
    "with('../data/labeled-data/labeled-data_2300.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        dataset_to_caption_fixed.append(myClass(row[0], row[1], row[2:]))\n",
    "\n",
    "    # # separate captions into separate columns\n",
    "    # for index, item in enumerate(dataset_to_caption[2:]):\n",
    "    #     dataset_to_caption[index][\"human_caption_1\"] = item[\"caption\"][0]\n",
    "    #     dataset_to_caption[index][\"human_caption_2\"] = item[\"caption\"][1]\n",
    "    #     dataset_to_caption[index][\"human_caption_3\"] = item[\"caption\"][2]\n",
    "    #     dataset_to_caption[index][\"human_caption_4\"] = item[\"caption\"][3]\n",
    "    #     dataset_to_caption[index][\"human_caption_5\"] = item[\"caption\"][4]\n",
    "    #     del dataset_to_caption[index][\"caption\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d291ce7b-33d3-47ac-8899-c633d99b5b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_to_caption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7138c1d0-38f0-423b-a08a-a76f9ac6b92d",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6629a72-5010-4d0a-84c0-e550cd18fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if processor is not None:\n",
    "    del processor\n",
    "if model is not None:\n",
    "    del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75df1457-4c0f-44e7-8f9b-6742a0a6aa37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
