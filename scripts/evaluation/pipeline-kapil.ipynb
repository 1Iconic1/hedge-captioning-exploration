{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library for cap_f1\n",
    "from cap_f1 import *\n",
    "\n",
    "# library for BLUE, METEOR, ROUGE\n",
    "import evaluate\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load caption file...\n",
      "Captioned dataset loaded: 7304 images.\n"
     ]
    }
   ],
   "source": [
    "print(\"Load caption file...\")\n",
    "caption_file = \"../../data/study-2-output/labeled-data/combined-caption-output/combined-caption-output_7304-images_2025-03-29_21:40:00.json\"\n",
    "\n",
    "# features that we need to extract from the original dataset\n",
    "keys = [\"file_name\", \"human_captions\", \"model_captions\"]\n",
    "org_caption_dataset = read_json(caption_file, keys)\n",
    "print(f\"Captioned dataset loaded: {len(org_caption_dataset)} images.\")\n",
    "\n",
    "for item in org_caption_dataset:\n",
    "    # Filter out human captions\n",
    "    human_captions = [\n",
    "        hc[\"caption\"]            \n",
    "        for hc in item[\"human_captions\"]\n",
    "        if hc[\"caption\"] != \"Quality issues are too severe to recognize visual content.\"\n",
    "    ]\n",
    "    for mc in item[\"model_captions\"]:\n",
    "        model_name = mc[\"model_name\"]\n",
    "        model_caption = mc[\"caption\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Caption into Atomic Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating atomic statements using gpt-4o...\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating atomic statements using gpt-4o...\")\n",
    "T_atomics, g_atomics  = generate_atomic_statement(org_caption_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to: parsed_caption.json\n"
     ]
    }
   ],
   "source": [
    "# Save the parsing results\n",
    "save_results_json(output_path=\"parsed_caption.json\", org_dataset=org_caption_dataset, T_atomics=T_atomics, g_atomics=g_atomics)\n",
    "\n",
    "# Read Atomic Caption Dataset If Needed\n",
    "keys = [\"file_name\", \"human_captions\", \"model_captions\", \"evaluation\"]\n",
    "parsed_dataset = read_json(\"parsed_caption.json\", keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = evaluate_matching(human_captions, T_atomics, g_atomics)\n",
    "# evaluation = evaluate_matching_file(parsed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    [\n",
      "        {\n",
      "            \"model_name\": \"gpt-4o\",\n",
      "            \"recall\": 0.3,\n",
      "            \"precision\": 0.8571428571428571,\n",
      "            \"cap_f1\": 0.4444444444444444\n",
      "        },\n",
      "        {\n",
      "            \"model_name\": \"llama\",\n",
      "            \"recall\": 0.3,\n",
      "            \"precision\": 0.2857142857142857,\n",
      "            \"cap_f1\": 0.2926829268292683\n",
      "        },\n",
      "        {\n",
      "            \"model_name\": \"molmo\",\n",
      "            \"recall\": 0.4444444444444444,\n",
      "            \"precision\": 0.5714285714285714,\n",
      "            \"cap_f1\": 0.5\n",
      "        }\n",
      "    ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "output = calculate_cap_f1(evaluation)\n",
    "print(json.dumps(output, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n",
    "### BLUE, METEOR, ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/kgarg/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human captions: ['A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.', 'A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.', 'A kitchen counter the various items on top including a can of Coca-Cola, metal containers, and a teapot.', 'a black tin of Coca Cola placed on a black surface', 'Black counter with canisters, kettle and can of soda.']\n",
      "\n",
      "gpt-4o-2024-08-06 caption: ['A can of Coca-Cola Zero is on a kitchen countertop, next to a white mug and a black kettle. Three silver canisters are aligned against the wall, along with a visible electrical outlet above them.']\n",
      "\n",
      "BLEU-1: {'bleu': 0.1383437751327924, 'precisions': [0.5384615384615384], 'brevity_penalty': 0.256924153818043, 'length_ratio': 0.42391304347826086, 'translation_length': 39, 'reference_length': 92}\n",
      "BLEU-2: {'bleu': 0.07491453800514392, 'precisions': [0.5384615384615384, 0.15789473684210525], 'brevity_penalty': 0.256924153818043, 'length_ratio': 0.42391304347826086, 'translation_length': 39, 'reference_length': 92}\n",
      "BLEU-3: {'bleu': 0.033903547315646994, 'precisions': [0.5384615384615384, 0.15789473684210525, 0.02702702702702703], 'brevity_penalty': 0.256924153818043, 'length_ratio': 0.42391304347826086, 'translation_length': 39, 'reference_length': 92}\n",
      "BLEU-4: {'bleu': 0.0, 'precisions': [0.5384615384615384, 0.15789473684210525, 0.02702702702702703, 0.0], 'brevity_penalty': 0.256924153818043, 'length_ratio': 0.42391304347826086, 'translation_length': 39, 'reference_length': 92}\n",
      "METEOR: {'meteor': np.float64(0.42315262122025415)}\n",
      "ROUGE: {'rouge1': np.float64(0.4000000000000001), 'rouge2': np.float64(0.23529411764705876), 'rougeL': np.float64(0.33962264150943394), 'rougeLsum': np.float64(0.33962264150943394)}\n",
      "\n",
      "\n",
      "Llama-3.2-11B-Vision-Instruct caption: ['The image shows a black can with a yellow band and red writing, likely a beverage can, on a kitchen counter. The can has a white label with indistinct writing.']\n",
      "\n",
      "BLEU-1: {'bleu': 0.09614756621336873, 'precisions': [0.5294117647058824], 'brevity_penalty': 0.18161206951414094, 'length_ratio': 0.3695652173913043, 'translation_length': 34, 'reference_length': 92}\n",
      "BLEU-2: {'bleu': 0.046006005508843435, 'precisions': [0.5294117647058824, 0.12121212121212122], 'brevity_penalty': 0.18161206951414094, 'length_ratio': 0.3695652173913043, 'translation_length': 34, 'reference_length': 92}\n",
      "BLEU-3: {'bleu': 0.0, 'precisions': [0.5294117647058824, 0.12121212121212122, 0.0], 'brevity_penalty': 0.18161206951414094, 'length_ratio': 0.3695652173913043, 'translation_length': 34, 'reference_length': 92}\n",
      "BLEU-4: {'bleu': 0.0, 'precisions': [0.5294117647058824, 0.12121212121212122, 0.0, 0.0], 'brevity_penalty': 0.18161206951414094, 'length_ratio': 0.3695652173913043, 'translation_length': 34, 'reference_length': 92}\n",
      "METEOR: {'meteor': np.float64(0.33087319382162433)}\n",
      "ROUGE: {'rouge1': np.float64(0.3673469387755102), 'rouge2': np.float64(0.1276595744680851), 'rougeL': np.float64(0.2857142857142857), 'rougeLsum': np.float64(0.2857142857142857)}\n",
      "\n",
      "\n",
      "Molmo-7B-O-0924 caption: ['A black and yellow can of Coca-Cola is prominently displayed on a black countertop. The can features the Coca-Cola logo in red and white text.']\n",
      "\n",
      "BLEU-1: {'bleu': 0.046691789484701235, 'precisions': [0.5185185185185185], 'brevity_penalty': 0.09004845114906668, 'length_ratio': 0.29347826086956524, 'translation_length': 27, 'reference_length': 92}\n",
      "BLEU-2: {'bleu': 0.025433240891145174, 'precisions': [0.5185185185185185, 0.15384615384615385], 'brevity_penalty': 0.09004845114906668, 'length_ratio': 0.29347826086956524, 'translation_length': 27, 'reference_length': 92}\n",
      "BLEU-3: {'bleu': 0.016702823088895577, 'precisions': [0.5185185185185185, 0.15384615384615385, 0.08], 'brevity_penalty': 0.09004845114906668, 'length_ratio': 0.29347826086956524, 'translation_length': 27, 'reference_length': 92}\n",
      "BLEU-4: {'bleu': 0.0, 'precisions': [0.5185185185185185, 0.15384615384615385, 0.08, 0.0], 'brevity_penalty': 0.09004845114906668, 'length_ratio': 0.29347826086956524, 'translation_length': 27, 'reference_length': 92}\n",
      "METEOR: {'meteor': np.float64(0.503725299643667)}\n",
      "ROUGE: {'rouge1': np.float64(0.45454545454545453), 'rouge2': np.float64(0.2777777777777778), 'rougeL': np.float64(0.45454545454545453), 'rougeLsum': np.float64(0.45454545454545453)}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in org_caption_dataset[0:1]:\n",
    "    # Filter out human captions that we'll use for all models \n",
    "    human_captions = [\n",
    "        hc[\"caption\"]            \n",
    "        for hc in item[\"human_captions\"]\n",
    "        if hc[\"caption\"] != \"Quality issues are too severe to recognize visual content.\"\n",
    "    ]\n",
    "\n",
    "    print(f\"Human captions: {human_captions}\\n\")\n",
    "    # apply metric for each model separately\n",
    "    for mc in item[\"model_captions\"]:\n",
    "        model_name = mc[\"model_name\"]\n",
    "        model_caption = mc[\"caption\"]\n",
    "        \n",
    "        references = [human_captions]\n",
    "        predictions = [model_caption]\n",
    "\n",
    "        print(f\"{model_name} caption: {predictions}\\n\")\n",
    "        print(\"BLEU-1:\", bleu.compute(predictions=predictions, references=[references], max_order=1))\n",
    "        print(\"BLEU-2:\", bleu.compute(predictions=predictions, references=[references], max_order=2))\n",
    "        print(\"BLEU-3:\", bleu.compute(predictions=predictions, references=[references], max_order=3))\n",
    "        print(\"BLEU-4:\", bleu.compute(predictions=predictions, references=[references], max_order=4))\n",
    "        print(\"METEOR:\", meteor.compute(predictions=predictions, references=references))\n",
    "        print(\"ROUGE:\", rouge.compute(predictions=predictions, references=references))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.821831989445342e-231\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "hypothesis = [\"hello there general kenobi\"]\n",
    "reference = [\"hello there general kenobi\"]\n",
    "#there may be several references\n",
    "BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis)\n",
    "print(BLEUscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 1.0,\n",
       " 'precisions': [1.0, 1.0, 1.0, 1.0],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.75,\n",
       " 'translation_length': 7,\n",
       " 'reference_length': 4}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\"hello there general kenobi\", \"foo bar foobar\"]\n",
    "references = [\n",
    "    [\"hello there general kenobi\", \"hello there!\"],\n",
    "    [\"foo bar foobar\", \"cat\"]\n",
    "]\n",
    "bleu.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.0,\n",
       " 'precisions': [1.0, 0.0, 0.0, 0.0],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.0,\n",
       " 'translation_length': 23,\n",
       " 'reference_length': 23}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions=\"hello there general kenobi\", references=\"hello there general kenobi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'VizWiz_train_00000001.jpg',\n",
       " 'human_captions': [{'caption': 'A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.',\n",
       "   'is_precanned': False,\n",
       "   'is_rejected': False},\n",
       "  {'caption': 'A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.',\n",
       "   'is_precanned': False,\n",
       "   'is_rejected': False},\n",
       "  {'caption': 'A kitchen counter the various items on top including a can of Coca-Cola, metal containers, and a teapot.',\n",
       "   'is_precanned': False,\n",
       "   'is_rejected': False},\n",
       "  {'caption': 'a black tin of Coca Cola placed on a black surface',\n",
       "   'is_precanned': False,\n",
       "   'is_rejected': False},\n",
       "  {'caption': 'Black counter with canisters, kettle and can of soda.',\n",
       "   'is_precanned': False,\n",
       "   'is_rejected': False}],\n",
       " 'model_captions': [{'model_name': 'gpt-4o-2024-08-06',\n",
       "   'caption': 'A can of Coca-Cola Zero is on a kitchen countertop, next to a white mug and a black kettle. Three silver canisters are aligned against the wall, along with a visible electrical outlet above them.'},\n",
       "  {'model_name': 'Llama-3.2-11B-Vision-Instruct',\n",
       "   'caption': 'The image shows a black can with a yellow band and red writing, likely a beverage can, on a kitchen counter. The can has a white label with indistinct writing.'},\n",
       "  {'model_name': 'Molmo-7B-O-0924',\n",
       "   'caption': 'A black and yellow can of Coca-Cola is prominently displayed on a black countertop. The can features the Coca-Cola logo in red and white text.'}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_caption_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
