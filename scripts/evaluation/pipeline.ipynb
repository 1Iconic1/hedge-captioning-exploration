{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# library for cap_f1\n",
    "from cap_f1 import *\n",
    "from datetime import datetime\n",
    "\n",
    "# code for no need for restarting the kernel when python file is updated\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# number of data points\n",
    "LIMIT = 50\n",
    "\n",
    "# for filename\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%Y-%m-%d_%H-%M\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load caption file...\n"
     ]
    }
   ],
   "source": [
    "print(\"Load caption file...\")\n",
    "\n",
    "# features that we need to extract from the original dataset\n",
    "keys = [\"file_name\", \"human_captions\", \"model_captions\"]\n",
    "org_caption_dataset = read_json(\"combined-caption-output_7304-images2025-03-29_21_40_00.json\", keys)\n",
    "\n",
    "all_human_captions=[]\n",
    "for item in org_caption_dataset:\n",
    "    # Filter out human captions\n",
    "    human_captions = [\n",
    "        hc[\"caption\"]            \n",
    "        for hc in item[\"human_captions\"]\n",
    "        if hc[\"caption\"] != \"Quality issues are too severe to recognize visual content.\"\n",
    "    ]\n",
    "    all_human_captions.append(human_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Caption into Atomic Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating atomic statements using gpt-4o...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [11:07<00:00, 13.34s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating atomic statements using gpt-4o...\")\n",
    "\n",
    "T_atomics, g_atomics  = generate_atomic_statement(org_caption_dataset, limit=LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to: parsed_caption_2025-04-02_23-50.json\n"
     ]
    }
   ],
   "source": [
    "# Save the parsing results\n",
    "save_results_json(output_path=f\"parsed_caption_{timestamp}.json\", org_dataset=org_caption_dataset, T_atomics=T_atomics, g_atomics=g_atomics, limit=LIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:34<00:00, 12.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to: recall_precision_2025-04-02_23-50.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Read data from variable\n",
    "# before calculating F1 score, match sentences between human generated and model generated  \n",
    "metadata = evaluate_matching(all_human_captions, T_atomics, g_atomics)\n",
    "\n",
    "# Read existing atomic caption dataset from previous run\n",
    "# If you want to use results from previous run without running atomic captioning call\n",
    "# keys = [\"file_name\", \"human_captions\", \"model_captions\", \"evaluation\"]\n",
    "# parsed_dataset = read_json(f\"parsed_caption_{timestamp}.json\", keys)\n",
    "# metadata = evaluate_matching_file(parsed_dataset, print_mode=True)\n",
    "\n",
    "# save the temp result\n",
    "save_results_json(output_path=f\"recall_precision_{timestamp}.json\", update_existing=f\"parsed_caption_{timestamp}.json\", metadata=metadata, limit=LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 131813.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to: final_2025-04-02_23-50.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get cap f1 score\n",
    "evaluation = calculate_cap_f1(metadata)\n",
    "save_results_json(output_path=f\"final_{timestamp}.json\", update_existing=f\"recall_precision_{timestamp}.json\", evaluations=evaluation, limit=LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to: final_2025-04-02_23-50.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "json_path = f\"final_{timestamp}.json\" \n",
    "csv_path = f\"final_{timestamp}.csv\"\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "fieldnames = [\n",
    "    \"image\",\n",
    "    \"T_atomics\",\n",
    "    \n",
    "    \"gpt_g_atomics\", \"gpt_recall_TPs\", \"gpt_precision_TPs\",\n",
    "    \"molmo_g_atomics\", \"molmo_recall_TPs\", \"molmo_precision_TPs\",\n",
    "    \"llama_g_atomics\", \"llama_recall_TPs\", \"llama_precision_TPs\",\n",
    "    \n",
    "    \"gpt_recall\", \"gpt_precision\", \"gpt_capf1\",\n",
    "    \"molmo_recall\", \"molmo_precision\", \"molmo_capf1\",\n",
    "    \"llama_recall\", \"llama_precision\", \"llama_capf1\"\n",
    "]\n",
    "\n",
    "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for item in data:\n",
    "        file_name = item.get(\"file_name\", \"\")\n",
    "        cap_f1 = item.get(\"evaluation\", {}).get(\"cap_f1\", {})\n",
    "        scores = cap_f1.get(\"scores\", {})\n",
    "        metadata = cap_f1.get(\"metadata\", {})\n",
    "        t_atomics = cap_f1.get(\"T_atomics\", [])\n",
    "\n",
    "        model_keys = {\n",
    "            \"gpt\": \"gpt-4o-2024-08-06\",\n",
    "            \"molmo\": \"Molmo-7B-O-0924\",\n",
    "            \"llama\": \"Llama-3.2-11B-Vision-Instruct\"\n",
    "        }\n",
    "\n",
    "        row = {\n",
    "            \"image\": file_name,\n",
    "            \"T_atomics\": \"\\n\".join(t_atomics),\n",
    "\n",
    "            \"gpt_g_atomics\": \"\",\n",
    "            \"gpt_recall_TPs\": \"\",\n",
    "            \"gpt_precision_TPs\": \"\",\n",
    "\n",
    "            \"molmo_g_atomics\": \"\",\n",
    "            \"molmo_recall_TPs\": \"\",\n",
    "            \"molmo_precision_TPs\": \"\",\n",
    "\n",
    "            \"llama_g_atomics\": \"\",\n",
    "            \"llama_recall_TPs\": \"\",\n",
    "            \"llama_precision_TPs\": \"\",\n",
    "\n",
    "            \"gpt_recall\": scores.get(model_keys[\"gpt\"], {}).get(\"recall\"),\n",
    "            \"gpt_precision\": scores.get(model_keys[\"gpt\"], {}).get(\"precision\"),\n",
    "            \"gpt_capf1\": scores.get(model_keys[\"gpt\"], {}).get(\"cap_f1\"),\n",
    "\n",
    "            \"molmo_recall\": scores.get(model_keys[\"molmo\"], {}).get(\"recall\"),\n",
    "            \"molmo_precision\": scores.get(model_keys[\"molmo\"], {}).get(\"precision\"),\n",
    "            \"molmo_capf1\": scores.get(model_keys[\"molmo\"], {}).get(\"cap_f1\"),\n",
    "\n",
    "            \"llama_recall\": scores.get(model_keys[\"llama\"], {}).get(\"recall\"),\n",
    "            \"llama_precision\": scores.get(model_keys[\"llama\"], {}).get(\"precision\"),\n",
    "            \"llama_capf1\": scores.get(model_keys[\"llama\"], {}).get(\"cap_f1\"),\n",
    "        }\n",
    "\n",
    "        for short_name, model_key in model_keys.items():\n",
    "            # g_atomics\n",
    "            g_atomics_list = cap_f1.get(\"g_atomics\", {}).get(model_key, [])\n",
    "            row[f\"{short_name}_g_atomics\"] = \"\\n\".join(g_atomics_list)\n",
    "\n",
    "            # recall TPs\n",
    "            recall_tps = metadata.get(model_key, {}).get(\"recall\", {}).get(\"TPs\", [])\n",
    "            row[f\"{short_name}_recall_TPs\"] = \"\\n\".join(recall_tps)\n",
    "\n",
    "            # precision TPs\n",
    "            precision_tps = metadata.get(model_key, {}).get(\"precision\", {}).get(\"TPs\", [])\n",
    "            row[f\"{short_name}_precision_TPs\"] = \"\\n\".join(precision_tps)\n",
    "\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Evaluation \n",
    "### BLUE, METEOR, ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load caption file...\n"
     ]
    }
   ],
   "source": [
    "print(\"Load caption file...\")\n",
    "\n",
    "# features that we need to extract from the original dataset\n",
    "keys = [\"file_name\", \"human_captions\", \"model_captions\"]\n",
    "org_caption_dataset = read_json(\"combined-caption-output_7304-images2025-03-29_21_40_00.json\", keys)\n",
    "\n",
    "for item in org_caption_dataset:\n",
    "    # Filter out human captions\n",
    "    human_captions = [\n",
    "        hc[\"caption\"]            \n",
    "        for hc in item[\"human_captions\"]\n",
    "        if hc[\"caption\"] != \"Quality issues are too severe to recognize visual content.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/heoj4/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/heoj4/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/heoj4/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "evall = get_others(org_caption_dataset, human_captions)\n",
    "# print(json.dumps(evall, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to: others_evaluation.json\n"
     ]
    }
   ],
   "source": [
    "save_results_json(output_path=\"others_evaluation.json\", metric_name=\"others\",  evaluations=evall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
