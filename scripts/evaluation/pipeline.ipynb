{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# library for cap_f1\n",
    "from cap_f1 import *\n",
    "from datetime import datetime\n",
    "\n",
    "# code for no need for restarting the kernel when python file is updated\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# number of data points\n",

    "LIMIT = 10\n",

    "\n",
    "# for filename\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%Y-%m-%d_%H-%M\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load caption file...\n"
     ]
    }
   ],
   "source": [
    "print(\"Load caption file...\")\n",
    "\n",
    "# features that we need to extract from the original dataset\n",
    "keys = [\"file_name\", \"human_captions\", \"model_captions\"]\n",
    "org_caption_dataset = read_json(\n",
    "    \"combined-caption-output_7304-images2025-03-29_21_40_00.json\", keys\n",
    ")\n",
    "\n",
    "all_human_captions = []\n",
    "for item in org_caption_dataset:\n",
    "    # Filter out human captions\n",
    "    human_captions = [\n",
    "        hc[\"caption\"]\n",
    "        for hc in item[\"human_captions\"]\n",
    "        if hc[\"caption\"] != \"Quality issues are too severe to recognize visual content.\"\n",
    "    ]\n",
    "    all_human_captions.append(human_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Caption into Atomic Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating atomic statements using gpt-4o...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "print(\"Generating atomic statements using gpt-4o...\")\n",
    "\n",
    "T_atomics, g_atomics = generate_atomic_statement(org_caption_dataset, limit=LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

     ]
    }
   ],
   "source": [
    "# Save the parsing results\n",
    "save_results_json(\n",
    "    output_path=f\"parsed_caption_{timestamp}.json\",\n",
    "    org_dataset=org_caption_dataset,\n",
    "    T_atomics=T_atomics,\n",
    "    g_atomics=g_atomics,\n",
    "    limit=LIMIT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Read data from variable\n",
    "# before calculating F1 score, match sentences between human generated and model generated\n",
    "metadata = evaluate_matching(all_human_captions, T_atomics, g_atomics)\n",
    "\n",
    "# Read existing atomic caption dataset from previous run\n",
    "# If you want to use results from previous run without running atomic captioning call\n",
    "# keys = [\"file_name\", \"human_captions\", \"model_captions\", \"evaluation\"]\n",
    "# parsed_dataset = read_json(f\"parsed_caption_{timestamp}.json\", keys)\n",
    "# metadata = evaluate_matching_file(parsed_dataset, print_mode=True)\n",
    "\n",
    "# save the temp result\n",
    "save_results_json(\n",
    "    output_path=f\"recall_precision_{timestamp}.json\",\n",
    "    update_existing=f\"parsed_caption_{timestamp}.json\",\n",
    "    metadata=metadata,\n",
    "    limit=LIMIT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 147168.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to: final_2025-04-03_04-07.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get cap f1 score\n",
    "evaluation = calculate_cap_f1(metadata)\n",
    "save_results_json(\n",
    "    output_path=f\"final_{timestamp}.json\",\n",
    "    update_existing=f\"recall_precision_{timestamp}.json\",\n",
    "    evaluations=evaluation,\n",
    "    limit=LIMIT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'VizWiz_train_00000001.jpg',\n",
       " 'human_captions': ['A can of Coca Cola on a counter is shown for when one can use a nice, cold drink.',\n",
       "  'A black can of Coca Cola Zero calorie soda is on the counter near the coffee maker.',\n",
       "  'A kitchen counter the various items on top including a can of Coca-Cola, metal containers, and a teapot.',\n",
       "  'a black tin of Coca Cola placed on a black surface',\n",
       "  'Black counter with canisters, kettle and can of soda.'],\n",
       " 'model_captions': [{'model_name': 'gpt-4o-2024-08-06',\n",
       "   'caption': 'A can of Coca-Cola Zero is on a kitchen countertop, next to a white mug and a black kettle. Three silver canisters are aligned against the wall, along with a visible electrical outlet above them.'},\n",
       "  {'model_name': 'Llama-3.2-11B-Vision-Instruct',\n",
       "   'caption': 'The image shows a black can with a yellow band and red writing, likely a beverage can, on a kitchen counter. The can has a white label with indistinct writing.'},\n",
       "  {'model_name': 'Molmo-7B-O-0924',\n",
       "   'caption': 'A black and yellow can of Coca-Cola is prominently displayed on a black countertop. The can features the Coca-Cola logo in red and white text.'}],\n",
       " 'evaluation': {'cap_f1': {'T_atomics': ['There is a can of Coca Cola Zero.',\n",
       "    'The can is on a counter.',\n",
       "    'The can is black.',\n",
       "    'The can is near the coffee maker.',\n",
       "    'There is a kitchen counter.',\n",
       "    'There are metal containers on the counter.',\n",
       "    'There is a teapot on the counter.',\n",
       "    'The counter is black.',\n",
       "    'There are canisters on the counter.',\n",
       "    'There is a kettle on the counter.'],\n",
       "   'g_atomics': {'gpt-4o-2024-08-06': ['There is a can of Coca-Cola Zero.',\n",
       "     'The can of Coca-Cola Zero is on a kitchen countertop.',\n",
       "     'There is a white mug.',\n",
       "     'The white mug is on the kitchen countertop.',\n",
       "     'There is a black kettle.',\n",
       "     'The black kettle is on the kitchen countertop.',\n",
       "     'There are three silver canisters.',\n",
       "     'The three silver canisters are aligned against the wall.',\n",
       "     'There is an electrical outlet.',\n",
       "     'The electrical outlet is above the silver canisters.'],\n",
       "    'Llama-3.2-11B-Vision-Instruct': ['There is a black can.',\n",
       "     'The can has a yellow band.',\n",
       "     'The can has red writing.',\n",
       "     'The can is likely a beverage can.',\n",
       "     'The can is on a kitchen counter.',\n",
       "     'The can has a white label.',\n",
       "     'The writing on the label is indistinct.'],\n",
       "    'Molmo-7B-O-0924': ['There is a can of Coca-Cola.',\n",
       "     'The can is black and yellow.',\n",
       "     'The can is on a black countertop.',\n",
       "     'The can has the Coca-Cola logo.',\n",
       "     'The logo is in red text.',\n",
       "     'The logo is in white text.']},\n",
       "   'scores': {'gpt-4o-2024-08-06': {'recall': 0.6,\n",
       "     'precision': 0.2,\n",
       "     'cap_f1': 0.3},\n",
       "    'Llama-3.2-11B-Vision-Instruct': {'recall': 0.4,\n",
       "     'precision': 0.42857142857142855,\n",
       "     'cap_f1': 0.4137931034482759},\n",
       "    'Molmo-7B-O-0924': {'recall': 0.4,\n",
       "     'precision': 0.5,\n",
       "     'cap_f1': 0.4444444444444445}},\n",
       "   'metadata': {'gpt-4o-2024-08-06': {'recall': {'TPs': ['There is a can of Coca Cola Zero.',\n",
       "       'The can is on a counter.',\n",
       "       'There is a kitchen counter.',\n",
       "       'There are metal containers on the counter.',\n",
       "       'There are canisters on the counter.',\n",
       "       'There is a kettle on the counter.'],\n",
       "      'FNs': ['The can is black.',\n",
       "       'The can is near the coffee maker.',\n",
       "       'There is a teapot on the counter.',\n",
       "       'The counter is black.'],\n",
       "      'Counts': {'TP': 6, 'FN': 4}},\n",
       "     'precision': {'TPs': ['There is a can of Coca-Cola Zero.',\n",
       "       'The can of Coca-Cola Zero is on a kitchen countertop.'],\n",
       "      'FPs': ['There is a white mug.',\n",
       "       'The white mug is on the kitchen countertop.',\n",
       "       'There is a black kettle.',\n",
       "       'The black kettle is on the kitchen countertop.',\n",
       "       'There are three silver canisters.',\n",
       "       'The three silver canisters are aligned against the wall.',\n",
       "       'There is an electrical outlet.',\n",
       "       'The electrical outlet is above the silver canisters.'],\n",
       "      'Counts': {'TP': 2, 'FP': 8}}},\n",
       "    'Llama-3.2-11B-Vision-Instruct': {'recall': {'TPs': ['There is a can of Coca Cola Zero.',\n",
       "       'The can is on a counter.',\n",
       "       'The can is black.',\n",
       "       'There is a kitchen counter.'],\n",
       "      'FNs': ['The can is near the coffee maker.',\n",
       "       'There are metal containers on the counter.',\n",
       "       'There is a teapot on the counter.',\n",
       "       'The counter is black.',\n",
       "       'There are canisters on the counter.',\n",
       "       'There is a kettle on the counter.'],\n",
       "      'Counts': {'TP': 4, 'FN': 6}},\n",
       "     'precision': {'TPs': ['There is a black can.',\n",
       "       'The can is likely a beverage can.',\n",
       "       'The can is on a kitchen counter.'],\n",
       "      'FPs': ['The can has a yellow band.',\n",
       "       'The can has red writing.',\n",
       "       'The can has a white label.',\n",
       "       'The writing on the label is indistinct.'],\n",
       "      'Counts': {'TP': 3, 'FP': 4}}},\n",
       "    'Molmo-7B-O-0924': {'recall': {'TPs': ['There is a can of Coca Cola Zero.',\n",
       "       'The can is on a counter.',\n",
       "       'The can is black.',\n",
       "       'The counter is black.'],\n",
       "      'FNs': ['The can is near the coffee maker.',\n",
       "       'There is a kitchen counter.',\n",
       "       'There are metal containers on the counter.',\n",
       "       'There is a teapot on the counter.',\n",
       "       'There are canisters on the counter.',\n",
       "       'There is a kettle on the counter.'],\n",
       "      'Counts': {'TP': 4, 'FN': 6}},\n",
       "     'precision': {'TPs': ['There is a can of Coca-Cola.',\n",
       "       'The can is on a black countertop.',\n",
       "       'The can has the Coca-Cola logo.'],\n",
       "      'FPs': ['The can is black and yellow.',\n",
       "       'The logo is in red text.',\n",
       "       'The logo is in white text.'],\n",
       "      'Counts': {'TP': 3, 'FP': 3}}}}}}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to: final_2025-04-03_04-07.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "json_path = f\"final_{timestamp}.json\"\n",
    "csv_path = f\"final_{timestamp}.csv\"\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "fieldnames = [\n",
    "    \"image\",\n",
    "    \"T_atomics\",\n",
    "    \"gpt_caption\",\n",
    "    \"gpt_g_atomics\",\n",
    "    \"gpt_recall_TPs\",\n",
    "    \"gpt_recall_FNs\",\n",
    "    \"gpt_precision_TPs\",\n",
    "    \"gpt_precision_FPs\",\n",
    "    \"molmo_caption\",\n",
    "    \"molmo_g_atomics\",\n",
    "    \"molmo_recall_TPs\",\n",
    "    \"molmo_recall_FNs\",\n",
    "    \"molmo_precision_TPs\",\n",
    "    \"molmo_precision_FPs\",\n",
    "    \"llama_caption\",\n",
    "    \"llama_g_atomics\",\n",
    "    \"llama_recall_TPs\",\n",
    "    \"llama_recall_FNs\",\n",
    "    \"llama_precision_TPs\",\n",
    "    \"llama_precision_FPs\",\n",
    "    \"gpt_recall\",\n",
    "    \"gpt_precision\",\n",
    "    \"gpt_capf1\",\n",
    "    \"molmo_recall\",\n",
    "    \"molmo_precision\",\n",
    "    \"molmo_capf1\",\n",
    "    \"llama_recall\",\n",
    "    \"llama_precision\",\n",
    "    \"llama_capf1\",\n",
    "]\n",
    "\n",
    "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for item in data:\n",
    "        file_name = item.get(\"file_name\", \"\")\n",
    "        cap_f1 = item.get(\"evaluation\", {}).get(\"cap_f1\", {})\n",
    "        scores = cap_f1.get(\"scores\", {})\n",
    "        metadata = cap_f1.get(\"metadata\", {})\n",
    "        t_atomics = cap_f1.get(\"T_atomics\", [])\n",
    "\n",
    "        model_keys = {\n",
    "            \"gpt\": \"gpt-4o-2024-08-06\",\n",
    "            \"molmo\": \"Molmo-7B-O-0924\",\n",
    "            \"llama\": \"Llama-3.2-11B-Vision-Instruct\",\n",
    "        }\n",
    "\n",
    "        row = {\n",
    "            \"image\": file_name,\n",
    "            \"T_atomics\": \"\\n\".join(t_atomics),\n",
    "            \"gpt_caption\": item[\"model_captions\"][0][\"caption\"],\n",
    "            \"gpt_g_atomics\": \"\",\n",
    "            \"gpt_recall_TPs\": \"\",\n",
    "            \"gpt_precision_TPs\": \"\",\n",
    "            \"molmo_caption\": item[\"model_captions\"][2][\"caption\"],\n",
    "            \"molmo_g_atomics\": \"\",\n",
    "            \"molmo_recall_TPs\": \"\",\n",
    "            \"molmo_precision_TPs\": \"\",\n",
    "            \"llama_caption\": item[\"model_captions\"][1][\"caption\"],\n",
    "            \"llama_g_atomics\": \"\",\n",
    "            \"llama_recall_TPs\": \"\",\n",
    "            \"llama_precision_TPs\": \"\",\n",
    "            \"gpt_recall\": scores.get(model_keys[\"gpt\"], {}).get(\"recall\"),\n",
    "            \"gpt_precision\": scores.get(model_keys[\"gpt\"], {}).get(\"precision\"),\n",
    "            \"gpt_capf1\": scores.get(model_keys[\"gpt\"], {}).get(\"cap_f1\"),\n",
    "            \"molmo_recall\": scores.get(model_keys[\"molmo\"], {}).get(\"recall\"),\n",
    "            \"molmo_precision\": scores.get(model_keys[\"molmo\"], {}).get(\"precision\"),\n",
    "            \"molmo_capf1\": scores.get(model_keys[\"molmo\"], {}).get(\"cap_f1\"),\n",
    "            \"llama_recall\": scores.get(model_keys[\"llama\"], {}).get(\"recall\"),\n",
    "            \"llama_precision\": scores.get(model_keys[\"llama\"], {}).get(\"precision\"),\n",
    "            \"llama_capf1\": scores.get(model_keys[\"llama\"], {}).get(\"cap_f1\"),\n",
    "        }\n",
    "\n",
    "        for short_name, model_key in model_keys.items():\n",
    "            # g_atomics\n",
    "            g_atomics_list = cap_f1.get(\"g_atomics\", {}).get(model_key, [])\n",
    "            row[f\"{short_name}_g_atomics\"] = \"\\n\".join(g_atomics_list)\n",
    "\n",
    "            # recall TPs\n",
    "            recall_tps = metadata.get(model_key, {}).get(\"recall\", {}).get(\"TPs\", [])\n",
    "            row[f\"{short_name}_recall_TPs\"] = \"\\n\".join(recall_tps)\n",
    "\n",
    "            # recall FNs\n",
    "            recall_fns = metadata.get(model_key, {}).get(\"recall\", {}).get(\"FNs\", [])\n",
    "            row[f\"{short_name}_recall_FNs\"] = \"\\n\".join(recall_fns)\n",
    "\n",
    "            # precision TPs\n",
    "            precision_tps = (\n",
    "                metadata.get(model_key, {}).get(\"precision\", {}).get(\"TPs\", [])\n",
    "            )\n",
    "            row[f\"{short_name}_precision_TPs\"] = \"\\n\".join(precision_tps)\n",
    "\n",
    "            # precision FPs\n",
    "            precision_fps = (\n",
    "                metadata.get(model_key, {}).get(\"precision\", {}).get(\"FPs\", [])\n",
    "            )\n",
    "            row[f\"{short_name}_precision_FPs\"] = \"\\n\".join(precision_fps)\n",
    "\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Evaluation \n",
    "### BLUE, METEOR, ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load caption file...\n"
     ]
    }
   ],
   "source": [
    "print(\"Load caption file...\")\n",
    "\n",
    "# features that we need to extract from the original dataset\n",
    "keys = [\"file_name\", \"human_captions\", \"model_captions\"]\n",
    "org_caption_dataset = read_json(\n",
    "    \"combined-caption-output_7304-images2025-03-29_21_40_00.json\", keys\n",
    ")\n",
    "\n",
    "for item in org_caption_dataset:\n",
    "    # Filter out human captions\n",
    "    human_captions = [\n",
    "        hc[\"caption\"]\n",
    "        for hc in item[\"human_captions\"]\n",
    "        if hc[\"caption\"] != \"Quality issues are too severe to recognize visual content.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/heoj4/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/heoj4/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/heoj4/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "evall = get_others(org_caption_dataset, human_captions)\n",
    "# print(json.dumps(evall, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to: others_evaluation.json\n"
     ]
    }
   ],
   "source": [
    "save_results_json(\n",
    "    output_path=\"others_evaluation.json\", metric_name=\"others\", evaluations=evall\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-blurred-captioning-exploration-4LZKhcfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
