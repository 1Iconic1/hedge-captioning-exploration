{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# library for cap_f1\n",
    "from cap_f1 import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load caption file...\n"
     ]
    }
   ],
   "source": [
    "print(\"Load caption file...\")\n",
    "\n",
    "# features that we need to extract from the original dataset\n",
    "keys = [\"file_name\", \"human_captions\", \"model_captions\"]\n",
    "org_caption_dataset = read_json(\"combined-caption-output_7304-images2025-03-29_21_40_00.json\", keys)\n",
    "\n",
    "all_human_captions=[]\n",
    "for item in org_caption_dataset:\n",
    "    # Filter out human captions\n",
    "    human_captions = [\n",
    "        hc[\"caption\"]            \n",
    "        for hc in item[\"human_captions\"]\n",
    "        if hc[\"caption\"] != \"Quality issues are too severe to recognize visual content.\"\n",
    "    ]\n",
    "    all_human_captions.append(human_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Caption into Atomic Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating atomic statements using gpt-4o...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [05:24<00:00, 16.23s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating atomic statements using gpt-4o...\")\n",
    "LIMIT = 5\n",
    "T_atomics, g_atomics  = generate_atomic_statement(org_caption_dataset, limit=LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to: parsed_caption.json\n"
     ]
    }
   ],
   "source": [
    "# Save the parsing results\n",
    "save_results_json(output_path=\"parsed_caption.json\", org_dataset=org_caption_dataset, T_atomics=T_atomics, g_atomics=g_atomics, limit=LIMIT)\n",
    "\n",
    "# Read Atomic Caption Dataset If Needed\n",
    "keys = [\"file_name\", \"human_captions\", \"model_captions\", \"evaluation\"]\n",
    "parsed_dataset = read_json(\"parsed_caption.json\", keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [04:41<00:00, 14.05s/it]\n"
     ]
    }
   ],
   "source": [
    "metadata = evaluate_matching(all_human_captions, T_atomics, g_atomics)\n",
    "# metadata = evaluate_matching_file(parsed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to: data_recall_precision.json\n"
     ]
    }
   ],
   "source": [
    "save_results_json(output_path=\"data_recall_precision.json\", update_existing=\"parsed_caption.json\", metadata=metadata, limit=LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 72377.98it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluation = calculate_cap_f1(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to: final_with_evaluation.json\n"
     ]
    }
   ],
   "source": [
    "save_results_json(output_path=\"final_with_evaluation.json\", update_existing=\"data_recall_precision.json\", evaluations=evaluation, limit=LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to: final_with_evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "json_path = \"final_with_evaluation.json\"  # 본인 파일 경로로 바꿔주세요\n",
    "csv_path = \"final_with_evaluation.csv\"\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "fieldnames = [\n",
    "    \"image\",\n",
    "    \"gpt_recall\", \"gpt_precision\", \"gpt_capf1\",\n",
    "    \"molmo_recall\", \"molmo_precision\", \"molmo_capf1\",\n",
    "    \"llama_recall\", \"llama_precision\", \"llama_capf1\"\n",
    "]\n",
    "\n",
    "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for item in data:\n",
    "        file_name = item.get(\"file_name\", \"\")\n",
    "        scores = item.get(\"evaluation\", {}).get(\"cap_f1\", {}).get(\"scores\", {})\n",
    "\n",
    "        row = {\n",
    "            \"image\": file_name,\n",
    "            \"gpt_recall\": scores.get(\"gpt-4o-2024-08-06\", {}).get(\"recall\"),\n",
    "            \"gpt_precision\": scores.get(\"gpt-4o-2024-08-06\", {}).get(\"precision\"),\n",
    "            \"gpt_capf1\": scores.get(\"gpt-4o-2024-08-06\", {}).get(\"cap_f1\"),\n",
    "            \"molmo_recall\": scores.get(\"Molmo-7B-O-0924\", {}).get(\"recall\"),\n",
    "            \"molmo_precision\": scores.get(\"Molmo-7B-O-0924\", {}).get(\"precision\"),\n",
    "            \"molmo_capf1\": scores.get(\"Molmo-7B-O-0924\", {}).get(\"cap_f1\"),\n",
    "            \"llama_recall\": scores.get(\"Llama-3.2-11B-Vision-Instruct\", {}).get(\"recall\"),\n",
    "            \"llama_precision\": scores.get(\"Llama-3.2-11B-Vision-Instruct\", {}).get(\"precision\"),\n",
    "            \"llama_capf1\": scores.get(\"Llama-3.2-11B-Vision-Instruct\", {}).get(\"cap_f1\"),\n",
    "        }\n",
    "\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Evaluation \n",
    "### BLUE, METEOR, ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load caption file...\n"
     ]
    }
   ],
   "source": [
    "print(\"Load caption file...\")\n",
    "\n",
    "# features that we need to extract from the original dataset\n",
    "keys = [\"file_name\", \"human_captions\", \"model_captions\"]\n",
    "org_caption_dataset = read_json(\"combined-caption-output_7304-images2025-03-29_21_40_00.json\", keys)\n",
    "\n",
    "for item in org_caption_dataset:\n",
    "    # Filter out human captions\n",
    "    human_captions = [\n",
    "        hc[\"caption\"]            \n",
    "        for hc in item[\"human_captions\"]\n",
    "        if hc[\"caption\"] != \"Quality issues are too severe to recognize visual content.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/heoj4/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/heoj4/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/heoj4/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "evall = get_others(org_caption_dataset, human_captions)\n",
    "# print(json.dumps(evall, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to: others_evaluation.json\n"
     ]
    }
   ],
   "source": [
    "save_results_json(output_path=\"others_evaluation.json\", metric_name=\"others\",  evaluations=evall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
