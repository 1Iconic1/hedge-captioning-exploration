{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library for cap_f1\n",
    "from cap_f1 import *\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool\n",
    "import math\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "# code for no need for restarting the kernel when python file is updated\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load caption file...\n"
     ]
    }
   ],
   "source": [
    "print(\"Load caption file...\")\n",
    "\n",
    "# for filename\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "# create folder to save the results\n",
    "folder_path = f\"results/{timestamp}\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# features that we need to extract from the original dataset\n",
    "org_caption_dataset = read_json(\n",
    "    \"../../data/study-2-output/final-evaluated-captions/expert-captions_evaluation_600-images_2025-04-13_06:22.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 data, JSON results/2025-04-09_17-07/selected_data.json created with 24 items.\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# This is for testing\n",
    "select_data(\n",
    "    \"results/selected_filename.txt\",\n",
    "    \"evaluation_results_5432-images_2025-04-03_11_27_fixed.json\",\n",
    "    f\"{folder_path}/selected_data.json\",\n",
    ")\n",
    "org_caption_dataset = read_json(f\"{folder_path}/selected_data.json\")\n",
    "print(len(org_caption_dataset))\n",
    "# org_caption_dataset = org_caption_dataset[:1]\n",
    "# all_human_captions = all_human_captions[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The upper portion of a PlayStation 2 game case for \"Grand Theft Auto: Vice City\" is shown. The colorful illustrated cover includes characters, vehicles, and a building, with a \"Rockstar Games\" logo in yellow. The case is partially off-frame on a white surface with a cord nearby.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_human_captions = []\n",
    "for item in org_caption_dataset:\n",
    "    # Filter out human captions\n",
    "    human_captions = [\n",
    "        hc[\"caption\"]\n",
    "        for hc in item[\"human_captions\"]\n",
    "        if hc[\"caption\"] != \"Quality issues are too severe to recognize visual content.\"\n",
    "    ]\n",
    "    all_human_captions.append(human_captions)\n",
    "all_human_captions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Multi Processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(\n",
    "    start_idx,\n",
    "    end_idx,\n",
    "    org_caption_dataset,\n",
    "    all_human_captions,\n",
    "    folder_path,\n",
    "    timestamp,\n",
    "    chunk_id,\n",
    "):\n",
    "    subset = org_caption_dataset[start_idx:end_idx]\n",
    "    LIMIT = len(subset)\n",
    "    human_subset = all_human_captions[start_idx:end_idx]\n",
    "    print(human_subset)\n",
    "\n",
    "    # Step 1: Parse atomics\n",
    "    T_atomics, g_atomics, parsed_T = generate_atomic_statement(subset, limit=LIMIT)\n",
    "    save_results_json(\n",
    "        output_path=f\"{folder_path}/parsed_caption_{timestamp}_chunk{chunk_id}.json\",\n",
    "        org_dataset=subset,\n",
    "        T_atomics=T_atomics,\n",
    "        g_atomics=g_atomics,\n",
    "        parsed_T=parsed_T,\n",
    "        T_org=human_subset,\n",
    "        limit=LIMIT,\n",
    "    )\n",
    "\n",
    "    # Step 2: Match human & generated\n",
    "    metadata = evaluate_matching(human_subset, T_atomics, g_atomics)\n",
    "    save_results_json(\n",
    "        output_path=f\"{folder_path}/recall_precision_{timestamp}_chunk{chunk_id}.json\",\n",
    "        update_existing=f\"{folder_path}/parsed_caption_{timestamp}_chunk{chunk_id}.json\",\n",
    "        metadata=metadata,\n",
    "        limit=LIMIT,\n",
    "    )\n",
    "\n",
    "    # Step 3: Cap F1\n",
    "    evaluation = calculate_cap_f1(metadata)\n",
    "    save_results_json(\n",
    "        output_path=f\"{folder_path}/final_{timestamp}_chunk{chunk_id}.json\",\n",
    "        update_existing=f\"{folder_path}/recall_precision_{timestamp}_chunk{chunk_id}.json\",\n",
    "        evaluations=evaluation,\n",
    "        limit=LIMIT,\n",
    "    )\n",
    "\n",
    "\n",
    "def run_parallel_processing(\n",
    "    org_caption_dataset, all_human_captions, folder_path, timestamp, num_workers=32\n",
    "):\n",
    "    total = len(org_caption_dataset)\n",
    "    chunk_size = math.ceil(total / num_workers)\n",
    "\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        jobs = []\n",
    "        for i in range(num_workers):\n",
    "            start_idx = i * chunk_size\n",
    "            end_idx = min((i + 1) * chunk_size, total)\n",
    "            jobs.append(\n",
    "                pool.apply_async(\n",
    "                    process_batch,\n",
    "                    (\n",
    "                        start_idx,\n",
    "                        end_idx,\n",
    "                        org_caption_dataset,\n",
    "                        all_human_captions,\n",
    "                        folder_path,\n",
    "                        timestamp,\n",
    "                        i,\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for job in jobs:\n",
    "            job.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kgarg/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/kgarg/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/kgarg/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/kgarg/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_batch' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kgarg/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/kgarg/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/kgarg/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/kgarg/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_batch' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kgarg/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/kgarg/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/kgarg/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/kgarg/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_batch' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kgarg/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/kgarg/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/kgarg/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/Users/kgarg/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_batch' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_parallel_processing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43morg_caption_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_human_captions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mrun_parallel_processing\u001b[39m\u001b[34m(org_caption_dataset, all_human_captions, folder_path, timestamp, num_workers)\u001b[39m\n\u001b[32m     33\u001b[39m     jobs.append(pool.apply_async(process_batch, (start_idx, end_idx, org_caption_dataset, all_human_captions, folder_path, timestamp, i)))\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m jobs:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[43mjob\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/pool.py:768\u001b[39m, in \u001b[36mApplyResult.get\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    769\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ready():\n\u001b[32m    770\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/multiprocessing/pool.py:765\u001b[39m, in \u001b[36mApplyResult.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/threading.py:629\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    627\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "run_parallel_processing(\n",
    "    org_caption_dataset, all_human_captions, folder_path, timestamp, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged 24 entries into results/2025-04-09_17-07/__final_2025-04-09_17-07_merged.json\n"
     ]
    }
   ],
   "source": [
    "def merge_json_chunks(output_file, file_pattern):\n",
    "    merged_data = []\n",
    "\n",
    "    for filename in sorted(glob.glob(file_pattern)):\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                if isinstance(data, list):\n",
    "                    merged_data.extend(data)\n",
    "                elif isinstance(data, dict):\n",
    "                    merged_data.append(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to read {filename}: {e}\")\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as out_f:\n",
    "        json.dump(merged_data, out_f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Merged {len(merged_data)} entries into {output_file}\")\n",
    "\n",
    "\n",
    "merge_json_chunks(\n",
    "    output_file=f\"{folder_path}/__final_{timestamp}_merged.json\",\n",
    "    file_pattern=f\"{folder_path}/final_{timestamp}_chunk*.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to: results/2025-04-09_17-07/__final_2025-04-09_17-07_merged.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "\n",
    "def format_matches(match_list):\n",
    "    lines = []\n",
    "    for m in match_list:\n",
    "        if \"T_atomic\" in m and \"g_atomic\" in m:\n",
    "            lines.append(f'{m[\"T_atomic\"]} : {m[\"g_atomic\"]}')\n",
    "        elif \"g_atomic\" in m and \"T_org\" in m:\n",
    "            lines.append(f'{m[\"g_atomic\"]} : {m[\"T_org\"]}')\n",
    "        else:\n",
    "            lines.append(str(m))  # fallback for unexpected format\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "json_path = f\"{folder_path}/__final_{timestamp}_merged.json\"\n",
    "csv_path = f\"{folder_path}/__final_{timestamp}_merged.csv\"\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "fieldnames = [\n",
    "    \"image\",\n",
    "    \"link\",\n",
    "    \"T_org\",\n",
    "    \"parsed_T\",\n",
    "    \"T_atomics\",\n",
    "    \"gpt_caption\",\n",
    "    \"gpt_g_atomics\",\n",
    "    \"gpt_recall_TPs\",\n",
    "    \"gpt_recall_Matches\",\n",
    "    \"gpt_recall_FNs\",\n",
    "    \"gpt_precision_TPs\",\n",
    "    \"gpt_precision_Matches\",\n",
    "    \"gpt_precision_FPs\",\n",
    "    \"molmo_caption\",\n",
    "    \"molmo_g_atomics\",\n",
    "    \"molmo_recall_TPs\",\n",
    "    \"molmo_recall_Matches\",\n",
    "    \"molmo_recall_FNs\",\n",
    "    \"molmo_precision_TPs\",\n",
    "    \"molmo_precision_Matches\",\n",
    "    \"molmo_precision_FPs\",\n",
    "    \"llama_caption\",\n",
    "    \"llama_g_atomics\",\n",
    "    \"llama_recall_TPs\",\n",
    "    \"llama_recall_Matches\",\n",
    "    \"llama_recall_FNs\",\n",
    "    \"llama_precision_TPs\",\n",
    "    \"llama_precision_Matches\",\n",
    "    \"llama_precision_FPs\",\n",
    "    \"gpt_recall\",\n",
    "    \"gpt_precision\",\n",
    "    \"gpt_capf1\",\n",
    "    \"molmo_recall\",\n",
    "    \"molmo_precision\",\n",
    "    \"molmo_capf1\",\n",
    "    \"llama_recall\",\n",
    "    \"llama_precision\",\n",
    "    \"llama_capf1\",\n",
    "]\n",
    "\n",
    "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for item in data:\n",
    "        file_name = item.get(\"file_name\", \"\")\n",
    "        cap_f1 = item.get(\"evaluation\", {}).get(\"cap_f1\", {})\n",
    "        scores = cap_f1.get(\"scores\", {})\n",
    "        metadata = cap_f1.get(\"metadata\", {})\n",
    "        t_atomics = cap_f1.get(\"T_atomics\", [])\n",
    "        parsed_T = cap_f1.get(\"parsed_atomics\", [])\n",
    "        T_org = cap_f1.get(\"T_org\", [])\n",
    "\n",
    "        model_keys = {\n",
    "            \"gpt\": \"gpt-4o-2024-08-06\",\n",
    "            \"molmo\": \"Molmo-7B-O-0924\",\n",
    "            \"llama\": \"Llama-3.2-11B-Vision-Instruct\",\n",
    "        }\n",
    "\n",
    "        row = {\n",
    "            \"image\": file_name,\n",
    "            \"link\": f'=HYPERLINK(\"https://vizwiz.cs.colorado.edu/VizWiz_visualization_img/{file_name}\", \"{file_name}\")',\n",
    "            \"T_org\": \"\\n\".join(T_org),\n",
    "            \"parsed_T\": \"\\n\".join(parsed_T),\n",
    "            \"T_atomics\": \"\\n\".join(t_atomics),\n",
    "            \"gpt_caption\": item[\"model_captions\"][0][\"caption\"],\n",
    "            \"molmo_caption\": item[\"model_captions\"][2][\"caption\"],\n",
    "            \"llama_caption\": item[\"model_captions\"][1][\"caption\"],\n",
    "            \"gpt_g_atomics\": \"\",\n",
    "            \"molmo_g_atomics\": \"\",\n",
    "            \"llama_g_atomics\": \"\",\n",
    "            \"gpt_recall_TPs\": \"\",\n",
    "            \"molmo_recall_TPs\": \"\",\n",
    "            \"llama_recall_TPs\": \"\",\n",
    "            \"gpt_recall_Matches\": \"\",\n",
    "            \"molmo_recall_Matches\": \"\",\n",
    "            \"llama_recall_Matches\": \"\",\n",
    "            \"gpt_recall_FNs\": \"\",\n",
    "            \"molmo_recall_FNs\": \"\",\n",
    "            \"llama_recall_FNs\": \"\",\n",
    "            \"gpt_precision_TPs\": \"\",\n",
    "            \"molmo_precision_TPs\": \"\",\n",
    "            \"llama_precision_TPs\": \"\",\n",
    "            \"gpt_precision_Matches\": \"\",\n",
    "            \"molmo_precision_Matches\": \"\",\n",
    "            \"llama_precision_Matches\": \"\",\n",
    "            \"gpt_precision_FPs\": \"\",\n",
    "            \"molmo_precision_FPs\": \"\",\n",
    "            \"llama_precision_FPs\": \"\",\n",
    "            \"gpt_recall\": scores.get(model_keys[\"gpt\"], {}).get(\"recall\"),\n",
    "            \"gpt_precision\": scores.get(model_keys[\"gpt\"], {}).get(\"precision\"),\n",
    "            \"gpt_capf1\": scores.get(model_keys[\"gpt\"], {}).get(\"cap_f1\"),\n",
    "            \"molmo_recall\": scores.get(model_keys[\"molmo\"], {}).get(\"recall\"),\n",
    "            \"molmo_precision\": scores.get(model_keys[\"molmo\"], {}).get(\"precision\"),\n",
    "            \"molmo_capf1\": scores.get(model_keys[\"molmo\"], {}).get(\"cap_f1\"),\n",
    "            \"llama_recall\": scores.get(model_keys[\"llama\"], {}).get(\"recall\"),\n",
    "            \"llama_precision\": scores.get(model_keys[\"llama\"], {}).get(\"precision\"),\n",
    "            \"llama_capf1\": scores.get(model_keys[\"llama\"], {}).get(\"cap_f1\"),\n",
    "        }\n",
    "\n",
    "        for short_name, model_key in model_keys.items():\n",
    "            g_atomics_list = cap_f1.get(\"g_atomics\", {}).get(model_key, [])\n",
    "            row[f\"{short_name}_g_atomics\"] = \"\\n\".join(g_atomics_list)\n",
    "\n",
    "            recall = metadata.get(model_key, {}).get(\"recall\", {})\n",
    "            row[f\"{short_name}_recall_TPs\"] = \"\\n\".join(recall.get(\"TPs\", []))\n",
    "            row[f\"{short_name}_recall_FNs\"] = \"\\n\".join(recall.get(\"FNs\", []))\n",
    "            row[f\"{short_name}_recall_Matches\"] = format_matches(\n",
    "                recall.get(\"Match\", [])\n",
    "            )\n",
    "\n",
    "            precision = metadata.get(model_key, {}).get(\"precision\", {})\n",
    "            row[f\"{short_name}_precision_TPs\"] = \"\\n\".join(precision.get(\"TPs\", []))\n",
    "            row[f\"{short_name}_precision_FPs\"] = \"\\n\".join(precision.get(\"FPs\", []))\n",
    "            row[f\"{short_name}_precision_Matches\"] = format_matches(\n",
    "                precision.get(\"Match\", [])\n",
    "            )\n",
    "\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-blurred-captioning-exploration-4LZKhcfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
