{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_black\n",
    "\n",
    "# Libraries\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# for showing image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc7a670ec0f4f4580771ba41b8e4da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model\n",
    "model_id = \"allenai/Molmo-7B-O-0924\"\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# parameters to model\n",
    "prompt = \"You are a program designed to help blind and low-vision users understand images. When asked about the image, generate accessible image description that includes key visual and contextual details of the image for blind and low-vision people. Focus on the following principles: Clarity and Conciseness: Use simple, straightforward language to describe the main subjects and their relationships.; Relevance: Highlight only essential visual elements that contribute to understanding the image or its purpose.; Context: Provide contextual information when necessary, such as emotional tone, setting, or action. Avoid assumptions or subjective interpretations.; Specificity: Include important details like colors, shapes, textures, or text visible in the image, if relevant. Avoid overly general terms or unnecessary details. Once you generate your caption, shorten it to a succinct, single sentence. Output only the final sentence. Can you please tell me what is in this image?\"\n",
    "\n",
    "\n",
    "# captioning function\n",
    "def generate_caption(\n",
    "    image_object, model, processor, prompt, temperature=1.0, do_sample=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a caption for an image.\n",
    "\n",
    "    Inputs:\n",
    "    - image_object (pil Image): image to caption.\n",
    "    - model (torch model): loaded model to use for captioning.\n",
    "    - processor (torch processor): loaded processor for pre-processing inputs.\n",
    "    - temperature (float; optional): temperature setting for model, greater than 0. Defaults to 1.0; lower values are more deterministic.\n",
    "    - do_sample (boolean; optional): whether model should sample probabilities. Defaults to False -- greedy decoding.\n",
    "\n",
    "    Output:\n",
    "    - (str): caption for image.\n",
    "    \"\"\"\n",
    "    # process the image and text\n",
    "    inputs = processor.process(\n",
    "        images=[image_object],\n",
    "        text=prompt,\n",
    "    )\n",
    "\n",
    "    # move inputs to the correct device and make a batch of size 1\n",
    "    inputs = {k: v.to(model.device).unsqueeze(0) for k, v in inputs.items()}\n",
    "\n",
    "    # generate output; maximum 200 new tokens; stop generation when <|endoftext|> is generated\n",
    "    output = \"\"\n",
    "    with torch.autocast(device_type=\"mps\", enabled=True, dtype=torch.bfloat16):\n",
    "        output = model.generate_from_batch(\n",
    "            inputs,\n",
    "            GenerationConfig(max_new_tokens=200, stop_strings=\"<|endoftext|>\"),\n",
    "            tokenizer=processor.tokenizer,\n",
    "            use_cache=False,\n",
    "            temperature=temperature,\n",
    "            do_sample=do_sample,\n",
    "        )\n",
    "\n",
    "        # only get generated tokens; decode them to text\n",
    "        generated_tokens = output[0, inputs[\"input_ids\"].size(1) :]\n",
    "        generated_text = processor.tokenizer.decode(\n",
    "            generated_tokens, skip_special_tokens=True\n",
    "        )\n",
    "        output = generated_text.strip()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>filepath</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>notes (include initials, e.g. 'KG: ...')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VizWiz_test_00000565</td>\n",
       "      <td>../data/multi-generation-experiment/cropped-ex...</td>\n",
       "      <td>cropped-experiment</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VizWiz_test_00000004</td>\n",
       "      <td>../data/multi-generation-experiment/cropped-ex...</td>\n",
       "      <td>cropped-experiment</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VizWiz_test_00000079</td>\n",
       "      <td>../data/multi-generation-experiment/cropped-ex...</td>\n",
       "      <td>cropped-experiment</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VizWiz_test_00000235</td>\n",
       "      <td>../data/multi-generation-experiment/cropped-ex...</td>\n",
       "      <td>cropped-experiment</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VizWiz_test_00000025</td>\n",
       "      <td>../data/multi-generation-experiment/cropped-ex...</td>\n",
       "      <td>cropped-experiment</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VizWiz_test_00000032</td>\n",
       "      <td>../data/multi-generation-experiment/cropped-ex...</td>\n",
       "      <td>cropped-experiment</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VizWiz_train_00000049</td>\n",
       "      <td>../data/multi-generation-experiment/blurring-e...</td>\n",
       "      <td>blurring-experiment</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VizWiz_train_00000000</td>\n",
       "      <td>../data/multi-generation-experiment/blurring-e...</td>\n",
       "      <td>blurring-experiment</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VizWiz_train_00023146</td>\n",
       "      <td>../data/multi-generation-experiment/blurring-e...</td>\n",
       "      <td>blurring-experiment</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VizWiz_train_00000043</td>\n",
       "      <td>../data/multi-generation-experiment/blurring-e...</td>\n",
       "      <td>blurring-experiment</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VizWiz_train_00000050</td>\n",
       "      <td>../data/multi-generation-experiment/blurring-e...</td>\n",
       "      <td>blurring-experiment</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VizWiz_train_00000088</td>\n",
       "      <td>../data/multi-generation-experiment/vizwiz-blu...</td>\n",
       "      <td>vizwiz-blurred-images</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VizWiz_train_00000506</td>\n",
       "      <td>../data/multi-generation-experiment/vizwiz-blu...</td>\n",
       "      <td>vizwiz-blurred-images</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>VizWiz_train_00000139</td>\n",
       "      <td>../data/multi-generation-experiment/vizwiz-blu...</td>\n",
       "      <td>vizwiz-blurred-images</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>VizWiz_train_00000070</td>\n",
       "      <td>../data/multi-generation-experiment/vizwiz-blu...</td>\n",
       "      <td>vizwiz-blurred-images</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>VizWiz_train_00000149</td>\n",
       "      <td>../data/multi-generation-experiment/vizwiz-blu...</td>\n",
       "      <td>vizwiz-blurred-images</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>VizWiz_train_00000201</td>\n",
       "      <td>../data/multi-generation-experiment/vizwiz-blu...</td>\n",
       "      <td>vizwiz-blurred-images</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VizWiz_train_00000200</td>\n",
       "      <td>../data/multi-generation-experiment/vizwiz-blu...</td>\n",
       "      <td>vizwiz-blurred-images</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>VizWiz_train_00000173</td>\n",
       "      <td>../data/multi-generation-experiment/vizwiz-blu...</td>\n",
       "      <td>vizwiz-blurred-images</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>VizWiz_train_00000155</td>\n",
       "      <td>../data/multi-generation-experiment/vizwiz-blu...</td>\n",
       "      <td>vizwiz-blurred-images</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>VizWiz_train_00000154</td>\n",
       "      <td>../data/multi-generation-experiment/vizwiz-blu...</td>\n",
       "      <td>vizwiz-blurred-images</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VizWiz_train_00000150</td>\n",
       "      <td>../data/multi-generation-experiment/vizwiz-blu...</td>\n",
       "      <td>vizwiz-blurred-images</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VizWiz_train_00000145</td>\n",
       "      <td>../data/multi-generation-experiment/vizwiz-blu...</td>\n",
       "      <td>vizwiz-blurred-images</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>VizWiz_train_00000131</td>\n",
       "      <td>../data/multi-generation-experiment/vizwiz-blu...</td>\n",
       "      <td>vizwiz-blurred-images</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>VizWiz_train_00000051</td>\n",
       "      <td>../data/multi-generation-experiment/vizwiz-blu...</td>\n",
       "      <td>vizwiz-blurred-images</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>VizWiz_train_00000126</td>\n",
       "      <td>../data/multi-generation-experiment/vizwiz-blu...</td>\n",
       "      <td>vizwiz-blurred-images</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name                                           filepath  \\\n",
       "0    VizWiz_test_00000565  ../data/multi-generation-experiment/cropped-ex...   \n",
       "1    VizWiz_test_00000004  ../data/multi-generation-experiment/cropped-ex...   \n",
       "2    VizWiz_test_00000079  ../data/multi-generation-experiment/cropped-ex...   \n",
       "3    VizWiz_test_00000235  ../data/multi-generation-experiment/cropped-ex...   \n",
       "4    VizWiz_test_00000025  ../data/multi-generation-experiment/cropped-ex...   \n",
       "5    VizWiz_test_00000032  ../data/multi-generation-experiment/cropped-ex...   \n",
       "6   VizWiz_train_00000049  ../data/multi-generation-experiment/blurring-e...   \n",
       "7   VizWiz_train_00000000  ../data/multi-generation-experiment/blurring-e...   \n",
       "8   VizWiz_train_00023146  ../data/multi-generation-experiment/blurring-e...   \n",
       "9   VizWiz_train_00000043  ../data/multi-generation-experiment/blurring-e...   \n",
       "10  VizWiz_train_00000050  ../data/multi-generation-experiment/blurring-e...   \n",
       "11  VizWiz_train_00000088  ../data/multi-generation-experiment/vizwiz-blu...   \n",
       "12  VizWiz_train_00000506  ../data/multi-generation-experiment/vizwiz-blu...   \n",
       "13  VizWiz_train_00000139  ../data/multi-generation-experiment/vizwiz-blu...   \n",
       "14  VizWiz_train_00000070  ../data/multi-generation-experiment/vizwiz-blu...   \n",
       "15  VizWiz_train_00000149  ../data/multi-generation-experiment/vizwiz-blu...   \n",
       "16  VizWiz_train_00000201  ../data/multi-generation-experiment/vizwiz-blu...   \n",
       "17  VizWiz_train_00000200  ../data/multi-generation-experiment/vizwiz-blu...   \n",
       "18  VizWiz_train_00000173  ../data/multi-generation-experiment/vizwiz-blu...   \n",
       "19  VizWiz_train_00000155  ../data/multi-generation-experiment/vizwiz-blu...   \n",
       "20  VizWiz_train_00000154  ../data/multi-generation-experiment/vizwiz-blu...   \n",
       "21  VizWiz_train_00000150  ../data/multi-generation-experiment/vizwiz-blu...   \n",
       "22  VizWiz_train_00000145  ../data/multi-generation-experiment/vizwiz-blu...   \n",
       "23  VizWiz_train_00000131  ../data/multi-generation-experiment/vizwiz-blu...   \n",
       "24  VizWiz_train_00000051  ../data/multi-generation-experiment/vizwiz-blu...   \n",
       "25  VizWiz_train_00000126  ../data/multi-generation-experiment/vizwiz-blu...   \n",
       "\n",
       "          experiment_type notes (include initials, e.g. 'KG: ...')  \n",
       "0      cropped-experiment                                           \n",
       "1      cropped-experiment                                           \n",
       "2      cropped-experiment                                           \n",
       "3      cropped-experiment                                           \n",
       "4      cropped-experiment                                           \n",
       "5      cropped-experiment                                           \n",
       "6     blurring-experiment                                           \n",
       "7     blurring-experiment                                           \n",
       "8     blurring-experiment                                           \n",
       "9     blurring-experiment                                           \n",
       "10    blurring-experiment                                           \n",
       "11  vizwiz-blurred-images                                           \n",
       "12  vizwiz-blurred-images                                           \n",
       "13  vizwiz-blurred-images                                           \n",
       "14  vizwiz-blurred-images                                           \n",
       "15  vizwiz-blurred-images                                           \n",
       "16  vizwiz-blurred-images                                           \n",
       "17  vizwiz-blurred-images                                           \n",
       "18  vizwiz-blurred-images                                           \n",
       "19  vizwiz-blurred-images                                           \n",
       "20  vizwiz-blurred-images                                           \n",
       "21  vizwiz-blurred-images                                           \n",
       "22  vizwiz-blurred-images                                           \n",
       "23  vizwiz-blurred-images                                           \n",
       "24  vizwiz-blurred-images                                           \n",
       "25  vizwiz-blurred-images                                           "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data folder\n",
    "data_folder = \"../data/multi-generation-experiment\"\n",
    "\n",
    "# initialize dictionary for all experiments\n",
    "input_dict = {}\n",
    "\n",
    "for directory in next(os.walk(data_folder), ([], [], []))[1]:\n",
    "    # create path to subdirectory\n",
    "    subdir_path = os.path.join(data_folder, directory)\n",
    "\n",
    "    # get all image files in subdirectory\n",
    "    for image_file in next(os.walk(subdir_path), ([], [], []))[2]:\n",
    "        # skip hidden files\n",
    "        if image_file.startswith(\".\"):\n",
    "            continue\n",
    "\n",
    "        # get name without extension\n",
    "        name_without_extension, _ = os.path.splitext(image_file)\n",
    "\n",
    "        # add to dictionary with full filepath\n",
    "        input_dict[name_without_extension] = {\n",
    "            \"filepath\": os.path.join(subdir_path, image_file),\n",
    "            \"experiment_type\": directory,  # track which experiment this is from\n",
    "            \"notes (include initials, e.g. 'KG: ...')\": \"\",\n",
    "        }\n",
    "\n",
    "dataset_to_caption = [{\"name\": key} | value for key, value in input_dict.items()]\n",
    "pd.DataFrame.from_dict(dataset_to_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Generation Experiment 1: same temperature, but add sampling\n",
    "Sampling helps break the determistic generation the model has by default. Fix temperature to `1.0` so it balances determinism with randomness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd48c150a8bb437684991b320cf28419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for index, row in enumerate(tqdm(dataset_to_caption)):\n",
    "    # get image for current annotation\n",
    "    image_file = dataset_to_caption[index][\"filepath\"]\n",
    "\n",
    "    # show original image\n",
    "    pillow_image = Image.open(image_file)\n",
    "\n",
    "    # generate n_samples captions for this image\n",
    "    for sample_idx in range(n_samples):\n",
    "        key = f\"caption_temperature-1.0_number-{sample_idx + 1}\"\n",
    "        # get caption from model\n",
    "        dataset_to_caption[index][key] = generate_caption(\n",
    "            pillow_image,\n",
    "            model,\n",
    "            processor,\n",
    "            prompt,\n",
    "            temperature=1.0,\n",
    "            do_sample=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Generation Experiment 2: varying temperature with sampling\n",
    "Sampling helps break the determistic generation the model has by default. Temperature varies from `0.1` to `2.0`, with lower temperatures leading to more determinstic outputs and higher to more random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_settings = [0.1, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1991eda226c646e1a0407be7ae6541ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for index, row in enumerate(tqdm(dataset_to_caption)):\n",
    "    # get image for current annotation\n",
    "    image_file = dataset_to_caption[index][\"filepath\"]\n",
    "\n",
    "    # show original image\n",
    "    pillow_image = Image.open(image_file)\n",
    "\n",
    "    # generate n_samples captions for this image\n",
    "    for temperature in temperature_settings:\n",
    "        key = f\"caption_temperature-{temperature}\"\n",
    "\n",
    "        # get caption from model\n",
    "        dataset_to_caption[index][key] = generate_caption(\n",
    "            pillow_image,\n",
    "            model,\n",
    "            processor,\n",
    "            prompt,\n",
    "            temperature=1.0,\n",
    "            do_sample=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>filepath</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>notes (include initials, e.g. 'KG: ...')</th>\n",
       "      <th>caption_temperature-1.0_number-1</th>\n",
       "      <th>caption_temperature-1.0_number-2</th>\n",
       "      <th>caption_temperature-1.0_number-3</th>\n",
       "      <th>caption_temperature-1.0_number-4</th>\n",
       "      <th>caption_temperature-1.0_number-5</th>\n",
       "      <th>caption_temperature-0.1</th>\n",
       "      <th>caption_temperature-0.25</th>\n",
       "      <th>caption_temperature-0.5</th>\n",
       "      <th>caption_temperature-0.75</th>\n",
       "      <th>caption_temperature-1.0</th>\n",
       "      <th>caption_temperature-1.5</th>\n",
       "      <th>caption_temperature-2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VizWiz_train_00000000</td>\n",
       "      <td>../data/multi-generation-experiment/blurring-e...</td>\n",
       "      <td>blurring-experiment</td>\n",
       "      <td></td>\n",
       "      <td>A clear bottle containing basil leaves rests o...</td>\n",
       "      <td>An empty bottle of basil leaves is visible on ...</td>\n",
       "      <td>The image shows a jar of dried basil leaves on...</td>\n",
       "      <td>A plastic container of ground basil leaves is ...</td>\n",
       "      <td>The image shows a small plastic container of d...</td>\n",
       "      <td>A clear plastic jar containing dried basil lea...</td>\n",
       "      <td>A spice container labeled \"basil leaves\" sits ...</td>\n",
       "      <td>The image shows a clear plastic bottle contain...</td>\n",
       "      <td>A bottle of dried basil leaves is placed on a ...</td>\n",
       "      <td>The image shows a jar of basil leaves sitting ...</td>\n",
       "      <td>The image depicts a bottle of loose basil leav...</td>\n",
       "      <td>A small plastic bottle of basil leaves sits on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VizWiz_train_00000043</td>\n",
       "      <td>../data/multi-generation-experiment/blurring-e...</td>\n",
       "      <td>blurring-experiment</td>\n",
       "      <td></td>\n",
       "      <td>The image shows a container of spice mix in a ...</td>\n",
       "      <td>The image shows a spice packaging for apple pi...</td>\n",
       "      <td>The image shows a rectangular spice container ...</td>\n",
       "      <td>The image shows a jar of natural spices, speci...</td>\n",
       "      <td>The image shows a container labeled \"Apple Pie...</td>\n",
       "      <td>The image shows a spice jar labeled \"Apple Pie...</td>\n",
       "      <td>The image shows a spice jar containing a blend...</td>\n",
       "      <td>An apple pie spice container is visible on a b...</td>\n",
       "      <td>The image shows a food container with a label ...</td>\n",
       "      <td>The image shows a sideways plastic spice bottl...</td>\n",
       "      <td>The image shows a label on a spice bottle, lik...</td>\n",
       "      <td>The image shows a container of apple pie spice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VizWiz_train_00000049</td>\n",
       "      <td>../data/multi-generation-experiment/blurring-e...</td>\n",
       "      <td>blurring-experiment</td>\n",
       "      <td></td>\n",
       "      <td>A clear water bottle with a blue Kirkland logo...</td>\n",
       "      <td>A plastic bottle of water with a blue label ca...</td>\n",
       "      <td>A water bottle sits on a desk, with a power st...</td>\n",
       "      <td>I can see a plastic bottle of water with a blu...</td>\n",
       "      <td>A plastic bottle of water labeled \"Kirkland Si...</td>\n",
       "      <td>A plastic bottle of water and a white sheet of...</td>\n",
       "      <td>A plastic water bottle sits on a green desk wi...</td>\n",
       "      <td>The image shows a white desk with a clear plas...</td>\n",
       "      <td>A clear bottled water on a white surface with ...</td>\n",
       "      <td>A water bottle with a blue label sits on a des...</td>\n",
       "      <td>A table with a Kirkland label water bottle on ...</td>\n",
       "      <td>The image shows a desk with a clear plastic wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VizWiz_train_00000050</td>\n",
       "      <td>../data/multi-generation-experiment/blurring-e...</td>\n",
       "      <td>blurring-experiment</td>\n",
       "      <td></td>\n",
       "      <td>A blurred close-up shows a hand holding an unr...</td>\n",
       "      <td>A hand holds up a blue yogurt pot in an indoor...</td>\n",
       "      <td>A hand holds a container of Dr. Oetker Yoken y...</td>\n",
       "      <td>A person is holding a yogurt container labeled...</td>\n",
       "      <td>A person is holding a container of yogurt, lik...</td>\n",
       "      <td>I am a machine-generated program designed to a...</td>\n",
       "      <td>I understand you're asking me to describe the ...</td>\n",
       "      <td>A hand is holding a small container labeled 'D...</td>\n",
       "      <td>The image shows a hand holding a blue and whit...</td>\n",
       "      <td>A hand in the bottom left corner holds a canis...</td>\n",
       "      <td>The image shows a man's hand holding a cylindr...</td>\n",
       "      <td>The image shows a hand holding a blue food lab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VizWiz_train_00023146</td>\n",
       "      <td>../data/multi-generation-experiment/blurring-e...</td>\n",
       "      <td>blurring-experiment</td>\n",
       "      <td></td>\n",
       "      <td>I am designed to help blind and low-vision use...</td>\n",
       "      <td>There's a yellow highlighter pen on a dark gre...</td>\n",
       "      <td>A neon yellow highlighter lies on its side aga...</td>\n",
       "      <td>The image shows a bright yellow highlighter pe...</td>\n",
       "      <td>It shows a yellow highlighter on a gray surfac...</td>\n",
       "      <td>I have developed an AI model to generate descr...</td>\n",
       "      <td>A highlighter pen is lying on a grey surface, ...</td>\n",
       "      <td>There's a yellow highlighter on a gray surface...</td>\n",
       "      <td>The image shows a highlighter on a surface, wi...</td>\n",
       "      <td>A yellow highlighter on a textured surface wit...</td>\n",
       "      <td>The image shows a yellow highlighter on a text...</td>\n",
       "      <td>A yellow highlighter with \"hi-liter\" written o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name                                           filepath  \\\n",
       "7   VizWiz_train_00000000  ../data/multi-generation-experiment/blurring-e...   \n",
       "9   VizWiz_train_00000043  ../data/multi-generation-experiment/blurring-e...   \n",
       "6   VizWiz_train_00000049  ../data/multi-generation-experiment/blurring-e...   \n",
       "10  VizWiz_train_00000050  ../data/multi-generation-experiment/blurring-e...   \n",
       "8   VizWiz_train_00023146  ../data/multi-generation-experiment/blurring-e...   \n",
       "\n",
       "        experiment_type notes (include initials, e.g. 'KG: ...')  \\\n",
       "7   blurring-experiment                                            \n",
       "9   blurring-experiment                                            \n",
       "6   blurring-experiment                                            \n",
       "10  blurring-experiment                                            \n",
       "8   blurring-experiment                                            \n",
       "\n",
       "                     caption_temperature-1.0_number-1  \\\n",
       "7   A clear bottle containing basil leaves rests o...   \n",
       "9   The image shows a container of spice mix in a ...   \n",
       "6   A clear water bottle with a blue Kirkland logo...   \n",
       "10  A blurred close-up shows a hand holding an unr...   \n",
       "8   I am designed to help blind and low-vision use...   \n",
       "\n",
       "                     caption_temperature-1.0_number-2  \\\n",
       "7   An empty bottle of basil leaves is visible on ...   \n",
       "9   The image shows a spice packaging for apple pi...   \n",
       "6   A plastic bottle of water with a blue label ca...   \n",
       "10  A hand holds up a blue yogurt pot in an indoor...   \n",
       "8   There's a yellow highlighter pen on a dark gre...   \n",
       "\n",
       "                     caption_temperature-1.0_number-3  \\\n",
       "7   The image shows a jar of dried basil leaves on...   \n",
       "9   The image shows a rectangular spice container ...   \n",
       "6   A water bottle sits on a desk, with a power st...   \n",
       "10  A hand holds a container of Dr. Oetker Yoken y...   \n",
       "8   A neon yellow highlighter lies on its side aga...   \n",
       "\n",
       "                     caption_temperature-1.0_number-4  \\\n",
       "7   A plastic container of ground basil leaves is ...   \n",
       "9   The image shows a jar of natural spices, speci...   \n",
       "6   I can see a plastic bottle of water with a blu...   \n",
       "10  A person is holding a yogurt container labeled...   \n",
       "8   The image shows a bright yellow highlighter pe...   \n",
       "\n",
       "                     caption_temperature-1.0_number-5  \\\n",
       "7   The image shows a small plastic container of d...   \n",
       "9   The image shows a container labeled \"Apple Pie...   \n",
       "6   A plastic bottle of water labeled \"Kirkland Si...   \n",
       "10  A person is holding a container of yogurt, lik...   \n",
       "8   It shows a yellow highlighter on a gray surfac...   \n",
       "\n",
       "                              caption_temperature-0.1  \\\n",
       "7   A clear plastic jar containing dried basil lea...   \n",
       "9   The image shows a spice jar labeled \"Apple Pie...   \n",
       "6   A plastic bottle of water and a white sheet of...   \n",
       "10  I am a machine-generated program designed to a...   \n",
       "8   I have developed an AI model to generate descr...   \n",
       "\n",
       "                             caption_temperature-0.25  \\\n",
       "7   A spice container labeled \"basil leaves\" sits ...   \n",
       "9   The image shows a spice jar containing a blend...   \n",
       "6   A plastic water bottle sits on a green desk wi...   \n",
       "10  I understand you're asking me to describe the ...   \n",
       "8   A highlighter pen is lying on a grey surface, ...   \n",
       "\n",
       "                              caption_temperature-0.5  \\\n",
       "7   The image shows a clear plastic bottle contain...   \n",
       "9   An apple pie spice container is visible on a b...   \n",
       "6   The image shows a white desk with a clear plas...   \n",
       "10  A hand is holding a small container labeled 'D...   \n",
       "8   There's a yellow highlighter on a gray surface...   \n",
       "\n",
       "                             caption_temperature-0.75  \\\n",
       "7   A bottle of dried basil leaves is placed on a ...   \n",
       "9   The image shows a food container with a label ...   \n",
       "6   A clear bottled water on a white surface with ...   \n",
       "10  The image shows a hand holding a blue and whit...   \n",
       "8   The image shows a highlighter on a surface, wi...   \n",
       "\n",
       "                              caption_temperature-1.0  \\\n",
       "7   The image shows a jar of basil leaves sitting ...   \n",
       "9   The image shows a sideways plastic spice bottl...   \n",
       "6   A water bottle with a blue label sits on a des...   \n",
       "10  A hand in the bottom left corner holds a canis...   \n",
       "8   A yellow highlighter on a textured surface wit...   \n",
       "\n",
       "                              caption_temperature-1.5  \\\n",
       "7   The image depicts a bottle of loose basil leav...   \n",
       "9   The image shows a label on a spice bottle, lik...   \n",
       "6   A table with a Kirkland label water bottle on ...   \n",
       "10  The image shows a man's hand holding a cylindr...   \n",
       "8   The image shows a yellow highlighter on a text...   \n",
       "\n",
       "                              caption_temperature-2.0  \n",
       "7   A small plastic bottle of basil leaves sits on...  \n",
       "9   The image shows a container of apple pie spice...  \n",
       "6   The image shows a desk with a clear plastic wa...  \n",
       "10  The image shows a hand holding a blue food lab...  \n",
       "8   A yellow highlighter with \"hi-liter\" written o...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe\n",
    "output_df = pd.DataFrame.from_dict(dataset_to_caption)\n",
    "\n",
    "# sort on image type and name\n",
    "output_df.sort_values(by=[\"experiment_type\", \"name\"], inplace=True)\n",
    "\n",
    "# save file\n",
    "output_df.to_csv(\n",
    "    \"../data/labeled-data/molmo-model/multi-generation-experiment_03-03-25.csv\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "# print dataframe\n",
    "output_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-blurred-captioning-exploration-4LZKhcfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
